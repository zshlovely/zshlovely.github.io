<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>HBase基础</title>
    <url>/2019/10/18/HBase%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><p>或者说 HBase是在Hadoop和ZooKeeper之上构建<strong>非关系型</strong>，<strong>面向列存储</strong>的开源分布式结构化数据存储系统。</p>
<p>HBase的部署前提：Zookeeper + Hadoop</p>
<h2 id="1-HBase-介绍"><a href="#1-HBase-介绍" class="headerlink" title="1. HBase 介绍"></a>1. HBase 介绍</h2><ul>
<li><p>HBase和Hive</p>
<ol>
<li><p>应用场景</p>
<p>Hive适合用于对一段时间内的数据进行分析查询。如 计算趋势金和网站的日志。Hive需要很长的时间才可以返回结果，因此不适合进行实时查询。</p>
<p>HBase 非常适合大数据的实时查询。Facebook使用HBase进行消息的实时分析，统计Facebook的连接数</p>
</li>
<li><p>总结</p>
<p><strong>Hive</strong> 是一种类SQL的引擎，运行MR任务。<strong>用来离线统计查询</strong>。</p>
<p><strong>HBase</strong>是一种在Hadoop之上的<strong>NoSQL的key&#x2F;value 数据库</strong>。<strong>进行实时查询</strong>。</p>
</li>
</ol>
</li>
<li><p>HBase角色</p>
<p>HMaster 和 RegionServer</p>
<ol>
<li><p>HMaster</p>
<ol>
<li><p>监控RegionServer</p>
</li>
<li><p>处理RegionServer故障转移</p>
</li>
<li><p>处理元数据的变更</p>
</li>
<li><p>处理region的分配或移除</p>
</li>
<li><p>在空闲时间进行数据的负载均衡</p>
</li>
<li><p>通过Zookeeper发布自己的位置给客户端</p>
</li>
</ol>
</li>
<li><p>RegionServer</p>
<ol>
<li><p>负责存储HBase的实际数据</p>
</li>
<li><p>处理分配给它的Region</p>
</li>
<li><p>刷新缓存到HDFS</p>
</li>
<li><p>维护HLog</p>
</li>
<li><p>执行压缩</p>
</li>
<li><p>负责处理Region分片</p>
</li>
</ol>
</li>
<li><p>组件</p>
<ul>
<li><p>Write-Ahead logs</p>
<p>HBase读写数据的时候，数据会先写在一个叫做Write-Ahead logfile的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p>
</li>
<li><p>HFile</p>
<p>原始数据的实际存储文件。</p>
</li>
<li><p>Store</p>
<p>HFile存储在Store中，一个Store对应HBase表中的一个列族。</p>
</li>
<li><p>MemStore</p>
<p>内存存储，位于内存中，用来保存当前的数据操作。</p>
<p>当数据保存在WAL中之后，RegsionServer会在内存中存储键值对。</p>
</li>
<li><p>Region</p>
<p>Hbase表的分片，HBase表会根据RowKey值被切分成不同的region存储在RegionServer中，在一个RegionServer中可以有多个不同的region。（我的理解类似于分区）</p>
</li>
</ul>
</li>
<li><p>HBase的启动</p>
<ul>
<li>bin&#x2F;start-hbase.sh</li>
<li>bin&#x2F;stop-hbase.sh</li>
</ul>
<p>如果使用的是JDK8以上版本，则应在hbase-evn.sh中</p>
<p>移除“HBASE_MASTER_OPTS”和“HBASE_REGIONSERVER_OPTS”配置。</p>
<ul>
<li><p>查看Hbase页面</p>
<p><a href="http://masterhost:16010/">http://masterhost:16010</a></p>
</li>
</ul>
</li>
</ol>
<p><strong>简单说下HBase的表分区和索引管理</strong></p>
<ul>
<li>将Table 中的数据根据rowKey 字段划分为多个HRegion</li>
<li>HRegion分配给RegionServer管理</li>
</ul>
</li>
</ul>
<h2 id="2-HBase的使用"><a href="#2-HBase的使用" class="headerlink" title="2. HBase的使用"></a>2. HBase的使用</h2><h3 id="2-1-简单实用"><a href="#2-1-简单实用" class="headerlink" title="2.1 简单实用"></a>2.1 简单实用</h3><h4 id="2-1-1-基本操作"><a href="#2-1-1-基本操作" class="headerlink" title="2.1.1 基本操作"></a>2.1.1 基本操作</h4><ul>
<li><p>进入客户端</p>
<p>bin&#x2F;hbase shell</p>
</li>
<li><p>帮助命令：help</p>
</li>
<li><p>查看当前数据库的表：list</p>
</li>
</ul>
<h4 id="2-2-2-表的操作"><a href="#2-2-2-表的操作" class="headerlink" title="2.2.2 表的操作"></a>2.2.2 表的操作</h4><p>涉及的名称：表名，列族，rowkey，列名，值</p>
<p>ps：由于是key value结构的数据，可以<strong>把列族理解为一个对象</strong>，<strong>列理解为对象的一个属性</strong></p>
<ul>
<li><p>创建表 student – <strong>student 表名，info 列族</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create &#x27;student&#x27;,&#x27;info&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>插入数据列表 – <strong>name,sex,age 列名，</strong> <strong>1001&#x2F;1002 rowkey</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;,&#x27;Thomas&#x27;</span><br><span class="line">put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:sex&#x27;,&#x27;male&#x27;</span><br><span class="line">put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:age&#x27;,&#x27;18&#x27;</span><br><span class="line">put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:name&#x27;,&#x27;Janna&#x27;</span><br><span class="line">put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:sex&#x27;,&#x27;female&#x27;</span><br><span class="line">put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:age&#x27;,&#x27;20&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>扫描查看表数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scan &#x27;student&#x27;</span><br><span class="line"></span><br><span class="line">scan &#x27;student&#x27;,&#123;STARTROW =&gt; &#x27;1001&#x27;, STOPROW  =&gt; &#x27;1001&#x27;&#125;</span><br><span class="line"></span><br><span class="line">scan &#x27;student&#x27;,&#123;STARTROW =&gt; &#x27;1001&#x27;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看表结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">describe ‘student’</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新指定字段的数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;,&#x27;Nick&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:age&#x27;,&#x27;100&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看“指定行”或“指定列族:列”的数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">get &#x27;student&#x27;,&#x27;1001&#x27; //查看指定行</span><br><span class="line"></span><br><span class="line">get &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27; //指定列族info 指定列name</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除数据</p>
<p>删除某 rowkey 的全部数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;student&#x27;,&#x27;1001&#x27;</span><br></pre></td></tr></table></figure>

<p>删除某 rowkey 的某一列数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delete &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:sex&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>清空表数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable &#x27;student&#x27;</span><br><span class="line"></span><br><span class="line">truncate &#x27;student&#x27;</span><br></pre></td></tr></table></figure>

<p>PS: 清空表的操作顺序为先disable，然后再truncating。</p>
</li>
<li><p>删除表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable &#x27;student&#x27;</span><br><span class="line"></span><br><span class="line">drop &#x27;student&#x27;</span><br></pre></td></tr></table></figure>

<p>PS: 删除表的操作顺序为先disable，然后再drop。</p>
</li>
<li><p>统计表数据的行数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">count &#x27;student&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>变更表信息</p>
<p>将列族中的数据存放3个版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter &#x27;student&#x27;,&#123;NAME=&gt;&#x27;info&#x27;,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-读写流程"><a href="#2-2-读写流程" class="headerlink" title="2.2 读写流程"></a>2.2 读写流程</h3><h4 id="2-2-1-Hbase读流程"><a href="#2-2-1-Hbase读流程" class="headerlink" title="2.2.1 Hbase读流程"></a>2.2.1 Hbase读流程</h4><ol>
<li><p><strong>确定meta表所在的HRegionServer</strong>。</p>
<p>HRegionServer保存着meta表以及表数据。因此要访问表数据，首先Client先去访问zookeeper，从zookeeper里面获取meta表所在的位置信息，即找到这个meta表在哪个HRegionServer上保存着。</p>
</li>
<li><p><strong>访问meta表所在的HRegionServer,读取meta表中存放的元数据</strong>。</p>
<p>Client通过刚才获取到的HRegionServer的IP来访问Meta表所在的HRegionServer，从而读取到Meta，进而获取到Meta表中存放的元数据。</p>
</li>
<li><p><strong>根据元数据扫描Memstore和Storefile 查询数据</strong>。</p>
<p>Client通过元数据中存储的信息，访问对应的HRegionServer，然后扫描所在HRegionServer的Memstore和Storefile来查询数据。</p>
</li>
<li><p>HRegionServer把查询到的数据响应给Client。</p>
</li>
</ol>
<h4 id="2-2-2-HBase写数据流程"><a href="#2-2-2-HBase写数据流程" class="headerlink" title="2.2.2 HBase写数据流程"></a>2.2.2 HBase写数据流程</h4><ol>
<li><p><strong>获取Meta表信息</strong></p>
<p>Client也是先访问zookeeper，找到Meta表，并获取Meta表信息。</p>
</li>
<li><p><strong>确定RegionServer服务器和Region。</strong></p>
<p>确定当前将要写入的数据所对应的RegionServer服务器和Region。</p>
</li>
<li><p><strong>发起写入数据请求</strong></p>
<p>Client向该RegionServer服务器发起写入数据请求，然后RegionServer收到请求并响应。</p>
</li>
<li><p><strong>先写HLog</strong></p>
<p>Client先把数据写入到HLog，以防止数据丢失。</p>
</li>
<li><p><strong>再写Memstore</strong></p>
</li>
<li><p>如果<strong>Hlog</strong>和<strong>Memstore均写入成功</strong>，则这条数据<strong>写入成功</strong>。</p>
<p>在此过程中，如果Memstore达到阈值，会把Memstore中的数据flush到StoreFile中。</p>
</li>
<li><p><strong>Compact合并操作 和 Split操作</strong></p>
<p>当<strong>Storefile越来越多</strong>，会触发Compact<strong>合并操作</strong>，把过多的Storefile合并成一个大的Storefile。当<strong>Storefile越来越大</strong>，Region也会越来越大，<strong>达到阈值后</strong>，会触发<strong>Split操作</strong>，<strong>将Region一分为二</strong>。</p>
</li>
</ol>
<p><strong>PS: 因为内存空间的限制，溢写文件必定伴随着大量小文件的产生。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">总结：写入的时候 Hlog 和 Memstore均写入。</span><br><span class="line"></span><br><span class="line">1. Memstore 达到阈值，flush 到 Storefile 中。</span><br><span class="line">2. Storefile太多，Compact合并操作，合成大的Storefile。</span><br><span class="line">3. Storefile太大，Region达到阈值后触发Split操作，将Region一分为二。</span><br></pre></td></tr></table></figure>

<h2 id="3-HBase-MapReduce。。"><a href="#3-HBase-MapReduce。。" class="headerlink" title="3. HBase - MapReduce。。"></a>3. HBase - MapReduce。。</h2><ol>
<li>使用MapReduce将数据从本地文件系统导入到HBase的表。</li>
<li>从HBase中读取一些原始数据后使用MapReduce做数据分析</li>
</ol>
<h3 id="3-1-使用官方的-MR"><a href="#3-1-使用官方的-MR" class="headerlink" title="3.1 使用官方的 MR"></a>3.1 使用官方的 MR</h3><h2 id="4-HBase-Hive。。"><a href="#4-HBase-Hive。。" class="headerlink" title="4. HBase - Hive。。"></a>4. HBase - Hive。。</h2><h2 id="5-常用-Shell-操作"><a href="#5-常用-Shell-操作" class="headerlink" title="5. 常用 Shell 操作"></a>5. 常用 Shell 操作</h2><ol>
<li><p><strong>status</strong></p>
<p>例如显示服务器状态：status ‘linux01’</p>
</li>
<li><p><strong>whoami</strong></p>
<p>显示HBase 当前用户：hbase&gt; whoami</p>
</li>
<li><p><strong>list</strong></p>
<p>显示当前所有的表：hbase&gt; list</p>
</li>
<li><p><strong>count</strong></p>
<p>统计指定表的记录数：count ‘hbase_student’</p>
</li>
<li><p><strong>describe</strong></p>
<p>展示表结构：describe ‘hbase_student’</p>
</li>
<li><p><strong>exist</strong></p>
<p>检查表是否存在：exist ‘hbase_student’</p>
</li>
<li><p><strong>is_enabled &#x2F; is_disabled</strong></p>
<p>检查表是否启用或禁用:</p>
<p>is_enabled ‘hbase_student’</p>
<p>is_disabled ‘hbase_student’</p>
</li>
<li><p><strong>alter</strong></p>
<p><strong>改变表和列族的模式</strong>：</p>
<p>为当前表增加列族：alter ‘hbase_student’, NAME &#x3D;&gt; ‘info2’, VERSIONS &#x3D;&gt; 2</p>
<p>为当前表删除列族：alter ‘hbase_student’, ‘delete’ &#x3D;&gt; ‘info2’</p>
</li>
<li><p><strong>disabled</strong></p>
<p>禁用一张表：disable ‘hbase_student’</p>
</li>
<li><p><strong>drop</strong></p>
<p>删除一张表：disable ‘hbase_student’；drop ‘hbase_student’；</p>
</li>
<li><p><strong>delete</strong></p>
<p>删除一行中一个单元格的值：delete ‘hbase_student’, ‘1001’, ‘info:name’</p>
<p> 表名 rowkey 列族:列名</p>
</li>
<li><p><strong>truncate</strong></p>
<p>清空表数据：disable ‘hbase_student’；truncate ‘hbase_student’；</p>
</li>
<li><p><strong>create</strong></p>
<p>创建表： create ‘table’,‘info’</p>
<p> 表名，列族名</p>
<p>创建多个族：</p>
<p>create ‘table’,{NAME &#x3D;&gt; ‘info1’}, {NAME &#x3D;&gt; ‘info2’}, {NAME &#x3D;&gt; ‘info3’}</p>
</li>
</ol>
<h2 id="6-数据的备份与恢复"><a href="#6-数据的备份与恢复" class="headerlink" title="6. 数据的备份与恢复"></a>6. 数据的备份与恢复</h2><h3 id="6-1-备份"><a href="#6-1-备份" class="headerlink" title="6.1 备份"></a>6.1 备份</h3><p>停止HBase服务后，使用distcp命令运行MapReduce任务进行备份，将数据备份到另一个地方，可以是同一个集群，也可以是专用的备份集群。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/hadoop distcp \</span><br><span class="line">hdfs://masterhost:8020/hbase \</span><br><span class="line">hdfs://masterhost:8020/HbaseBackup/backup20191016</span><br></pre></td></tr></table></figure>

<p><strong>PS: 执行该操作，一定要开启Yarn服务</strong></p>
<h3 id="6-2-恢复"><a href="#6-2-恢复" class="headerlink" title="6.2 恢复"></a>6.2 恢复</h3><p>跟备份方法一样，将数据整个移动回来即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/hadoop distcp \</span><br><span class="line">hdfs://masterhost:8020/HbaseBackup/backup20171016 \</span><br><span class="line">hdfs://masterhost:8020/hbase</span><br></pre></td></tr></table></figure>

<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>不一定所有的企业都会使用HBase，大数据的框架可以是相互配合相互依赖的，同时，根据不同的业务，部分框架之间的使用也可以是相互独立的。</p>
<p>例如有些企业在处理整个业务时，只是用HDFS+Spark部分的内容。</p>
<p>一定要有宏观思维，了解其框架特性，不一定非要在所有的业务中使用所有的框架，要具体情况具体分析，酌情选择。</p>
<h2 id="8-协处理器"><a href="#8-协处理器" class="headerlink" title="8. 协处理器"></a>8. 协处理器</h2><h3 id="8-1-简介"><a href="#8-1-简介" class="headerlink" title="8.1 简介"></a>8.1 简介</h3><h4 id="8-1-1-起源"><a href="#8-1-1-起源" class="headerlink" title="8.1.1 起源"></a>8.1.1 起源</h4><p>Hbase 作为列族数据库最经常被人诟病的特性包括：无法轻易建立“二级索引”，难以执 行求和、计数、排序等操作。</p>
<p>比如，在旧版本的(&lt;0.92)Hbase 中，统计数据表的总行数，需 要使用 Counter 方法，执行一次 MapReduce Job 才能得到。</p>
<p><strong>如果直接将计算过程放置在 server 端，能够减少通讯开销，从而获 得很好的性能提升。</strong></p>
<p>于是，HBase 在 0.92 之后引入了协处理器(coprocessors)，能够轻易<strong>建立二次索引</strong>、<strong>复杂过滤器(谓词下推)以及访问控制</strong>等。</p>
<h4 id="8-1-2-介绍"><a href="#8-1-2-介绍" class="headerlink" title="8.1.2 介绍"></a>8.1.2 介绍</h4><p>协处理器有两种：<strong>observer 和 endpoint</strong></p>
<p>　　<strong>Observer</strong> <strong>类似于传统数据库中的触发器</strong>，当发生某些事件的时候这类协处理器会被 Server 端调用。<strong>Observer Coprocessor</strong> 就是一些散布在 HBase Server 端代码中的 hook 钩子， 在固定的事件发生时被调用。</p>
<p>比如：put 操作之前有钩子函数 prePut，该函数在 put 操作执 行前会被 Region Server 调用；在 put 操作之后则有 postPut 钩子函数。</p>
<p>以 HBase0.92 版本为例，它提供了三种观察者接口：</p>
<p> <strong>RegionObserver</strong>：提供客户端的数据操纵事件钩子：<strong>Get</strong>、<strong>Put</strong>、<strong>Delete</strong>、<strong>Scan</strong> 等。</p>
<p> <strong>WALObserver</strong>：提供 WAL 相关操作钩子。</p>
<p> <strong>MasterObserver</strong>：提供 DDL-类型的操作钩子。如创建、删除、修改数据表等。</p>
<p> 到 0.96 版本又新增一个 <strong>RegionServerObserver</strong></p>
<p><strong>补充：WAL的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。</strong></p>
<p> <strong>Endpoint</strong> 协处理器类似传统数据库中的存储过程，客户端可以调用这些 Endpoint 协处 理器执行一段 Server 端代码，并将 Server 端代码的结果返回给客户端进一步处理，<strong>最常见 的用法就是进行聚集操作</strong>。</p>
<p> 如果没有协处理器，当用户需要找出一张表中的最大数据，即 max 聚合操作，就必须进行全表扫描，在客户端代码内遍历扫描结果，并执行求最大值的 操作。这样的方法无法利用底层集群的并发能力，而将所有计算都集中到 Client 端统一执行， 势必效率低下。</p>
<p> 利用 Coprocessor，用户可以将求最大值的代码部署到 HBase Server 端，HBase 将利用底层 cluster 的多个节点<strong>并发执行求最大值的操作</strong>。即在每个 Region 范围内执行求最大值的代码，将<strong>每个 Region 的最大值在 Region Server 端计算出</strong>，仅仅将该 max 值返回给客 户端。在<strong>客户端进一步将多个 Region 的最大值进一步处理而找到其中的最大值</strong>。</p>
<h4 id="8-1-3-协处理器原理"><a href="#8-1-3-协处理器原理" class="headerlink" title="8.1.3 协处理器原理"></a>8.1.3 协处理器原理</h4><p>以<em>observer</em> put请求为例：</p>
<p> 1、客户端发出 put 请求</p>
<p>　　2、该请求被分派给合适的 RegionServer 和 region</p>
<p>　　3、coprocessorHost 拦截该请求，然后在该表上登记的每个 RegionObserver 上调用 prePut()</p>
<p>　　4、如果没有被 prePut()拦截，该请求继续送到 region，然后进行处理</p>
<p>　　5、region 产生的结果再次被 CoprocessorHost 拦截，调用 postPut()</p>
<p>　　6、假如没有 postPut()拦截该响应，最终结果被返回给客户端</p>
<h4 id="8-1-4-总结"><a href="#8-1-4-总结" class="headerlink" title="8.1.4 总结"></a>8.1.4 总结</h4><p> <strong>Observer</strong> 允许集群在正常的客户端操作过程中可以有不同的行为表现</p>
<p>　　<strong>Endpoint</strong> 允许<strong>扩展集群的能力</strong>，对客户端应用开放新的运算命令</p>
<p>　　<strong>Observer</strong> 类似于 RDBMS 中的<strong>触发器</strong>，主要在服务端工作</p>
<p>　　<strong>Endpoint</strong> 类似于 RDBMS 中的<strong>存储过程</strong>，主要在服务端工作</p>
<p>　　</p>
<p> Observer 可以实现权限管理、优先级设置、监控、ddl 控制、<strong>二级索引</strong>等功能</p>
<p>　　Endpoint 可以实现 <strong>min、max、avg、sum、count、distinct、group by</strong> 等功能</p>
<h4 id="8-1-5-WAL"><a href="#8-1-5-WAL" class="headerlink" title="8.1.5 WAL"></a>8.1.5 WAL</h4><p><strong>WAL(Write-Ahead-Log)<strong>预写日志是Hbase的RegionServer在处理数据插入和删除的过程中用来</strong>记录操作内容的一种日志</strong>。</p>
<p>在每次Put、Delete等一条记录时，首先将其数据写入到RegionServer对应的HLog文件中去。</p>
<p>客户端向RegionServer端提交数据的时候，会先写入WAL日志，只有当WAL日志写入成功的时候，客户端才会被告诉提交数据成功。<strong>如果写WAL失败会告知客户端提交失败，这其实就是数据落地的过程。</strong></p>
<p>在一个RegionServer上的所有Region都共享一个HLog，一次数据的提交先写入WAL，写入成功后，再写入menstore之中。</p>
<p>当menstore的值达到一定的时候，就会形成一个StoreFile。</p>
<ul>
<li><p>HBase容错处理</p>
<p>WAL记载了每一个RegionServer对应的HLog。</p>
<p>RegionServer1或者RegionServer1上某一个regiong挂掉了，都会迁移到其它的机器上处理，重新操作，进行恢复。</p>
<p>当RegionServer意外终止的时候，Master会通过Zookeeper感知到，Master首先会处理遗留下来的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应的Region目录下，然后再将实效的Region重新分配，领取到这些Region的RegionMaster发现有历史的HLog需要处理，因此会Replay HLog的数据到Memstore之中，然后flush数据到StoreFiles，完成数据的恢复。</p>
</li>
<li><p>HBase和HDFS的关系</p>
<p>相同点：</p>
<ul>
<li>二者都具有良好的容错性和扩展性，都可以扩展成百千上万个结点</li>
</ul>
<p>不同点：</p>
<ul>
<li>HDFS<strong>适合批处理场景</strong>。</li>
<li>HDFS<strong>不支持数据的随机查找</strong>、<strong>不适合增量数据处理</strong>、<strong>不支持数据更新</strong>。</li>
</ul>
<p>关系：</p>
<ul>
<li>Hbase内存管理的所有文件都存储在HDFS之中。</li>
</ul>
</li>
</ul>
<h3 id="8-2-协处理器的加载方式"><a href="#8-2-协处理器的加载方式" class="headerlink" title="8.2 协处理器的加载方式"></a>8.2 协处理器的加载方式</h3><p>协处理器的加载方式有两种，我们称之为<strong>静态加载方式（Static Load）和动态加载方式 （Dynamic Load）</strong>。</p>
<p>静态加载的协处理器称之为 <strong>System Coprocessor</strong>，动态加载的协处理器称 之为 <strong>Table Coprocessor</strong>。</p>
<h4 id="8-2-1-静态加载"><a href="#8-2-1-静态加载" class="headerlink" title="8.2.1 静态加载"></a>8.2.1 静态加载</h4><p>通过修改hbase-site.xml 这个文件实现，启动全局的aggregation, 能够操作所有表上的数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;	</span><br><span class="line">	&lt;name&gt;hbase.coprocessor.user.region.classes&lt;/name&gt;	</span><br><span class="line">	&lt;value&gt;org.apache.hadoop.hbase.coprocessor.AggregateImplementation&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>为所有 table 加载了一个 cp class，可以用”,”分割加载多个 class。</p>
<h4 id="8-2-2-动态加载"><a href="#8-2-2-动态加载" class="headerlink" title="8.2.2 动态加载"></a>8.2.2 动态加载</h4><p>启用表 aggregation，只对特定的表生效。通过 HBase Shell 来实现。</p>
<ol>
<li><p>停用表　　disable ‘tablename’</p>
</li>
<li><p>添加协处理器　　</p>
<p>alter ‘tablename’, METHOD &#x3D;&gt; ‘table_att’, ‘coprocessor’ &#x3D;&gt; ‘hdfs:&#x2F;&#x2F;myha01&#x2F;hbase&#x2F;guanzhu.jar|com.hypers.insight.HbaseCoprocessorTest|1001|’</p>
</li>
<li><p>启用表　　enable ‘tablename’</p>
</li>
</ol>
<h4 id="8-2-3-协处理器卸载"><a href="#8-2-3-协处理器卸载" class="headerlink" title="8.2.3 协处理器卸载"></a>8.2.3 协处理器卸载</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable &#x27;mytable&#x27;</span><br><span class="line"></span><br><span class="line">alter &#x27;mytable&#x27;,METHOD=&gt;&#x27;table_att_unset&#x27;,NAME=&gt;&#x27;coprocessor$1&#x27;</span><br><span class="line"></span><br><span class="line">enable &#x27;mytable&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-Endpoint"><a href="#8-3-Endpoint" class="headerlink" title="8.3 Endpoint"></a>8.3 Endpoint</h3><ul>
<li>与Observer类型不同的是，<strong>Endpoint协处理器需要与服务区直接通信</strong>，服务端是对于Protobuf Service的实现，所以两者直接会有一个基于protocl的RPC接口，客户端和服务端都需要进行基于接口的代码逻辑实现。</li>
<li>不同于Observer协处理器，EndPoint由于需要同region进行rpc服务的通信，以及客户端出数据的归并，需要自行实现客户端代码。</li>
<li></li>
</ul>
<h3 id="8-4-关于二级索引"><a href="#8-4-关于二级索引" class="headerlink" title="8.4 关于二级索引"></a>8.4 关于二级索引</h3><ul>
<li><p>HBase的局限性</p>
<p>HBase本身<strong>只提供基于行键和全表扫描的查询</strong>，而<strong>行键索引单一</strong>，对于多维度的查询困难。</p>
</li>
<li><p>常见的二级索引方案</p>
<p>HBase的<strong>一级索引</strong>就是<strong>rowkey</strong>，我们只能通过rowkey进行检索。如果我们相对HBase里面列族的<strong>列列进行一些组合查询</strong>，就<strong>需要采用HBase的二级索引方案</strong>来进行多条件的查询。</p>
<ul>
<li><p>MapReduce 方案</p>
<p><a href="https://blog.csdn.net/wypersist/article/details/79830811">https://blog.csdn.net/wypersist/article/details/79830811</a></p>
</li>
<li><p>ITHBASE（Indexed-Transanctional HBase）方案</p>
</li>
<li><p>IHBASE（Index HBase）方案</p>
</li>
<li><p>Hbase Coprocessor(协处理器)方案</p>
</li>
<li><p>Solr+hbase方案</p>
</li>
<li><p>CCIndex（complementalclustering index）方案</p>
</li>
</ul>
</li>
</ul>
<p>这里主要学习Hbase Coprocessor(协处理器)方案 。</p>
<p><strong>二级索引的本质就是建立各列值与行键之间的映射关系</strong></p>
<p><a href="20220710-4.jpg"><img src="/../../../../images/20220710-4.jpg" alt="20220710-4.jpg"></a></p>
<p>如上图1，当要对F:C1这列建立索引时，只需要建立F:C1各列值到其对应行键的映射关系，如C11-&gt;RK1等（第二张表），这样就完成了对F:C1列值的二级索引的构建。</p>
<p>当要查询符合F:C1&#x3D;C11对应的F:C2的列值时（即根据C1&#x3D;C11来查询C2的值,第三张表青色部分）</p>
<p>其查询步骤如下：</p>
<ul>
<li>根据C1&#x3D;C11到索引数据中查找其对应的RK，查询得到其对应的RK&#x3D;RK1</li>
<li>得到RK1后就自然能根据RK1来查询C2的值了 这是构建二级索引大概思路，其他组合查询的联合索引的建立也类似。</li>
</ul>
<p><strong>HBase在0.92之后引入了coprocessors，提供了一系列的钩子，让我们能够轻易实现访问控制和二级索引的特性。</strong></p>
<h2 id="9-案例1（observer二级索引）"><a href="#9-案例1（observer二级索引）" class="headerlink" title="9. 案例1（observer二级索引）"></a>9. 案例1（observer二级索引）</h2><p>该例子使用RegionObserver实现在<strong>写主表之前将索引数据先写到另外一个表</strong></p>
<p>相当于表一添加，触发表二信息的添加或者更新</p>
<p>以关注表，粉丝表为例。</p>
<p>关注表：zhangsan 关注了 gulinazha</p>
<p>粉丝表：zhangsan 是gulinazha 的粉丝</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">put &#x27;insight:bonaGuanzhu&#x27;, &#x27;zhangsan&#x27;, &#x27;cf:star&#x27;, &#x27;gulinazha&#x27;</span><br><span class="line">put &#x27;insight:bonaFans&#x27;, &#x27;gulinazha&#x27;, &#x27;cf:fensi&#x27;, &#x27;zhangsan&#x27; //触发添加</span><br></pre></td></tr></table></figure>

<ol>
<li>java实现代码</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.xxx.bona;</span><br><span class="line"></span><br><span class="line">import java.util.*;import java.io.IOException;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.client.Table;</span><br><span class="line">import org.apache.hadoop.hbase.*;</span><br><span class="line">import org.apache.hadoop.hbase.client.Durability;</span><br><span class="line">import org.apache.hadoop.hbase.regionserver.wal.WALEdit;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.ObserverContext;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;</span><br><span class="line"></span><br><span class="line">public class HbaseCoprocessorTest extends BaseRegionObserver&#123;    </span><br><span class="line">	static Connection connection;    </span><br><span class="line">	static Configuration configuration;    </span><br><span class="line">	static Table table = null;    </span><br><span class="line">	static &#123;        </span><br><span class="line">		configuration = HBaseConfiguration.create();        </span><br><span class="line">		configuration.addResource(&quot;hbase-site.xml&quot;);        </span><br><span class="line">		try &#123;            </span><br><span class="line">			// 取得一个数据库连接对象            </span><br><span class="line">			connection = ConnectionFactory.createConnection(configuration);        </span><br><span class="line">		&#125; catch (IOException e) &#123;            </span><br><span class="line">			e.printStackTrace();        </span><br><span class="line">		&#125;    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	/***     </span><br><span class="line">	* 此方法是在put方法调用之前进行调用     </span><br><span class="line">	* @param e     </span><br><span class="line">	* @param put 是要进行插入的那条数据     </span><br><span class="line">	* @param edit     </span><br><span class="line">	* @param durability     </span><br><span class="line">	* @throws IOException     </span><br><span class="line">	*/    </span><br><span class="line">	@Override    </span><br><span class="line">	public void prePut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, </span><br><span class="line">	WALEdit edit, Durability durability) throws IOException &#123;        </span><br><span class="line">		//获取put对象里面的rowkey&#x27;zhangsan&#x27;        </span><br><span class="line">		byte[] row = put.getRow();        </span><br><span class="line">		table = connection.getTable(TableName.valueOf(&quot;test:bonaFans&quot;));        </span><br><span class="line">		//获取put对象里面的cell        </span><br><span class="line">		List&lt;Cell&gt; list = put.get(&quot;cf&quot;.getBytes(), &quot;star&quot;.getBytes());        </span><br><span class="line">		Cell cell = list.get(0);        </span><br><span class="line">		//创建一个新的put对象        </span><br><span class="line">		Put new_put = new Put(cell.getValueArray());        </span><br><span class="line">		new_put.addColumn(&quot;cf&quot;.getBytes(), &quot;fensi&quot;.getBytes(), row);        </span><br><span class="line">		table.put(new_put);        </span><br><span class="line">		connection.close();    </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>打包成jar, 重命名为 guanzhu.jar 并上传HDFS目录&#x2F;bona&#x2F;hbase下面</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -put guanzhu.jar /bona/hbase</span><br></pre></td></tr></table></figure>


</li>
<li><p>打开 hbase shell</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable &#x27;test:bonaGuanzhu&#x27;</span><br><span class="line"></span><br><span class="line">alter &#x27;test:bonaGuanzhu&#x27;, METHOD =&gt; &#x27;table_att&#x27;, &#x27;coprocessor&#x27; =&gt; &#x27;hdfs://nameserve1/bona/hbase/guanzhu.jar|com.xxx.bona.HbaseCoprocessorTest|1001|&#x27;</span><br><span class="line"></span><br><span class="line">enable &#x27;test:bonaGuanzhu&#x27;</span><br><span class="line"></span><br><span class="line">desc &#x27;test:bonaGuanzhu&#x27;</span><br><span class="line">put &#x27;test:bonaGuanzhu&#x27;, &#x27;zhangsan&#x27;, &#x27;cf:star&#x27;, &#x27;gulinazha&#x27;</span><br><span class="line"></span><br><span class="line">scan &#x27;test:bonaGuanzhu&#x27;</span><br><span class="line">scan &#x27;test:bonaFans&#x27;</span><br><span class="line"></span><br><span class="line">卸载协处理器</span><br><span class="line">disable &#x27;test:bonaGuanzhu&#x27;</span><br><span class="line">alter &#x27;test:bonaGuanzhu&#x27;,METHOD=&gt;&#x27;table_att_unset&#x27;,NAME=&gt;&#x27;coprocessor$1&#x27;</span><br><span class="line">enable &#x27;test:bonaGuanzhu&#x27;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="10-案例2（observer-读写分离）"><a href="#10-案例2（observer-读写分离）" class="headerlink" title="10. 案例2（observer,读写分离）"></a>10. 案例2（observer,读写分离）</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">假定某个表 test:bonaRW 有A和B两个列1. 当我们向A列插入数据的时候通过协处理器像B列也插入数据。2.在读取数据的时候只允许客户端读取B列数据而不能读取A列数据。换句话说A列是只写 B列是只读的。（为了简单起见，用户在读取数据的时候需要制定列名）3. A列值必须是整数，换句话说B列值也自然都是整数4.当删除操作的时候不能指定删除B列5.当删除A列的时候同时需要删除B列6.对于其他列的删除不做检查</span><br></pre></td></tr></table></figure>

<p>代码见github. <a href="https://www.cnblogs.com/ios123/p/6370724.html">https://www.cnblogs.com/ios123/p/6370724.html</a></p>
<h2 id="11-案例3（endpoint）"><a href="#11-案例3（endpoint）" class="headerlink" title="11. 案例3（endpoint）"></a>11. 案例3（endpoint）</h2><p>准备工作参考：<a href="https://blog.csdn.net/hp_cpp/article/details/81561310">https://blog.csdn.net/hp_cpp/article/details/81561310</a></p>
<p>实例参考：<a href="https://www.cnblogs.com/ios123/p/6379407.html">https://www.cnblogs.com/ios123/p/6379407.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">完成hbase表 test:bona_endpoint 表的count,max,min,sum,avg</span><br><span class="line">通过代码的方式实现 协处理器的添加，使用，删除主要分为5个步骤：	1.环境准备（使用Protobuf 生成序列化类）	2.Endpoint Coprocessor服务端实现	3.Endpoint Coprocessor客户端实现	4.部署以及调用</span><br></pre></td></tr></table></figure>

<h3 id="11-1-环境准备"><a href="#11-1-环境准备" class="headerlink" title="11.1 环境准备"></a>11.1 环境准备</h3><p>HBase在HMaster、RegionServer内部，创建了RpcServer实例，并可与Client三者之间实现了Rpc调用。</p>
<p>HBase0.95版本引入了Google-Protobuf作为中间数据组织方式，并在Protobuf提供的Rpc接口之上，实现了基于服务的Rpc实现。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Protobuf Buffers是一种轻便高效的结构化数据存储格式，可以用于数据序列化。适合做数据存储或RPC数据交换格式。用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。</span><br></pre></td></tr></table></figure>

<ul>
<li><p>下载Protobuf2.5.0版本的安装包。因此maven环境使用的是2.5.0，因此这里需要和项目的版本对应哦。</p>
</li>
<li><pre><code>https://github.com/protocolbuffers/protobuf/releases/tag/v2.5.0
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- win10 下解压到指定目录，这里用root表示</span><br><span class="line"></span><br><span class="line">- 准备HBase测试表，建表脚本及测试数据如下</span><br><span class="line"></span><br><span class="line">- ```</span><br><span class="line">  这里使用代码添加 见github：https://github.com/fenghuayangyi/hbasedemo/blob/master/src/main/java/com/hypers/insight/HbaseTest.java</span><br><span class="line">  </span><br><span class="line">  createTable(&quot;test:bona_endpoint&quot;, &quot;info&quot;);</span><br><span class="line">  </span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;001&quot;,&quot;info&quot;,&quot;sales&quot;,&quot;15.5&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;002&quot;,&quot;info&quot;,&quot;sales&quot;,&quot;12.8&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;003&quot;,&quot;info&quot;,&quot;sales&quot;,&quot;13.5&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;004&quot;,&quot;info&quot;,&quot;sales&quot;,&quot;11.0&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;005&quot;,&quot;info&quot;,&quot;sales&quot;,&quot;9.5&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;001&quot;,&quot;info&quot;,&quot;age&quot;,&quot;27&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;002&quot;,&quot;info&quot;,&quot;age&quot;,&quot;28&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;003&quot;,&quot;info&quot;,&quot;age&quot;,&quot;26&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;004&quot;,&quot;info&quot;,&quot;age&quot;,&quot;33&quot;);</span><br><span class="line">  addRowData(&quot;test:bona_endpoint&quot;,&quot;005&quot;,&quot;info&quot;,&quot;age&quot;,&quot;36&quot;);</span><br><span class="line">  </span><br><span class="line">  也可以通过 hbase shell:</span><br><span class="line">  create &#x27;test:bona_endpoint&#x27;</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;001&#x27;,&#x27;info:sales&#x27;,15.5</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;002&#x27;,&#x27;info:sales&#x27;,12.8</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;003&#x27;,&#x27;info:sales&#x27;,13.5</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;004&#x27;,&#x27;info:sales&#x27;,11.0</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;005&#x27;,&#x27;info:sales&#x27;,9.5</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;001&#x27;,&#x27;info:age&#x27;,27</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;002&#x27;,&#x27;info:age&#x27;,28</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;003&#x27;,&#x27;info:age&#x27;,26</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;004&#x27;,&#x27;info:age&#x27;,33</span><br><span class="line">  put &#x27;test:bona_endpoint&#x27;,&#x27;005&#x27;,&#x27;info:age&#x27;,36</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
<li><p>使用Protobuf生成序列化类</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.准备MyFirstCoprocessor.proto文件,放到root/bin目录下 </span><br><span class="line">见githubhttps://github.com/fenghuayangyi/hbasedemo/blob/master/src/filebackup/MyFirstCoprocessor.proto</span><br><span class="line"></span><br><span class="line">2.进入cmd命令行,切换到root/bin目录，执行如下命令生成Java类</span><br><span class="line">protoc --java_out=./ MyFirstCoprocessor.proto</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="11-2-Endpoint-Coprocessor服务端实现"><a href="#11-2-Endpoint-Coprocessor服务端实现" class="headerlink" title="11.2 Endpoint Coprocessor服务端实现"></a>11.2 Endpoint Coprocessor服务端实现</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.maven中添加依赖 见github主要涉及：</span><br><span class="line">hadoop-client,</span><br><span class="line">hadoop-common,</span><br><span class="line">hbase-client,</span><br><span class="line">hbase-examples,</span><br><span class="line">protobuf-java</span><br><span class="line"></span><br><span class="line">2.将root/bin目录下生成的类拷贝到指定的package目录下。</span><br><span class="line">与.proto文件指定的java_package包目录一致。</span><br><span class="line"></span><br><span class="line">3.新建server包，在包下新建MyFirstCoprocessorEndpoint实现类 内容见githubhttps://github.com/fenghuayangyi/hbasedemo/blob/master/src/main/java/com/hypers/insight/hbaseendpoint/server/MyFirstCoprocessorEndPoint.java</span><br></pre></td></tr></table></figure>

<h3 id="11-3-Endpoint-Coprocessor客户端实现"><a href="#11-3-Endpoint-Coprocessor客户端实现" class="headerlink" title="11.3 Endpoint Coprocessor客户端实现"></a>11.3 Endpoint Coprocessor客户端实现</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">新建client包，在包下新建MyFirstCoprocessExample.java 内容见githubhttps://github.com/fenghuayangyi/hbasedemo/blob/master/src/main/java/com/hypers/insight/hbaseendpoint/client/MyFirstCoprocessExample.java</span><br></pre></td></tr></table></figure>

<h3 id="11-4-部署以及调用"><a href="#11-4-部署以及调用" class="headerlink" title="11.4 部署以及调用"></a>11.4 部署以及调用</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.maven 编译代码</span><br><span class="line"></span><br><span class="line">2.将编译好的代码上传到hdfs指定目录    先将jar通过FZ传到hadoop的master node,然后将其传到hdfs指定目录 </span><br><span class="line">    hadoop fs -mkdir -p /bona/hbase    </span><br><span class="line">	hadoop fs -put /.../bona/hbasedemo-1.0-SNAPSHOT.jar /bona/hbase/hbasedemo-1.0-SNAPSHOT.jar    </span><br><span class="line">	hadoop fs -ls /bona/hbase</span><br><span class="line">	</span><br><span class="line">3.运行MyFirstCoprocessorExample代码，查看运行结果。校验结果的正确性。</span><br></pre></td></tr></table></figure>

<h3 id="11-5-总结"><a href="#11-5-总结" class="headerlink" title="11.5 总结"></a>11.5 总结</h3><p>开发HBase的Endpoint Coprocessor借助于Protobuf生成RPC请求数据交互类，我们只需要在生成的类基础上实现业务即可。</p>
<p>HBase自带的也有AggregateImplementation类实现列的聚合，原生的不能同时对多个列进行聚合处理，如果需要多次聚合则需要多次调用RPC请求，HBase数据在<strong>不断的写入会出现每次聚合的结果有偏差</strong>，本示例<strong>将聚合放在一个RPC中处理可以减少RPC的请求次数并确保查询条件相同的情况下不会出现数据不一致问题</strong>。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HiveSQL</title>
    <url>/2019/04/22/Hive-SQL/</url>
    <content><![CDATA[<h1 id="Hive-SQL总结"><a href="#Hive-SQL总结" class="headerlink" title="Hive SQL总结"></a>Hive SQL总结</h1><h2 id="1-自带-function-的使用"><a href="#1-自带-function-的使用" class="headerlink" title="1. 自带 function 的使用"></a>1. 自带 function 的使用</h2><p>使用<code>show functions;</code> 命令进行查看目前可以使用的function;</p>
<p>使用如下命令查看使用方法 split为例：</p>
<ul>
<li>desc function extended split;</li>
</ul>
<h2 id="2-常用func"><a href="#2-常用func" class="headerlink" title="2. 常用func"></a>2. 常用func</h2><ul>
<li><p>LIKE</p>
<p>A LIKE B</p>
<p>如果字符串A或者字符串B为NULL，则返回NULL；如果字符串A符合表达式B的正则语法，则为TRUE；否则为FALSE。B中字符”_”表示任意单个字符，而字符”%”表示任意数量的字符。</p>
</li>
<li><p>RLIKE &#x2F; REGEXP 二者等价</p>
<p>A RLIKE B</p>
<p>如果字符串A或者字符串B为NULL，则返回NULL；如果字符串A符合JAVA正则表达式B的正则语法，则为TRUE；否则为FALSE。</p>
<p>例：select 1 from dual where ‘footbar’ rlike ‘^f.*r$’</p>
</li>
<li><p>+、-、*、&#x2F; 、% 加 减 乘 除 取余 操作</p>
</li>
<li><p>&amp;、|、~、^ 与或非，异或操作</p>
</li>
<li><p>复合类型</p>
<p>map, struct, array</p>
</li>
<li><p>round(double a) 取整函数 四舍五入</p>
</li>
<li><p>round(double a, int d) 返回指定精度d的double类型</p>
</li>
<li><p>floor(double a) 向下取整函数</p>
</li>
<li><p>ceiling &#x2F; ceil(double a) 向上取整函数</p>
</li>
<li><p>power &#x2F; pow(double a, double p) 返回a的p次幂</p>
</li>
<li><p>from_unixtime(1323308943,’yyyyMMdd’) 时间戳转日期函数</p>
</li>
<li><p>unix_timestamp() 当前UNIX时间戳</p>
</li>
<li><p>unix_timestamp(’2011-12-07 13:01:03′) 日期转UNIX时间戳</p>
</li>
<li><p>unix_timestamp(’20111207 13:01:03′,’yyyyMMdd HH:mm:ss’) 指定格式日期转UNIX时间戳</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">【hive 日期转换】Hive中yyyymmdd和yyyy-mm-dd日期之间的切换</span><br><span class="line">方法1: from_unixtime+ unix_timestamp</span><br><span class="line"></span><br><span class="line">--20171205转成2017-12-05 </span><br><span class="line">select from_unixtime(unix_timestamp(&#x27;20171205&#x27;,&#x27;yyyymmdd&#x27;),&#x27;yyyy-mm-dd&#x27;) from dual;</span><br><span class="line"></span><br><span class="line">--2017-12-05转成20171205</span><br><span class="line">select from_unixtime(unix_timestamp(&#x27;2017-12-05&#x27;,&#x27;yyyy-mm-dd&#x27;),&#x27;yyyymmdd&#x27;) from dual;</span><br><span class="line"></span><br><span class="line">方法2: substr + concat</span><br><span class="line">--20171205转成2017-12-05 </span><br><span class="line">select concat(substr(&#x27;20171205&#x27;,1,4),&#x27;-&#x27;,substr(&#x27;20171205&#x27;,5,2),&#x27;-&#x27;,substr(&#x27;20171205&#x27;,7,2)) from dual;</span><br><span class="line"></span><br><span class="line">--2017-12-05转成20171205</span><br><span class="line">select concat(substr(&#x27;2017-12-05&#x27;,1,4),substr(&#x27;2017-12-05&#x27;,6,2),substr(&#x27;2017-12-05&#x27;,9,2)) from dual;</span><br></pre></td></tr></table></figure>


</li>
<li><p>to_date(’2011-12-08 10:03:01′)日期时间转 日期 out:2011-12-08</p>
</li>
<li><p>year(’2011-12-08 10:03:01′) 日期转年 可以直接做加减</p>
</li>
<li><p>month(’2011-08-08′)</p>
</li>
<li><p>day(’2011-12-24′)</p>
</li>
<li><p>hour(’2011-12-08 10:03:01′)</p>
</li>
<li><p>minute(’2011-12-08 10:03:01′)</p>
</li>
<li><p>second(’2011-12-08 10:03:01′)</p>
</li>
<li><p>weekofyear(’2011-12-08 10:03:01′)</p>
</li>
<li><p>datediff(’2012-12-08′,’2012-05-09′) 日期差</p>
</li>
<li><p>date_add(’2012-12-08′,10) 日期增加</p>
</li>
<li><p>date_sub(’2012-12-08′,10) 日期减少</p>
</li>
<li><p>if(1&#x3D;2,100,200) 条件函数 out:200</p>
</li>
<li><p>COALESCE(null,’100′,’50′) 非空查找 out:100</p>
</li>
<li><p><strong>条件判断函数1：CASE</strong></p>
<p>语法: CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END</p>
<p>如果a等于b，那么返回c；如果a等于d，那么返回e；否则返回f</p>
<p>例：Select case 100 when 50 then ‘tom’ when 100 then ‘mary’ else ‘tim’ end from dual;</p>
</li>
<li><p><strong>条件判断函数2：CASE</strong></p>
<p>语法: CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END</p>
<p>如果a为TRUE,则返回b；如果c为TRUE，则返回d；否则返回e</p>
<p>例如：select case when 1&#x3D;2 then ‘tom’ when 2&#x3D;2 then ‘mary’ else ‘tim’ end from dual;</p>
</li>
<li><p>length(string A) 字符串长度</p>
</li>
<li><p>reverse(string A) 字符串反转</p>
</li>
<li><p><strong>字符串连接函数：concat</strong></p>
<p>concat(string A, string B…)</p>
</li>
<li><p><strong>带分隔符字符串连接函数：concat_ws</strong></p>
<p>concat_ws(string SEP, string A, string B…)</p>
<p>例如：concat_ws(‘,’,’abc’,’def’,’gh’)</p>
</li>
<li><p><strong>字符串截取函数：substr,substring</strong></p>
<p>substr(‘abcde’,3) out:abc</p>
<p>substr(‘abcde’,-1) out:e</p>
<p>substr(string A, int start, int len),substring(string A, int start, int len)</p>
</li>
<li><p>字符串转小写函数：lower,lcase</p>
<p>lower(string A) lcase(string A)</p>
</li>
<li><p>去空格函数：trim</p>
<p>trim(string A)</p>
<p>左边去空格函数：ltrim</p>
<p>右边去空格函数：rtrim</p>
</li>
<li><p>正则表达式替换函数：regexp_replace</p>
<p>regexp_replace(string A, string B, string C)</p>
<p>将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符</p>
<p>regexp_replace(‘foobar’, ‘oo|ar’, ”) out:fb</p>
</li>
<li><p>保留两位小数</p>
<p>cast(column_name as decimal(10,2)) cast函数截取（推荐使用）</p>
</li>
<li><p><strong>列转行</strong> （collect_all() &#x2F; collect_list() 不去重）、（collect_set去重） 一般与concat_ws连用，带分隔符</p>
<p>select col1, concat_ws(‘,’, collect_set(col2))<br>from tb_name<br>group by col1;</p>
</li>
</ul>
<h2 id="3-hive使用细节记录"><a href="#3-hive使用细节记录" class="headerlink" title="3.hive使用细节记录"></a>3.hive使用细节记录</h2><ul>
<li>union <strong>Hive在1.2.0之前的版本只支持union all，在1.2.0之后的版本才支持union.</strong></li>
</ul>
<h1 id="sql记录"><a href="#sql记录" class="headerlink" title="sql记录"></a>sql记录</h1><h2 id="1-mysql分组高阶"><a href="#1-mysql分组高阶" class="headerlink" title="1. mysql分组高阶"></a>1. mysql分组高阶</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">purchase表</span><br><span class="line"></span><br><span class="line">字段有id,pkg,time,item,currency,usd,dt</span><br><span class="line">玩家id,游戏包名，交易完成时间,购买礼包id,交易币种,成交金额,交易日期</span><br><span class="line"></span><br><span class="line">求5月每个玩家最早的三次付费item和金额</span><br><span class="line"></span><br><span class="line">SET @num=1;</span><br><span class="line">SET @last_id=0;</span><br><span class="line">SELECT id, 1_item,1_usd,IFNULL(2_item,null) 2_item,IFNULL(2_usd,0) 2_usd,IFNULL(3_item,null) 3_item,IFNULL(3_usd,0) 3_usd </span><br><span class="line">FROM (	</span><br><span class="line">	select 	</span><br><span class="line">	id,	</span><br><span class="line">	GROUP_CONCAT(if(seq=1,item,NULL)) AS 1_item,	</span><br><span class="line">	GROUP_CONCAT(if(seq=1,usd,NULL)) AS 1_usd,	</span><br><span class="line">	GROUP_CONCAT(if(seq=2,item,NULL)) AS 2_item,	</span><br><span class="line">	GROUP_CONCAT(if(seq=2,usd,NULL)) AS 2_usd,	</span><br><span class="line">	GROUP_CONCAT(if(seq=3,item,NULL)) AS 3_item,	</span><br><span class="line">	GROUP_CONCAT(if(seq=3,usd,NULL)) AS 3_usd	</span><br><span class="line">	from(		</span><br><span class="line">		SELECT t1.*,IF(@last_id=id,@num:=@num+1,@num:=1) AS seq,		</span><br><span class="line">		(@last_id:=id) AS tmp </span><br><span class="line">		FROM (		</span><br><span class="line">		SELECT id,time,item,usd 		</span><br><span class="line">		FROM purchase 		</span><br><span class="line">		where month(time)=5 		</span><br><span class="line">		GROUP BY id ASC,time ASC		</span><br><span class="line">		) t1	</span><br><span class="line">	)t2 </span><br><span class="line">	GROUP BY id </span><br><span class="line">) t3</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker手册</title>
    <url>/2020/03/12/Docker%E6%89%8B%E5%86%8C/</url>
    <content><![CDATA[<h1 id="1-安装Docker"><a href="#1-安装Docker" class="headerlink" title="1. 安装Docker"></a>1. 安装Docker</h1><h2 id="1-Mac安装Docker"><a href="#1-Mac安装Docker" class="headerlink" title="1. Mac安装Docker"></a>1. Mac安装Docker</h2><p><a href="https://www.runoob.com/docker/macos-docker-install.html">https://www.runoob.com/docker/macos-docker-install.html</a></p>
<h2 id="2-Window安装Docker"><a href="#2-Window安装Docker" class="headerlink" title="2. Window安装Docker"></a>2. Window安装Docker</h2><p>安装Docker Desktop for Windows 后可以使用docker<br>安装连接<br><a href="https://www.runoob.com/docker/windows-docker-install.html">https://www.runoob.com/docker/windows-docker-install.html</a><br>Docker Desktop for Windows下载连接<br><a href="https://hub.docker.com/editions/community/docker-ce-desktop-windows/">https://hub.docker.com/editions/community/docker-ce-desktop-windows/</a></p>
<h2 id="3-CentOS7上安装Docker"><a href="#3-CentOS7上安装Docker" class="headerlink" title="3.CentOS7上安装Docker"></a>3.CentOS7上安装Docker</h2><p>官方安装手册 <a href="https://docs.docker.com/engine/install/centos/">https://docs.docker.com/engine/install/centos/</a></p>
<p>1、Docker要求CentOS 系统内核版本高于3.10.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使用  uname -r 查看当前内核版本</span><br><span class="line"></span><br><span class="line">另外：</span><br><span class="line">查看Linux系统发行版本，该命令适用于所有Linux系统, 命令: </span><br><span class="line">lsb_release -a </span><br></pre></td></tr></table></figure>



<p>2、使用 root 登录 CentOS, 确保yum 包更新到最新</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum update</span><br></pre></td></tr></table></figure>

<p>3、卸载旧版本（如果安装版本过旧）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker docker-common docker-selinux docker-engine</span><br></pre></td></tr></table></figure>

<p>4、安装需要的软件包， yum util 提供 yum-config-manager 的功能，另外两个是device-mapper驱动依赖的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></table></figure>

<p>5、设置yum源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">推荐阿里云</span><br><span class="line">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line">官方源</span><br><span class="line">sudo yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>6、查看所有仓库中的Docker版本，并选择特定版本安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure>

<p>7、 安装Docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce #安装最新stable版</span><br><span class="line">或者</span><br><span class="line">sudo yum install &lt;FQPN&gt; #例如： sudo yum install docker-ce-17.12.1</span><br></pre></td></tr></table></figure>

<p>8 、 查看docker 版本信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker version</span><br><span class="line"></span><br><span class="line"># docker随系统启动</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">sudo systemctl start docker</span><br><span class="line"></span><br><span class="line"># 查看yum库 jdk相关</span><br><span class="line">yum search jdk</span><br></pre></td></tr></table></figure>



<h1 id="2-Docker-常用命令"><a href="#2-Docker-常用命令" class="headerlink" title="2. Docker 常用命令"></a>2. Docker 常用命令</h1><h2 id="1-镜像相关"><a href="#1-镜像相关" class="headerlink" title="1. 镜像相关"></a>1. 镜像相关</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过命令 docker command --help 更深入的了解指定的 Docker 命令</span><br><span class="line"></span><br><span class="line">查看 docker stats 指令的具体使用方法</span><br><span class="line">docker stats --help</span><br><span class="line"></span><br><span class="line">查看docker的版本</span><br><span class="line">docker version</span><br><span class="line"></span><br><span class="line">列出镜像</span><br><span class="line">docker images</span><br><span class="line">docker images ls   # 列出最后一次使用镜像</span><br><span class="line"></span><br><span class="line">修改image tag</span><br><span class="line">docker tag imageTagName newName</span><br><span class="line"></span><br><span class="line">获取镜像</span><br><span class="line">docker pull NAME[：TAG]    # 不显式地指定TAG，则默认会选择latest标签</span><br><span class="line"></span><br><span class="line">搜索镜像-[搜索的范围是官方镜像和所有个人公共镜像。NAME列]</span><br><span class="line">docker search name</span><br><span class="line"></span><br><span class="line">#删除镜像</span><br><span class="line">docker rmi &lt;imageId&gt;</span><br><span class="line"></span><br><span class="line">#使用镜像tag删除镜像</span><br><span class="line">docker rmi [REPOSITORY：TAG]</span><br><span class="line"></span><br><span class="line">#导出本地镜像-[该命令支持-o、-output string参数，导出镜像到指定的文件中]</span><br><span class="line">docker [image] save</span><br><span class="line">ex:导出本地的 bona_centos:latest镜像为文件 bona_centos.tar</span><br><span class="line">docker save -o bona_centos.tar bona_centos:latest</span><br><span class="line"></span><br><span class="line">#载入镜像-[导入镜像及其相关的元数据信息（包括标签等）]</span><br><span class="line">docker load -i bona_centos.tar</span><br></pre></td></tr></table></figure>

<h2 id="2-容器相关"><a href="#2-容器相关" class="headerlink" title="2. 容器相关"></a>2. 容器相关</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#docker run：启动容器</span><br><span class="line">    #-i: 交互式操作。</span><br><span class="line">    #-t: 终端。</span><br><span class="line">    #--name 给容器命名 后面跟的是容器名称</span><br><span class="line">    #adsfg1234: 镜像id</span><br><span class="line">    #/bin/bash：放在镜像id后表示希望有个交互式 Shell</span><br><span class="line">    #docker中必须要保持一个进程的运行，不然容器启动后就会马上kill itself</span><br><span class="line">    #这个/bin/bash就表示启动容器后启动bash。</span><br><span class="line"> </span><br><span class="line">	docker run -it --name testcontanier adsfg1234 /bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看容器的信息container（ps）</span><br><span class="line">    #默认显示当前正在运行中的container</span><br><span class="line">    docker ps</span><br><span class="line"></span><br><span class="line">    #查看所有，包括已经停止的所有容器</span><br><span class="line">    docker ps -a</span><br><span class="line"></span><br><span class="line">    #显示最新启动的一个容器（包括已停止的）</span><br><span class="line">    docker ps -l</span><br><span class="line"></span><br><span class="line">#进入容器进行操作</span><br><span class="line">    docker start testcontanier</span><br><span class="line">    docker attach testcontanier</span><br><span class="line"></span><br><span class="line">#删除容器</span><br><span class="line">	docker rm container_name</span><br><span class="line"></span><br><span class="line">#查看container 日志</span><br><span class="line">    #显示更多的信息</span><br><span class="line">    docker logs --details container_name/container_id</span><br><span class="line"></span><br><span class="line">    #显示自具体某个时间或时间段的日志</span><br><span class="line">    docker logs --since=&lt;date&gt; container_name/container_id</span><br><span class="line"></span><br><span class="line">    #从日志末尾显示多少行日志， 默认是all</span><br><span class="line">    docker logs  --tail &lt;num&gt; container</span><br><span class="line"></span><br><span class="line">    #查看容器zzzcontanier从2020年12月23日后的最新10条日志。</span><br><span class="line">    docker logs --since=&quot;2020-12-23&quot; --tail=10 testcontanier</span><br><span class="line"></span><br><span class="line">    #实时跟踪日志最新输出,从倒数1000行开始</span><br><span class="line">    docker logs -f  --tail 1000 testcontanier</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-DockFile"><a href="#3-DockFile" class="headerlink" title="3. DockFile"></a>3. DockFile</h2><p>Dockerfile的基本指令有十三个，下面会用到部分。</p>
<ul>
<li><strong>FROM</strong>：所有Dockerfile的第一个指令都必须是FROM ，用于指定一个构建镜像的基础源镜像，如果本地没有就会从公共库中拉取，没有指定镜像的标签会使用默认的latest标签，如果需要在一个Dockerfile中构建多个镜像，可以使用多次。</li>
<li><strong>MAINTAINER</strong>：描述镜像的创建者，名称和邮箱。</li>
<li><strong>RUN</strong>：RUN命令是一个常用的命令，运行指定命令。通常用于运行安装任务从而向映像中添加额外的内容。在这里，我们需建立工作文件夹 。在第二个RUN命令中使用pip来安装requirements.txt文件中的所有包。</li>
<li><strong>COPY</strong>：复制本机文件或目录，添加到指定的容器目录，本例中将requirements.txt复制到镜像中。</li>
<li><strong>WORKDIR</strong>：为RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续参数如果是相对路径，则会基于之前命令指定的路径。为了避免出错，推荐WORKDIR指令中只使用绝对路径。</li>
<li><strong>ENTRYPOINT</strong>：在启动容器的时候提供一个默认的命令项。</li>
<li><strong>CMD</strong>：CMD指令用来指定启动容器时默认执行的命令。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基础镜像</span><br><span class="line">FROM python:3.7.9-slim-stretch</span><br><span class="line"> </span><br><span class="line"># 维护者信息</span><br><span class="line">MAINTAINER bona</span><br><span class="line"> </span><br><span class="line">#代码添加到code文件夹</span><br><span class="line">RUN mkdir /opt/code</span><br><span class="line">COPY ./requirment.txt /opt/code</span><br><span class="line">COPY ./customer.py /opt/code</span><br><span class="line"> </span><br><span class="line"># 设置code文件夹是工作目录</span><br><span class="line">WORKDIR /opt/code</span><br><span class="line"> </span><br><span class="line"># 安装支持</span><br><span class="line">RUN pip install -r requirment.txt</span><br><span class="line">CMD [&quot;python&quot;, &quot;./exercise.py&quot;]</span><br></pre></td></tr></table></figure>



<h1 id="3-深入探讨image"><a href="#3-深入探讨image" class="headerlink" title="3. 深入探讨image"></a>3. 深入探讨image</h1><h2 id="image常见操作"><a href="#image常见操作" class="headerlink" title="image常见操作"></a>image常见操作</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.查看本地image列表</span><br><span class="line">docker images</span><br><span class="line">docker image ls</span><br><span class="line"></span><br><span class="line">2.获取远端镜像</span><br><span class="line">docker pull 镜像：版本 或者 docker pull 拉去命令（url）</span><br><span class="line"></span><br><span class="line">3.删除镜像（如果此时镜像如果正在使用或者有关联的镜像，则需要先处理）</span><br><span class="line">docker image rm imageId</span><br><span class="line">docker rmi -f imageId</span><br><span class="line">docker rmi -f $(docker image ls) #删除所有镜像</span><br><span class="line"></span><br><span class="line">4.运行镜像</span><br><span class="line">docker run &lt;imageName&gt;</span><br><span class="line"></span><br><span class="line">5.发布镜像</span><br><span class="line">docker push &lt;image&gt;</span><br><span class="line"></span><br><span class="line">6.搜索镜像</span><br><span class="line">docker search &lt;image&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Dockerfile镜像制作"><a href="#Dockerfile镜像制作" class="headerlink" title="Dockerfile镜像制作"></a>Dockerfile镜像制作</h2><ul>
<li>下载java镜像</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo docker pull java:8</span><br></pre></td></tr></table></figure>

<ul>
<li>基于java镜像  自定义配置文件</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># create file</span><br><span class="line">touch Dockerfile</span><br><span class="line"># edit file</span><br><span class="line">vi Dockerfile</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM java:8</span><br><span class="line">VOLUME /tmp</span><br><span class="line">ENV file=&quot;&quot;</span><br><span class="line">ADD $file /root/$file</span><br><span class="line">ENTRYPOINT [&quot;sh&quot;,&quot;-c&quot;,&quot;java -jar /root/$file&quot;]</span><br></pre></td></tr></table></figure>

<ul>
<li>构建镜像</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前路径已经有 springboot-docker-0.0.1-SNAPSHOT.jar(spring web jar)</span><br><span class="line"></span><br><span class="line">docker build -t springboot-docker .</span><br><span class="line">#注意 最后的 . 这里是用于复制当前目录下的文件到镜像中，镜像名：springboot-docker</span><br><span class="line">运行后如下：</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>查看镜像列表</p>
<p>docker images</p>
</li>
<li><p>运行镜像</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run** -d --name springboot-docker-c -p 10000:8080 springboot-docker</span><br><span class="line"># (-p  把docker 容器中的 8080映射到主机的 10000端口)</span><br><span class="line"></span><br><span class="line">#查看端口被占用：</span><br><span class="line">netstat -tunlp | grep 9081</span><br></pre></td></tr></table></figure>



<ul>
<li>查看 docker 容器</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps -a #查看所有容器</span><br><span class="line"></span><br><span class="line">docker ps -l #查看最后一次创建的容器</span><br><span class="line"></span><br><span class="line"># 查看WEB应用程序容器的进程</span><br><span class="line">docker top container_id / container_name</span><br><span class="line"></span><br><span class="line"># 移除WEB应用容器   删除容器时，容器必须是停止状态</span><br><span class="line">docker rm container_id</span><br><span class="line">docker rmi container_name</span><br><span class="line"></span><br><span class="line"># 停止WEB应用容器  </span><br><span class="line">docker stop container_id / container_name</span><br></pre></td></tr></table></figure>



<ul>
<li><p>查看日志</p>
<p>docker logs -f -t –tail 50 containId</p>
</li>
</ul>
<h2 id="镜像仓库"><a href="#镜像仓库" class="headerlink" title="镜像仓库"></a>镜像仓库</h2><h3 id="发布镜像到-Docker-hub"><a href="#发布镜像到-Docker-hub" class="headerlink" title="发布镜像到 Docker hub"></a>发布镜像到 Docker hub</h3><h4 id="1、注册账号"><a href="#1、注册账号" class="headerlink" title="1、注册账号"></a>1、注册账号</h4><p>docker hub 官网：<a href="https://hub.docker.com/">https://hub.docker.com</a></p>
<h4 id="2、-客户端配置-daemon-json"><a href="#2、-客户端配置-daemon-json" class="headerlink" title="2、 客户端配置 daemon.json"></a>2、 客户端配置 daemon.json</h4><p>检查 registry-mirror 和 insecure-registries 节点为缺省值，也就是 []</p>
<p>默认没有设置过就是缺省值</p>
<h4 id="3、-登录"><a href="#3、-登录" class="headerlink" title="3、 登录"></a>3、 登录</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker login</span><br><span class="line"># 输入用户名和密码</span><br></pre></td></tr></table></figure>

<h4 id="4、构建自己的容器"><a href="#4、构建自己的容器" class="headerlink" title="4、构建自己的容器"></a>4、构建自己的容器</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker build 。。。</span><br></pre></td></tr></table></figure>

<h4 id="5、-打包镜像"><a href="#5、-打包镜像" class="headerlink" title="5、 打包镜像"></a>5、 打包镜像</h4><p>分两种</p>
<ul>
<li>通过tag方式打包</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker tag springboot-docker:latest bona/springboot-docker:latest</span><br><span class="line"></span><br><span class="line">#docker tag imageName:version userName/imageName:version</span><br></pre></td></tr></table></figure>

<ul>
<li>通过commit方式打包</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">运行容器</span><br><span class="line">docker run -d --name springboot-docker-c -p 10000:8080 springboot-docker</span><br><span class="line"># 此时通过 docker ps -l 得到一个容器id  xxxxxx</span><br><span class="line"></span><br><span class="line">打包镜像</span><br><span class="line">docker commit xxxxxx bona/springboot-docker</span><br><span class="line"># docker commit containerId userName/imageName</span><br></pre></td></tr></table></figure>

<h4 id="6、push镜像到-docker-hub"><a href="#6、push镜像到-docker-hub" class="headerlink" title="6、push镜像到 docker hub"></a>6、push镜像到 docker hub</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker push bona/springboot-docker</span><br><span class="line"># docker push userName/imageName</span><br></pre></td></tr></table></figure>

<h1 id="4-Docker搭建私有镜像仓库"><a href="#4-Docker搭建私有镜像仓库" class="headerlink" title="4. Docker搭建私有镜像仓库"></a>4. Docker搭建私有镜像仓库</h1><h2 id="私服服务器下载registry镜像"><a href="#私服服务器下载registry镜像" class="headerlink" title="私服服务器下载registry镜像"></a>私服服务器下载registry镜像</h2><p>在服务端下载私服镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull registry</span><br></pre></td></tr></table></figure>

<p>运行registry镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -itd -v /data/registry:/var/lib/registry --net=host --name bona-registry registry:latest</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">run 参数说明：</span><br><span class="line">-d：让容器后台运行</span><br><span class="line">-i: 以交互模式运行容器，通常与-t 同时使用</span><br><span class="line">-P：随机端口映射，容器内部端口随即映射到主机端口</span><br><span class="line">-p：指定端口映射，格式为 主机端口：容器端口</span><br><span class="line">-t: 为容器分配一个伪输入终端，通常与-i同时使用</span><br><span class="line">--name=&quot;bona-container&quot;：指定容器名称为bona-container</span><br><span class="line">-dns 8.8.8.8 指定容器使用的dns服务器，默认与宿主一致</span><br><span class="line">--dns-search example.com: 指定容器DNS搜索域名，默认与宿主一致</span><br><span class="line">-h &quot;hostname&quot;: 指定容器的hostname</span><br><span class="line">-e username=&quot;bona&quot;: 设置环境变量</span><br><span class="line">-envfile=[]:从指定文件读入环境变量</span><br><span class="line">-m: 设置容器使用的最大内存数</span><br><span class="line">--expose=[]:开放一个端口或者一组端口</span><br><span class="line">--volumn, -v: 绑定一个卷，将一个本地地址映射复制到docker内</span><br><span class="line">		例如：-v /data/registry:/var/lib/registry 本地/data/registry映射到容器指定路径</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="访问私有仓库"><a href="#访问私有仓库" class="headerlink" title="访问私有仓库"></a>访问私有仓库</h2><p>如果有防火墙，先关闭或者添加tcp入口规则</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#防火墙命令</span><br><span class="line">#查看防火墙的运行状态</span><br><span class="line">systemctl status firewalld</span><br><span class="line"></span><br><span class="line">#关闭防火墙</span><br><span class="line">service firewalld stop</span><br></pre></td></tr></table></figure>

<p>访问 192.168.2.100:5000&#x2F;v2&#x2F;_catalog</p>
<p>现在私服还没有镜像，接下来配置好客户端就可以上传镜像了</p>
<h2 id="客户端配置daemon-json"><a href="#客户端配置daemon-json" class="headerlink" title="客户端配置daemon.json"></a>客户端配置daemon.json</h2><p>官方配置参考：<a href="https://docs.docker.com/engine/reference/commandline/docker/">https://docs.docker.com/engine/reference/commandline/docker/</a></p>
<p>默认缺省值上传到 docker hub上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;registry-mirror&quot;: [],</span><br><span class="line">&quot;&quot;: [],</span><br><span class="line">... other info</span><br><span class="line">&#125;</span><br><span class="line">#等同于</span><br><span class="line">&#123;</span><br><span class="line">&quot;registry-mirror&quot;: [</span><br><span class="line">	&quot;https://registry.hub.docker.com&quot;</span><br><span class="line">],</span><br><span class="line">&quot;insecure-registries&quot;: [</span><br><span class="line">	&quot;registry.hub.docker.com&quot;</span><br><span class="line">],</span><br><span class="line">... other info</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要修改为指定的仓库时，修改此处的insecure-registries值</p>
<h3 id="centos-客户端"><a href="#centos-客户端" class="headerlink" title="centos 客户端"></a>centos 客户端</h3><p>创建daemon.json配置文件</p>
<p>创建并写入值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &#x27;&#123;&quot;insecure-registries&quot;: [&quot;192.168.2.100:5000&quot;] &#125;&#x27; &gt; /etc/docker/daemon.json</span><br></pre></td></tr></table></figure>

<p>重启docker服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl stop docker</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<h3 id="windows-客户端"><a href="#windows-客户端" class="headerlink" title="windows 客户端"></a>windows 客户端</h3><p>打开docker desktop</p>
<p>打开私服仓库</p>
<p>设置私服地址并重启</p>
<h3 id="客户端发布镜像"><a href="#客户端发布镜像" class="headerlink" title="客户端发布镜像"></a>客户端发布镜像</h3><p>打tag</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker tag springboot-docker:latest 192.168.2.100:5000/bona/springboot-docker:latest</span><br><span class="line"></span><br><span class="line">#docker tag imageName:version registry-address/userName/imageName:version</span><br></pre></td></tr></table></figure>

<h3 id="push-到仓库"><a href="#push-到仓库" class="headerlink" title="push 到仓库"></a>push 到仓库</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker push 192.168.2.100:5000/bona/springboot-docker</span><br><span class="line"># docker push registry-address/userName/imageName</span><br><span class="line"></span><br><span class="line"># windows 也可以使用 docker desktop 来push</span><br></pre></td></tr></table></figure>

<h2 id="搭建自己的Docker-Harbor"><a href="#搭建自己的Docker-Harbor" class="headerlink" title="搭建自己的Docker Harbor"></a>搭建自己的Docker Harbor</h2><p>1.访问github上的harbor项目</p>
<p><a href="https://github.com/goharbor/harbor">https://github.com/goharbor/harbor</a></p>
<p>2.下载版本，比如1.7.1</p>
<p><a href="https://github.com/goharbor/harbor/release">https://github.com/goharbor/harbor/release</a></p>
<p>官方演示地址：<a href="https://demo.goharbor.io/harbor">https://demo.goharbor.io/harbor</a></p>
<p>账号：admin, 密码：Harbor12345</p>
<p>3.找一台安装了docker-compose[后面会有笔记]， 上传并解压 tar -zxvf xxx.tar.gz</p>
<p>4.进入到harbor目录</p>
<p>修改 harbor.cfg文件，主要是ip地址的修改改成当前机器的ip地址</p>
<p>同时也可以看到Harbor的密码默认是 Harbor12345</p>
<p>5.安装Harbor,需要一些时间</p>
<p>sh install.sh</p>
<p>6.浏览器访问，比如192.168.2.100:8080, 输入用户名和密码即可</p>
<h1 id="5-深入探讨Container"><a href="#5-深入探讨Container" class="headerlink" title="5. 深入探讨Container"></a>5. 深入探讨Container</h1><p>container是由image运行起来的。即container是 docker run image 创建出来的</p>
<p><a href="20220716-1.jpg"><img src="/../../../../images/20220716-1.jpg" alt="img"></a></p>
<h2 id="Container到Image"><a href="#Container到Image" class="headerlink" title="Container到Image"></a>Container到Image</h2><p>container是 docker run image 创建出来的, 那能否由一个container反推出来一个image?</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 拉去一个centos image</span><br><span class="line">docker pull centos</span><br><span class="line">2. 根据centos镜像创建出一个container</span><br><span class="line">docker run -d -it --name my-centos</span><br><span class="line">3.进入 my-centos 容器</span><br><span class="line">docker exec -it my-centos bash</span><br><span class="line">4.输入vim命令</span><br><span class="line">报错：command not found</span><br><span class="line">5.修改container,安装vim命令</span><br><span class="line">在 容器中： yum install -y vim</span><br><span class="line">6.退出容器，将其生成一个image</span><br><span class="line">#docker commit container-name newImage-name</span><br><span class="line">docker commit my-centos vim-my-centos</span><br><span class="line">7.查看镜像列表，并基于新镜像创建容器</span><br><span class="line">docker run -d -it --name vim-my-centos</span><br><span class="line">8.进入容器，查看vim</span><br><span class="line">docker exec -it vim-my-centos bash</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>总结：通过docker commit命令基于一个container 生成一个新的 image。一般不建议这么做，因为image怎么来的就完全不知道了。</p>
]]></content>
      <categories>
        <category>容器化</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala 编码练习</title>
    <url>/2019/05/19/Scala%20%E7%BC%96%E7%A0%81%E7%BB%83%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="快捷键记录"><a href="#快捷键记录" class="headerlink" title="快捷键记录"></a>快捷键记录</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(ctrl+alt+l)    格式化的代码快捷键</span><br></pre></td></tr></table></figure>

<h2 id="1-scala-输出方式"><a href="#1-scala-输出方式" class="headerlink" title="1.scala 输出方式"></a>1.scala 输出方式</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val name = &quot;scala&quot;</span><br><span class="line">val age  = 15</span><br><span class="line">val url  = &quot;www.scala.com&quot;</span><br><span class="line"></span><br><span class="line">串通过+号连接（类似java）	</span><br><span class="line">	println(&quot;name=&quot; + name + &quot; age=&quot; + age + &quot; url=&quot; + url)</span><br><span class="line"></span><br><span class="line">串通过 % 传值。(格式化输出)	</span><br><span class="line">	printf(&quot;name=%s, age=%d, url=%s \n&quot;, name, age, url)</span><br><span class="line">	</span><br><span class="line">字符串插值：通过$引用(类似PHP）	</span><br><span class="line">	println(s&quot;name=$name, age=$age, url=$url&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="2-yield"><a href="#2-yield" class="headerlink" title="2.yield"></a>2.yield</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">循环返回值</span><br><span class="line">val res = for(i &lt;- 1 to 10) yield i * 2</span><br><span class="line">println(res)</span><br><span class="line"></span><br><span class="line">将遍历过程中处理的结果返回到一个新Vector集合中，使用yield关键字</span><br></pre></td></tr></table></figure>

<h2 id="3-函数式编程"><a href="#3-函数式编程" class="headerlink" title="3.函数式编程"></a>3.函数式编程</h2><p>高阶函数，函数柯里化，参数(类型)推断，过程，惰性函数，异常处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">函数的形参列表可以是多个, 如果函数没有形参，调用时 可以不带() </span><br><span class="line"></span><br><span class="line">高阶函数</span><br><span class="line">将其他函数作为参数或 返回值为一个函数 的函数    </span><br><span class="line"></span><br><span class="line">	// 1.函数的第一个参数类型是另一个函数(函数别名：参数类型=&gt;返回值类型)    </span><br><span class="line">	def apply(f: Int =&gt; String, v: Int) = f(v)    </span><br><span class="line">	def fmtInt(n: Int) : String = &quot;[整数值&#123;&quot; + n + &quot;&#125;]&quot;    </span><br><span class="line">	// 高阶函数的调用 函数名（函数参数，函数参数的参数）    </span><br><span class="line">	def main(args: Array[String]): Unit = &#123;        </span><br><span class="line">		println(apply(fmtInt, 1200))    </span><br><span class="line">	&#125;    </span><br><span class="line">	输出：[整数值&#123;1200&#125;]    </span><br><span class="line">	</span><br><span class="line">	// 2.函数的返回值是一个函数    </span><br><span class="line">	def addBy(n: Int) = &#123;        </span><br><span class="line">		(d : Double) =&gt; n + d     </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	def main(args: Array[String]): Unit = &#123;        </span><br><span class="line">		println(addBy(50)(80.223))    </span><br><span class="line">	&#125;    </span><br><span class="line">	输出：130.223</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">函数柯里化(Currying)：将原来接受多个参数的函数变成新的接受一个参数的函数的过程</span><br><span class="line">新函数的参数接受原来的第二个参数为唯一参数, 如果有n个参数, 就是把这个函数分解成n个新函数的过程。	</span><br><span class="line">	柯里化就是证明了函数只需要一个参数而已    </span><br><span class="line">	样例代码    </span><br><span class="line">	// 原始函数, 有3个参数的函数    </span><br><span class="line">	def addMulti(a: Int, b: Int, c: Int) = (a + b) * c    </span><br><span class="line">	</span><br><span class="line">	// 函数A的返回值是一个函数B, 函数B的返回值是函数C    </span><br><span class="line">	def addMulti(a: Int) = &#123;        </span><br><span class="line">		(b: Int) =&gt; (c: Int) =&gt; (a + b) * c      </span><br><span class="line">	&#125;    </span><br><span class="line">	输出：2600    </span><br><span class="line">	</span><br><span class="line">	函数柯里化最佳实践   比较两个字符串在忽略大小写的情况下是否相等    </span><br><span class="line">	方式1: 简单的方式,使用一个函数完成.    </span><br><span class="line">	def eq2(s1: String)(s2: String): Boolean = &#123;        </span><br><span class="line">		s1.toLowerCase == s2.toLowerCase    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	//方式2：使用稍微高级的用法(隐式类)：形式为 str.方法()    </span><br><span class="line">	//比较字符串是否相等是两件事，先转成小写[函数]， 再比较是否相等[函数]    </span><br><span class="line">	def eq(s1: String, s2: String): Boolean = &#123;        </span><br><span class="line">		s1.equals(s2)    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	implicit class TestEq(s: String) &#123;        </span><br><span class="line">		def checkEq(ss: String)(f: (String, String) =&gt; Boolean): Boolean = &#123;           </span><br><span class="line">			f(s.toLowerCase, ss.toLowerCase)        </span><br><span class="line">		&#125;    </span><br><span class="line">	&#125;    </span><br><span class="line">	str1.checkEq(str2)(_.equals(_))</span><br><span class="line">	</span><br><span class="line">参数(类型)推断    </span><br><span class="line">	应用实例    </span><br><span class="line">	val list = List(1, 2, 3, 4)    </span><br><span class="line">	println(list.map((x:Int)=&gt;x + 1))     </span><br><span class="line">	println(list.map((x)=&gt;x + 1))    </span><br><span class="line">	println(list.map(x=&gt;x + 1))    </span><br><span class="line">	println(list.map(_ + 1))    </span><br><span class="line">	val res = list.reduce(_+_)</span><br><span class="line">	</span><br><span class="line">过程        </span><br><span class="line">	将函数的返回类型为Unit的函数称之为过程(procedure)，        </span><br><span class="line">	## 如果明确函数没有返回值，那么等号可以省略 ##    </span><br><span class="line">	//函数无返回值，使用unit来说明    </span><br><span class="line">	//称为过程（procedure）    </span><br><span class="line">	def func(name:String):Unit=&#123;        </span><br><span class="line">		println(name+&quot; hello!&quot;)    </span><br><span class="line">	&#125;    </span><br><span class="line">	等价于，去除=      </span><br><span class="line">	</span><br><span class="line">	def func(name:String)&#123;        </span><br><span class="line">		println(name+&quot; hello!&quot;)      </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	###如果函数声明时没有返回值类型，但是有 = 号，可以进行类型推断最后一行代码。这时这个		</span><br><span class="line">	函数实际是有返回值的，该函数并不是过程。    </span><br><span class="line">	def func(name:String)=&#123;        </span><br><span class="line">		name+&quot; hello!&quot;      </span><br><span class="line">	&#125;    </span><br><span class="line">	函数返回值：String类型</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">惰性函数	</span><br><span class="line">	当函数返回值被声明为lazy时，函数的执行将被推迟，直到我们首次对此取值，该函数才会执行。</span><br><span class="line">	这种函数我们称之为惰性函数。java中称为懒加载。	</span><br><span class="line">	def main(args: Array[String]): Unit = &#123;        </span><br><span class="line">		lazy val res = sum(10, 20)        </span><br><span class="line">		println(&quot;-----------------&quot;)        </span><br><span class="line">		println(&quot;res=&quot; + res)     </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	def sum(n1 : Int, n2 : Int): Int = &#123;        </span><br><span class="line">		println(&quot;sum() 执行了..&quot;)        </span><br><span class="line">		return  n1 + n2    </span><br><span class="line">	&#125;	</span><br><span class="line">	</span><br><span class="line">	注意事项和细节:</span><br><span class="line">	lazy 不能修饰 var 类型的变量    </span><br><span class="line">	不但是 在调用函数时，加了 lazy ,会导致函数的执行被推迟，    </span><br><span class="line">	我们在声明一个变量时，如果给声明了 lazy ,那么变量值得分配也会推迟。     </span><br><span class="line">	比如 lazy val i = 10</span><br><span class="line">	</span><br><span class="line">Scala异常处理举例----模式匹配    </span><br><span class="line">	try &#123;          </span><br><span class="line">		val r = 10 / 0    </span><br><span class="line">	&#125; catch &#123;          </span><br><span class="line">		case ex: ArithmeticException=&gt; println(“捕获了除数为零的算术异常&quot;)          </span><br><span class="line">		case ex: Exception =&gt; println(&quot;捕获了异常&quot;)    </span><br><span class="line">	&#125; finally &#123;          </span><br><span class="line">		// 最终要执行的代码          </span><br><span class="line">		println(&quot;scala finally...&quot;)    </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-面向对象基础"><a href="#4-面向对象基础" class="headerlink" title="4.面向对象基础"></a>4.面向对象基础</h2><p>类，属性，属性高级，构造器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Scala中，一切皆为对象。 </span><br><span class="line"></span><br><span class="line">如何定义类    </span><br><span class="line">	[修饰符] class 类名 &#123;       </span><br><span class="line">		类体    </span><br><span class="line">	&#125;     </span><br><span class="line">	定义类的注意事项:</span><br><span class="line">	1.scala语法中，类并不声明为public，所有这些类都具有公有可见性(即默认就是public)    </span><br><span class="line">	2.一个Scala源文件可以包含多个类. </span><br><span class="line">	</span><br><span class="line">属性/成员变量	</span><br><span class="line">	1.Scala中声明一个属性,必须显示的初始化	</span><br><span class="line">	2.如果赋值为null,则一定要加类型，因为不加类型, 那么该属性的类型就是Null类型.	</span><br><span class="line">	3.在定义属性时，暂时不赋值，也可以使用符号_(下划线)，让系统分配默认值.</span><br><span class="line">	</span><br><span class="line">属性高级</span><br><span class="line">	JavaBeans规范定义了Java的属性是像getXxx（）和setXxx（）的方法。</span><br><span class="line">	将Scala字段加@BeanProperty时，这样会自动生成规范的 setXxx/getXxx 方法。	</span><br><span class="line">	可以使用 对象.setXxx() 和 对象.getXxx() 来调用属性。</span><br><span class="line">	</span><br><span class="line">构造器（又叫构造方法）</span><br><span class="line">构造器包括： 主构造器（一个） 和 辅助构造器(多个)</span><br><span class="line"></span><br><span class="line">class 类名(形参列表) &#123;  // 主构造器   </span><br><span class="line">	// 类体   </span><br><span class="line">	def  this(形参列表) &#123;  // 辅助构造器   &#125;   </span><br><span class="line">	</span><br><span class="line">	def  this(形参列表) &#123;  //辅助构造器可以有多个...   &#125;</span><br><span class="line">&#125; </span><br><span class="line">辅助构造器 函数的名称this, 可以有多个，编译器通过不同参数（个数或类型）来区分.</span><br></pre></td></tr></table></figure>

<h2 id="5-面向对象中级"><a href="#5-面向对象中级" class="headerlink" title="5.面向对象中级"></a>5.面向对象中级</h2><p>包、面向对象三大特性：封装、继承、多态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package包	</span><br><span class="line"></span><br><span class="line">	包的三大作用		</span><br><span class="line">		1.区分相同名字的类		</span><br><span class="line">		2.当类的数目增多时，便于管理		</span><br><span class="line">		3.控制类的访问范围	</span><br><span class="line">		</span><br><span class="line">		Scala会自动引入的常用包 		</span><br><span class="line">			java.lang.*           </span><br><span class="line">		</span><br><span class="line">		scala包         </span><br><span class="line">		Predef包	</span><br><span class="line">		作用域原则：可以直接向上访问,访问父包中的内容		</span><br><span class="line">			(提示：Java中子包使用父包的类，需要import)。	</span><br><span class="line">		包名可以相对路径也可以绝对路径		</span><br><span class="line">			//第一种形式         </span><br><span class="line">			//@BeanProperty var age: Int = _         </span><br><span class="line">			</span><br><span class="line">			//第二种形式, 和第一种一样，都是相对路径引入         </span><br><span class="line">			//@scala.beans.BeanProperty var age: Int = _         </span><br><span class="line">			</span><br><span class="line">			//第三种形式, 是绝对路径引入，可以解决包名冲突         </span><br><span class="line">			@_root_. scala.beans.BeanProperty var age: Int = _	</span><br><span class="line">			包可以包含Class、Object和特质Trait		</span><br><span class="line">			</span><br><span class="line">			包的可见性		</span><br><span class="line">				当属性访问权限为默认时，从底层看属性是private		</span><br><span class="line">				当方法访问权限为默认时，默认为public访问权限		</span><br><span class="line">				private为私有权限，只在类的内部和伴生对象中可用 		</span><br><span class="line">				protected为受保护权限,只能子类访问		</span><br><span class="line">				没有public关键字		</span><br><span class="line">				</span><br><span class="line">				总的来说分成三大类           </span><br><span class="line">                	(1) 处处可以访问public             </span><br><span class="line">                	(2) 子类和伴生对象能访问protected             </span><br><span class="line">                	(3) 本类和伴生对象访问 private	</span><br><span class="line">                </span><br><span class="line">                Java中如果想要导入包中所有的类，可以通过通配符*，	</span><br><span class="line">                Scala中采用通配符 _		</span><br><span class="line">           	</span><br><span class="line">           	引入部分类 采用选取器(大括号)			    </span><br><span class="line">           	import scala.collection.mutable.&#123;HashMap, HashSet&#125;		</span><br><span class="line">           	</span><br><span class="line">           	如果引入的多个包中含有相同的类，进行重命名进行区分		</span><br><span class="line">           	import java.util.&#123; HashMap=&gt;JavaHashMap, List&#125;		</span><br><span class="line">           	import scala.collection.mutable._	</span><br><span class="line">           	</span><br><span class="line">           	如果某个冲突的类根本就不会用到，那么这个类可以直接隐藏掉。		</span><br><span class="line">           	import java.util.&#123; HashMap=&gt;_, _&#125; 		</span><br><span class="line">           	var map = new HashMap()</span><br><span class="line">           	</span><br><span class="line">面向对象编程三大特征	</span><br><span class="line">	封装、继承和多态。		</span><br><span class="line"></span><br><span class="line">封装：把属性以及方法封装在一起。数据被保护，对数据的操作是经过授权的操作。		</span><br><span class="line">	优点:			</span><br><span class="line">		隐藏实现细节			</span><br><span class="line">		可以对数据进行验证，保证安全合理				</span><br><span class="line">	</span><br><span class="line">	Scala中为了简化代码的开发，</span><br><span class="line">	当声明属性时，本身就自动提供了对应setter/getter方法,访问权限与属性一致。		</span><br><span class="line">	private=&gt;private method,  省略=》public method		</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">继承：		</span><br><span class="line">	解决代码复用。当多个类存在相同的属性(变量)和方法时,		</span><br><span class="line">	子类不需要重新定义这些属性和方法。Scala只支持类的单继承		</span><br><span class="line">	优点：			</span><br><span class="line">		代码的复用性提高了			</span><br><span class="line">		代码的扩展性和维护性提高了		</span><br><span class="line">	子类继承了所有的属性，只是私有的属性不能直接访问。		</span><br><span class="line">	</span><br><span class="line">	类型检查和转换  **			</span><br><span class="line">	isInstanceOf() 测试某个对象是否属于某个给定的类			</span><br><span class="line">	asInstanceOf() 将引用转换为子类的引用  ***				</span><br><span class="line">	</span><br><span class="line">	scala中只有主构造器可以调用父类的构造器。				</span><br><span class="line">	</span><br><span class="line">	抽象类			</span><br><span class="line">		抽象方法和抽象属性不能使用private、final 来修饰。			</span><br><span class="line">		抽象类不能被实例化。			</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">多态：		</span><br><span class="line">	多态的前提条件是继承。		</span><br><span class="line">		主要表现：</span><br><span class="line">		1.方法的重写 				</span><br><span class="line">		2.父类引用指向子类对象（面向接口编程，低耦合）					</span><br><span class="line">			A a = New B();					</span><br><span class="line">			A的对象可访问B从A中继承来的和B复写A的方法，					</span><br><span class="line">			其它的方法都不能访问，包括A中的私有成员方法。				</span><br><span class="line">			</span><br><span class="line">	多态成员的访问特点:			</span><br><span class="line">		访问成员变量: 编译看左边,运行看左边			</span><br><span class="line">		非静态成员方法: 编译看左边,运行看右边			</span><br><span class="line">		静态成员方法:  编译看左边,运行看左边		</span><br><span class="line">		</span><br><span class="line">	即只有非静态成员方法才会编译看左边,运行看右边,其他的都是编译看左边,运行看左边		        </span><br><span class="line">	</span><br><span class="line">	优点：        	</span><br><span class="line">		使用父类类型作为方法的参数,可以接收该类所有的子类对象		</span><br><span class="line">	缺点：			</span><br><span class="line">		不能使用子类特有的属性和行为.</span><br></pre></td></tr></table></figure>

<h2 id="6-面向对象高级"><a href="#6-面向对象高级" class="headerlink" title="6.面向对象高级"></a>6.面向对象高级</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">静态属性和静态方法	</span><br><span class="line">	Java中静态方法并不是通过对象调用的，而是通过类对象调用的，	</span><br><span class="line">	所以静态操作并不是面向对象的。		</span><br><span class="line">	</span><br><span class="line">	Scala中静态的概念----伴生对象. 没有static关键字		</span><br><span class="line">		为了能够和Java语言交互.		</span><br><span class="line">		这个类的所有静态内容都可以放置在它的伴生对象中声明和调用	</span><br><span class="line">		</span><br><span class="line">	概念：伴生类（class）、伴生对象（object关键字声明）	</span><br><span class="line">	伴生对象的名称应该和伴生类名一致。		</span><br><span class="line">	</span><br><span class="line">	伴生对象的声明应该和伴生类的声明在同一个源码文件中.  ****		</span><br><span class="line">	</span><br><span class="line">	伴生对象-apply方法		</span><br><span class="line">		在伴生对象中定义apply方法,		</span><br><span class="line">		可以实现： 类名(参数) 方式 来创建对象实例. </span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">单例模式	</span><br><span class="line">	保证在整个的软件系统中，某个类只能存在一个对象实例。	</span><br><span class="line">	Scala中没有静态的概念，采用类对象(即伴生对象)方式构建单例对象	</span><br><span class="line">	采用伴生对象懒汉式或者饿汉式实现。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">接口	采</span><br><span class="line">	用trait（特质，特征）来代替接口的概念。		</span><br><span class="line">		trait 特质名 &#123;			</span><br><span class="line">			trait体		</span><br><span class="line">		&#125;	</span><br><span class="line">	</span><br><span class="line">	extends 实现trait  单继承多实现		</span><br><span class="line">		如果有多个特质或存在父类，那么需要采用with关键字连接		</span><br><span class="line">	</span><br><span class="line">	常用的常见对象的方法：		</span><br><span class="line">		new 对象		</span><br><span class="line">		applay 方法，创建对象		</span><br><span class="line">		反射		</span><br><span class="line">		反序列化</span><br></pre></td></tr></table></figure>

<h2 id="7-隐式转换"><a href="#7-隐式转换" class="headerlink" title="7.隐式转换"></a>7.隐式转换</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">隐式转换函数	</span><br><span class="line">	以implicit关键字声明的带有单个参数的函数。	</span><br><span class="line">	实例： 输入double,返回intssss		</span><br><span class="line">		implicit def f1(d: Double): Int = &#123;            </span><br><span class="line">			d.toInt          </span><br><span class="line">		&#125;          </span><br><span class="line">		val num: Int = 3.5     	  </span><br><span class="line">		println(num)		</span><br><span class="line">	</span><br><span class="line">	细节：		</span><br><span class="line">		1. 隐式转换与函数名称无关，只与函数签名有关		</span><br><span class="line">		2. 隐式函数可以有多个(即：隐式函数列表)，		</span><br><span class="line">		但是需要保证在当前环境下，只有一个隐式函数能被识别</span><br></pre></td></tr></table></figure>

<h2 id="8-集合"><a href="#8-集合" class="headerlink" title="8.集合"></a>8.集合</h2><p>数组、列表、</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Scala同时支持不可变集合和可变集合 ,默认采用不可变集合	</span><br><span class="line">	不可变集合：scala.collection.immutable	</span><br><span class="line">	可变集合：  scala.collection.mutable	</span><br><span class="line">	这里的可变与不可变可理解为定长与变长	</span><br><span class="line">	集合元素采用小括号访问</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">集合有三大类：序列Seq、集Set、映射Map. 所有的集合都扩展自Iterable特质</span><br><span class="line"></span><br><span class="line">元组：可以理解为一个容器，可以存放各种相同或不同类型的数据。</span><br><span class="line">注意：元组中最大只能有22个元素</span><br><span class="line"></span><br><span class="line">数组 Array, ArrayBuffer(类似java的ArrayList)	</span><br><span class="line">	多维数组：Array.ofDim[Int](3, 4)   3行4列		</span><br><span class="line">	</span><br><span class="line">	Scala数组转Java的List 	</span><br><span class="line">	val arr = ArrayBuffer(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)	</span><br><span class="line">	import scala.collection.JavaConversions.bufferAsJavaList	</span><br><span class="line">	val javaArr = new ProcessBuilder(arr)	</span><br><span class="line">	val arrList = javaArr.command()	</span><br><span class="line">	</span><br><span class="line">	Java的List转Scala数组	</span><br><span class="line">	import scala.collection.JavaConversions.asScalaBuffer	</span><br><span class="line">	import scala.collection.mutable	</span><br><span class="line">	val scalaArr: mutable.Buffer[String] = arrList</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">列表 Scala的List可以直接存放数据，就是一个object		</span><br><span class="line">	默认情况下Scala的List是不可变的，List属于序列Seq。		</span><br><span class="line">	Java中List是一个接口，真正存放数据是ArrayList			</span><br><span class="line">	</span><br><span class="line">	List小结：		</span><br><span class="line">		List 在 scala包对象声明的,因此不需要引入其它包也可以使用		</span><br><span class="line">		val List = scala.collection.immutable.List		</span><br><span class="line">		List 中可以放任何数据类型		</span><br><span class="line">		如果希望得到一个空列表，可以使用Nil对象		</span><br><span class="line">		</span><br><span class="line">	列表 List-元素的追加  尾加:+ 或  +：头插		</span><br><span class="line">		向列表中增加元素, 会返回新的列表/集合对象。		</span><br><span class="line">		列表增加数据            </span><br><span class="line">		</span><br><span class="line">	var list1 = List(1, 2, 3, &quot;abc&quot;)            </span><br><span class="line">	// :+运算符表示在列表的最后增加数据            </span><br><span class="line">	val list2 = list1 :+ 4            </span><br><span class="line">	// :+运算符表示在列表的最后增加数据            </span><br><span class="line">	val list3 = 4 +: list1		   </span><br><span class="line">	</span><br><span class="line">	最后增加数据也可以采用 </span><br><span class="line">		符号::   向集合中  新建集合添加元素。		</span><br><span class="line">		::: 运算符  将集合中的每一个元素加入到空集合中去		</span><br><span class="line">		运算规则，从右向左。		</span><br><span class="line">	</span><br><span class="line">	ListBuffer		</span><br><span class="line">	可变的list集合，可以添加，删除元素,ListBuffer属于序列</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">队列 Queue  new mutable.Queue[Int]     </span><br><span class="line">	+= 追加单个元素和 ++= 追加List    </span><br><span class="line">	q1.dequeue()     </span><br><span class="line">	q1.enqueue(20,60) </span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">映射 Map	</span><br><span class="line">	Scala中不可变的Map是有序的，可变的Map是无序的。	</span><br><span class="line">	可变Map (scala.collection.mutable.Map) 	</span><br><span class="line">	不可变Map(scala.collection.immutable.Map) 		</span><br><span class="line">	</span><br><span class="line">	new scala.collection.mutable.HashMap[String, Int]		</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	Map-取值        </span><br><span class="line">	1.map.get(键) 这样的调用返回一个Option对象，要么是Some，要么是None        </span><br><span class="line">	得到Some再取出， map.get(键).get		</span><br><span class="line">	</span><br><span class="line">	2.getOrElse（key,default） 方法 	</span><br><span class="line">	如何选择取值方式建议	    </span><br><span class="line">	如果我们确定key是存在的，应该使用map(&quot;key&quot;) ,速度快.        </span><br><span class="line">	</span><br><span class="line">	如果我们不确定key是否存在，</span><br><span class="line">	而且在不存在时，有业务逻辑处理就是用map.contains(),配合 map(&quot;key&quot;)        </span><br><span class="line">	</span><br><span class="line">	如果只是简单的希望返回一个值，就使用getOrElse() 	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	对map遍历		</span><br><span class="line">		for ((k, v) &lt;- map) 		</span><br><span class="line">		for (v &lt;- map.keys) 		</span><br><span class="line">		for (v &lt;- map.keys) 		</span><br><span class="line">		for(v &lt;- map) </span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">集 Set	</span><br><span class="line">	集是不重复元素的结合。默认是以哈希集实现</span><br></pre></td></tr></table></figure>

<h2 id="9-集合操作"><a href="#9-集合操作" class="headerlink" title="9.集合操作"></a>9.集合操作</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">max,min,sum,product(乘积),reverse(反转)</span><br><span class="line"></span><br><span class="line">map操作	</span><br><span class="line">	map 是一个高阶函数，可以接受一个函数的函数	</span><br><span class="line">	将集合中的每一个元素通过指定功能（函数）映射（转换）成新的结果集合</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">flatmap	</span><br><span class="line">	将集合中的每个元素的子元素映射到某个函数并返回新的集合。	</span><br><span class="line">	就是经过map函数之后多了一个扁平化的过程。	</span><br><span class="line">	特别适用于嵌套的集合。</span><br><span class="line">	</span><br><span class="line">过滤-filter	</span><br><span class="line">	col.filter(_.startsWith(&quot;A&quot;)</span><br><span class="line"></span><br><span class="line">归约	</span><br><span class="line">	list.reduceLeft(_+_)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala笔记</title>
    <url>/2019/10/16/Scala%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h1><p>静态编译的函数式语言。</p>
<h2 id="1-基本语法注意规范"><a href="#1-基本语法注意规范" class="headerlink" title="1. 基本语法注意规范"></a>1. 基本语法注意规范</h2><ul>
<li><p>大小写敏感</p>
</li>
<li><p>类名 单词首字母大写</p>
</li>
<li><p>方法名的命名规则类似的 camel 命名规则</p>
</li>
<li><p>程序文件名和对象名称完全匹配</p>
</li>
<li><p>scala入口 def main(args: Array[String])</p>
</li>
<li><p><strong>一些不了解的关键字</strong>：implicit，lazy，sealed，object，trait，yield</p>
</li>
<li><p><strong>一些不熟悉的数据类型</strong>：Unit，Nothing，Any，AnyRef</p>
<p>Unit等价于 void 只有一个实例，写成（）</p>
<p>Nothing类型是任何其他类型的子类型</p>
<p>Any 是所有其他类的超类</p>
<p>AnyRef是所有引用类（reference class）的基类。</p>
<p>PS:scala中所有的数据类型都是对象。</p>
</li>
<li><p>val 修饰不可变变量相当于final修饰，var修饰可变变量</p>
</li>
<li><p>访问修饰符</p>
<p>private（类内访问），protected（子类），public。</p>
<p>默认情况下，Scala 对象的访问级别都是 public。</p>
<p>Scala 中的 private 限定符，比 Java 更严格，在嵌套类情况下，外层类甚至不能访问被嵌套类的私有成员。</p>
</li>
</ul>
<h2 id="2-循环类型"><a href="#2-循环类型" class="headerlink" title="2. 循环类型"></a>2. 循环类型</h2><p>while, do…while, for中只有for和java略有区别。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for( a &lt;- 1 to 10)&#123;	</span><br><span class="line">	println( &quot;Value of a: &quot; + a );</span><br><span class="line">&#125;</span><br><span class="line">1....10</span><br><span class="line"></span><br><span class="line">for( a &lt;- 1 to 10)&#123;	</span><br><span class="line">	println( &quot;Value of a: &quot; + a );</span><br><span class="line">&#125;</span><br><span class="line">1....9</span><br><span class="line"></span><br><span class="line">--两层嵌套</span><br><span class="line">for( a &lt;- 1 to 3; b &lt;- 1 to 3)&#123;    </span><br><span class="line">	println( &quot;Value of a: &quot; + a );    </span><br><span class="line">	println( &quot;Value of b: &quot; + b );</span><br><span class="line">&#125;</span><br><span class="line">外层a  内层b</span><br><span class="line"></span><br><span class="line">-- 集合用法</span><br><span class="line">var a = 0;</span><br><span class="line">val numList = List(1,2,3,4,5,6,7,8,9);</span><br><span class="line">for( a &lt;- numList )&#123;	</span><br><span class="line">	println( &quot;Value of a: &quot; + a );</span><br><span class="line">&#125;</span><br><span class="line">for 循环会迭代所有集合的元素。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- for 循环过滤 3以及大于等于8的</span><br><span class="line">for( a &lt;- numList	if a != 3; if a &lt; 8 )&#123;	</span><br><span class="line">	println( &quot;Value of a: &quot; + a );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">-- for 使用 yield 将for循环的返回值作为一个变量存储。</span><br><span class="line">var retVal = for&#123; a &lt;- numList 	if a != 3; if a &lt; 8&#125;yield a</span><br><span class="line"></span><br><span class="line">for( a &lt;- retVal)&#123;	</span><br><span class="line">	println( &quot;Value of a: &quot; + a );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-方法和函数"><a href="#3-方法和函数" class="headerlink" title="3. 方法和函数"></a>3. 方法和函数</h2><p>Scala 有方法与函数，二者在语义上的区别很小。Scala <strong>方法是类的一部分</strong>，而<strong>函数是一个对象可以赋值给一个变量</strong>。</p>
<p>总结一下就是—–在类中定义的函数即是方法。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Test&#123;  </span><br><span class="line">	def m(x: Int) = x + 3 //方法  </span><br><span class="line">	val f = (x: Int) =&gt; x + 3 //函数</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-方法调用"><a href="#3-1-方法调用" class="headerlink" title="3.1 方法调用"></a>3.1 方法调用</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object Test &#123;   </span><br><span class="line">	def main(args: Array[String]) &#123;        </span><br><span class="line">		println( &quot;Returned Value : &quot; + addInt(5,7) );   </span><br><span class="line">	&#125;   </span><br><span class="line">	def addInt( a:Int, b:Int ) : Int = &#123;      </span><br><span class="line">		var sum:Int = 0      </span><br><span class="line">		sum = a + b      </span><br><span class="line">		return sum   </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-闭包"><a href="#3-2-闭包" class="headerlink" title="3.2 闭包"></a>3.2 闭包</h3><p><strong>闭包是一个函数</strong>，返回值依赖于<strong>声明在函数外部的一个或多个变量</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//一般情况</span><br><span class="line">val multiplier = (i:Int) =&gt; i * 10</span><br><span class="line">//由变量 factor 定义在函数外面，</span><br><span class="line">var factor = 3  </span><br><span class="line">val multiplier = (i:Int) =&gt; i * factor</span><br><span class="line"></span><br><span class="line">/* 这样定义的函数变量 multiplier 成为一个&quot;闭包&quot;，</span><br><span class="line">因为它引用到函数外面定义的变量，</span><br><span class="line">定义这个函数的过程是将这个自由变量捕获而构成一个封闭的函数。*/</span><br></pre></td></tr></table></figure>

<h2 id="4-常用数据结构"><a href="#4-常用数据结构" class="headerlink" title="4. 常用数据结构"></a>4. 常用数据结构</h2><h3 id="4-1-字符串"><a href="#4-1-字符串" class="headerlink" title="4.1 字符串"></a>4.1 字符串</h3><p>常用的记一下，用的时候再查。</p>
<ul>
<li><p>字符串拼接。string1.concat(string2);</p>
</li>
<li><p>创建格式化字符串。使用 printf() 方法来格式化字符串并输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var floatVar = 12.456</span><br><span class="line">var intVar = 2000</span><br><span class="line">var stringVar = &quot;菜鸟教程!&quot;</span><br><span class="line"></span><br><span class="line">var fs = printf(&quot;浮点型变量为 &quot;+&quot;%f, 整型变量为 %d, 字符串为 &quot;+&quot; %s&quot;, floatVar, intVar, stringVar)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="4-2-数组"><a href="#4-2-数组" class="headerlink" title="4.2 数组"></a>4.2 数组</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var z:Array[String] = new Array[String](3)</span><br><span class="line">或</span><br><span class="line">var z = new Array[String](3)</span><br><span class="line"></span><br><span class="line">//多维数组</span><br><span class="line">var myMatrix = ofDim[Int](3,3)</span><br><span class="line"></span><br><span class="line">//创建区间数组</span><br><span class="line">var myList1 = range(10, 20, 2) --  10 - 18的偶数</span><br><span class="line">var myList2 = range(10,20) --   10 - 19</span><br><span class="line"></span><br><span class="line">// 查找数组中的最大元素</span><br><span class="line">var max = myList(0);</span><br><span class="line">for ( i &lt;- 1 to (myList.length - 1) ) &#123;	</span><br><span class="line">	if (myList(i) &gt; max) </span><br><span class="line">		max = myList(i);</span><br><span class="line">&#125;</span><br><span class="line">println(&quot;最大值为 &quot; + max);</span><br><span class="line"></span><br><span class="line">//合并数组</span><br><span class="line">var myList3 =  concat( myList1, myList2)</span><br></pre></td></tr></table></figure>

<h3 id="4-3-集合"><a href="#4-3-集合" class="headerlink" title="4.3 集合"></a>4.3 集合</h3><ul>
<li><p>使用(:+)和(+:)，向后向前追加元素到序列。</p>
</li>
<li><p>(+)元素到<strong>无先后次序的集合</strong>中。</p>
</li>
<li><p>用 - 移除元素</p>
</li>
<li><p>用 ++ 和 – 批量添加和移除元素</p>
</li>
<li><p>对于<strong>列表</strong>优先使用 :: 和 :::</p>
</li>
<li><p>改值操作 +&#x3D;，++&#x3D;，-&#x3D;，–&#x3D;</p>
</li>
<li><p>对于集合更倾向于 ++ 、&amp; 和 –</p>
</li>
<li><p>尽量不要使用 ++：，+&#x3D;：，++&#x3D;：</p>
<p>对于列表，可以使用+&#x3D; 而不用:: 保持与其他集合操作的一致性，但有一个例外：</p>
<p>模式匹配（case h::t）不认+：操作符。</p>
</li>
</ul>
<h4 id="4-3-1-List"><a href="#4-3-1-List" class="headerlink" title="4.3.1 List"></a>4.3.1 List</h4><p>元素以线性方式存储，集合中可以存放重复对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val x = List(1,2,3,4)::添加元素:::链表拼接</span><br></pre></td></tr></table></figure>

<h4 id="4-3-2-Set"><a href="#4-3-2-Set" class="headerlink" title="4.3.2 Set"></a>4.3.2 Set</h4><p>集合中的对象不按特定的方式排序，并且没有重复对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val x = Set(1,3,5,7)+ 添加元素++ 集合拼接</span><br></pre></td></tr></table></figure>

<h4 id="4-3-3-Map"><a href="#4-3-3-Map" class="headerlink" title="4.3.3 Map"></a>4.3.3 Map</h4><p>它的每一个元素都包含一对键对象和值对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val x = Map(&quot;one&quot; -&gt; 1, &quot;two&quot; -&gt; 2, &quot;three&quot; -&gt; 3)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-4-元组"><a href="#4-3-4-元组" class="headerlink" title="4.3.4 元组"></a>4.3.4 元组</h4><p>元组不可变，且是不同类型的值的集合</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val x = (10, &quot;Runoob&quot;)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-5-迭代器"><a href="#4-3-5-迭代器" class="headerlink" title="4.3.5 迭代器"></a>4.3.5 迭代器</h4><p>迭代器不是一个容器，更确切的说是逐一访问容器内元素的方法。</p>
<h4 id="4-3-5-Option"><a href="#4-3-5-Option" class="headerlink" title="4.3.5 Option"></a>4.3.5 Option</h4><p>Option[T] 表示有可能包含值的容器，也可能不包含值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val x:Option[Int] = Some(5)</span><br></pre></td></tr></table></figure>

<p>Map类的get方法返回一个Option。如果对于一个给定的键没有对应的值，就会返回None, 如果有值，返回。</p>
<h2 id="5-类"><a href="#5-类" class="headerlink" title="5. 类"></a>5. 类</h2><p>Scala中的类不声明为public，一个Scala源文件中可以有多个类。</p>
<ul>
<li><p>构造器</p>
<p><strong>一个类如果没有显示定义主构造器则会自动拥有一个无参主构造器。</strong></p>
<p>scala 的 类中 有一个主构造器 和 多个 辅助构造器。</p>
<ul>
<li><p><strong>辅助构造器</strong></p>
<ol>
<li>辅助构造器的<strong>名称为this</strong>.</li>
<li>每一个辅助构造器都必须以一个先前已经定义好的其他辅助构造器或主构造器的<strong>调用开始</strong>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Person&#123;    </span><br><span class="line">	private var name = &quot;&quot;    </span><br><span class="line">	private var age = 0    </span><br><span class="line">	def this(name:String)&#123;//一个辅助构造器       </span><br><span class="line">		this() //调用主构造器       </span><br><span class="line">		this.name = name    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	def this(name:String, age:Int)&#123;//另一个辅助构造器       </span><br><span class="line">		this(name) //调用上一个辅助构造器       </span><br><span class="line">		this.age = age    </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">三种不同的方式构建对象：</span><br><span class="line">val p1 = new Person //主构造器</span><br><span class="line">val p2 = new Person(&quot;Fred&quot;) //第一个辅助构造器v</span><br><span class="line">al p3 = new Person(&quot;Fred&quot;,42) //第二个辅助主构造器</span><br></pre></td></tr></table></figure>
</li>
<li><p>主构造器</p>
<p>主构造器不以this方法定义，<strong>与类定义交织在一起</strong>。如果类名之后没有参数，则该类具备一个无参主构造器。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Person(val name:String, val age:Int)&#123; //(...)中的内容就是主构造器的参数</span><br><span class="line">	println(&quot;constrcture&quot;)    </span><br><span class="line">	def description = name + &quot; is&quot; + age + &quot; years old&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">主构造器会执行类定义中的所有语句</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="5-1-继承"><a href="#5-1-继承" class="headerlink" title="5.1 继承"></a>5.1 继承</h3><p>Scala继承一个基类跟Java很相似, 但我们需要注意以下几点：</p>
<ul>
<li><strong>在子类中重写超类的抽象方法时，你不需要使用override关键字。</strong></li>
<li><strong>重写一个非抽象方法必须使用override修饰符。</strong></li>
<li><strong>只有主构造函数才可以往基类的构造函数里写参数。</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Scala 使用 extends 关键字来继承一个类。</span><br><span class="line">实例中 Location 类继承了 Point 类。Point 称为父类(基类)，Location 称为子类。	</span><br><span class="line">override val xc 为重写了父类的字段。	</span><br><span class="line">继承会继承父类的所有属性和方法，Scala 只允许继承一个父类。</span><br><span class="line"></span><br><span class="line">class Point(xc: Int, yc: Int) &#123;   </span><br><span class="line">	var x: Int = xc   </span><br><span class="line">	var y: Int = yc   </span><br><span class="line">	</span><br><span class="line">	def move(dx: Int, dy: Int) &#123;      </span><br><span class="line">		x = x + dx      </span><br><span class="line">		y = y + dy      </span><br><span class="line">		println (&quot;x 的坐标点: &quot; + x);      </span><br><span class="line">		println (&quot;y 的坐标点: &quot; + y);   </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Location(override val xc: Int, override val yc: Int, val zc :Int) extends Point(xc, yc)&#123;   </span><br><span class="line">	var z: Int = zc   </span><br><span class="line">	</span><br><span class="line">	def move(dx: Int, dy: Int, dz: Int) &#123;      </span><br><span class="line">		x = x + dx     </span><br><span class="line">        y = y + dy      </span><br><span class="line">        z = z + dz      </span><br><span class="line">        println (&quot;x 的坐标点 : &quot; + x);      </span><br><span class="line">        println (&quot;y 的坐标点 : &quot; + y);      </span><br><span class="line">        println (&quot;z 的坐标点 : &quot; + z);   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-单例对象"><a href="#5-2-单例对象" class="headerlink" title="5.2 单例对象"></a>5.2 单例对象</h3><p>在 Scala 中，是没有 static 。使用<strong>关键字 object</strong> 提供单例模式的实现方法。</p>
<p>Scala 中<strong>使用单例模式时</strong>，除了定义的类之外，还要定义一个<strong>同名的 object 对象</strong>（伴生对象），它和类的区别是，object对象不能带参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">文件名：Marker.scala</span><br><span class="line"></span><br><span class="line">class Marker private(val color:String) &#123;  </span><br><span class="line">	println(&quot;创建&quot; + this)    </span><br><span class="line">	</span><br><span class="line">	override def toString(): String = &quot;颜色标记：&quot;+ color  </span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 伴生对象，与类名字相同，可以访问类的私有属性和方法</span><br><span class="line">object Marker&#123;      </span><br><span class="line">	private val markers: Map[String, Marker] = Map(      </span><br><span class="line">		&quot;red&quot; -&gt; new Marker(&quot;red&quot;),      </span><br><span class="line">		&quot;blue&quot; -&gt; new Marker(&quot;blue&quot;),      </span><br><span class="line">		&quot;green&quot; -&gt; new Marker(&quot;green&quot;)    </span><br><span class="line">	)        </span><br><span class="line">	</span><br><span class="line">	def apply(color:String) = &#123;      </span><br><span class="line">		if(markers.contains(color)) </span><br><span class="line">			markers(color) else null    </span><br><span class="line">	&#125;          </span><br><span class="line">	</span><br><span class="line">	def getMarker(color:String) = &#123;       </span><br><span class="line">		if(markers.contains(color)) </span><br><span class="line">			markers(color) else null    </span><br><span class="line">		&#125;    </span><br><span class="line">		</span><br><span class="line">	def main(args: Array[String]) &#123;         </span><br><span class="line">		println(Marker(&quot;red&quot;))          </span><br><span class="line">		// 单例函数调用，省略了.(点)符号          </span><br><span class="line">		println(Marker getMarker &quot;blue&quot;)      </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ scalac Marker.scala </span><br><span class="line">$ scala Marker</span><br></pre></td></tr></table></figure>

<h3 id="5-3-密封类"><a href="#5-3-密封类" class="headerlink" title="5.3 密封类"></a>5.3 密封类</h3><p>sealed 修饰的类，为密封类。</p>
<p>密封类的所有子类都必须在与该密封类<strong>相同的文件中定义</strong>。</p>
<p>如果一个类是密封的，在编译期所有的子类就是可知的，因此编译器可以检查模式语句的完整性。</p>
<h2 id="6-更好的switch"><a href="#6-更好的switch" class="headerlink" title="6. 更好的switch"></a>6. 更好的switch</h2><p>—match</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def matchTest(x: Char): String = x match &#123;    </span><br><span class="line">	case &#x27;+&#x27; =&gt; 1    </span><br><span class="line">	case &#x27;-&#x27; =&gt; -1    </span><br><span class="line">	case _ =&gt; 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//简化代码</span><br><span class="line">var charac = x match&#123;    </span><br><span class="line">	case &#x27;+&#x27; =&gt; 1    </span><br><span class="line">	case &#x27;-&#x27; =&gt; -1    </span><br><span class="line">	case _ =&gt; 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//守卫</span><br><span class="line">可以匹配符合定义的条件</span><br><span class="line">var charac = x match&#123;    </span><br><span class="line">	case &#x27;+&#x27; =&gt; 1    </span><br><span class="line">	case &#x27;-&#x27; =&gt; -1    </span><br><span class="line">	case _ if Character.isDigit(ch) =&gt; Character.isDigit(ch, 10)    </span><br><span class="line">	case _ =&gt; 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-高阶函数"><a href="#7-高阶函数" class="headerlink" title="7. 高阶函数"></a>7. 高阶函数</h2><p><strong>接收函数参数的函数称为高阶函数</strong>。</p>
<ul>
<li><p>带函数参数的函数</p>
<p>def valueAtOneQuarter(f: (Double)&#x3D;&gt;Double) &#x3D; f(0.25)</p>
<p>这里的参数是任何接受Double并返回Double的函数。</p>
<p>例如： valueAtOneQuarter（ceil _）&#x2F;&#x2F;1.0</p>
<p>valueAtOneQuarter（sqrt _） &#x2F;&#x2F;0.5</p>
<p>高阶函数产出一个函数：</p>
<p>def mulBy(factor: Double) &#x3D; (x: Double) &#x3D;&gt; factor * x</p>
<p>val quintuple &#x3D; mulBy(5) &#x2F;&#x2F;这里返回给quintuple的是一个能接受Double参数的函数</p>
<p>quintuple(20) &#x2F;&#x2F;调用函数</p>
</li>
<li><p>参数类型推断</p>
<p>将一个匿名函数传递给一个函数</p>
<p>def valueAtOneQuarter(（x : Double） &#x3D;&gt; 3 * x)</p>
<p>简写1：def valueAtOneQuarter(（x） &#x3D;&gt; 3 * x)</p>
<p>简写2：def valueAtOneQuarter(x &#x3D;&gt; 3 * x) &#x2F;&#x2F;一个参数的情况</p>
<p>简写2：def valueAtOneQuarter(3 * _) &#x2F;&#x2F;一个参数的情况</p>
<p>PS:这种写法仅在参数类型已知的情况下。</p>
<p>val fun &#x3D; 3 * _ &#x2F;&#x2F;错误</p>
<p>val fun &#x3D; 3 * (_: Double) &#x2F;&#x2F;正确</p>
</li>
<li><p>柯里化</p>
<p>将原来接受两个参数的函数 变成 新的接受一个参数的函数的过程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def mul(x:Int, y:Int) = x*y</span><br><span class="line"></span><br><span class="line">以下函数接受一个参数，生成另一个接受单个参数的函数</span><br><span class="line">def mulOneAtTime(x:Int) = (y:Int)=&gt;x*y</span><br><span class="line"></span><br><span class="line">调用： mulOneAtTime(6)(7) </span><br><span class="line">mulOneAtTime(6)返回结果是函数 (y:Int)=&gt;6*y，然后应用到7得到42  </span><br><span class="line"></span><br><span class="line">scala支持简写：****这样的函数成为柯里化 </span><br><span class="line">def mulOneAtTime(x:Int)(y:Int)=&gt;x*y</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">函数式编程实现 立方和，平方和以及阶乘和</span><br><span class="line"></span><br><span class="line">//一个高阶函数实现相同的求和逻辑</span><br><span class="line">def sum(f:Int =&gt; Int)(a:Int, b:Int):Int = if(a&gt;b) 0 else f(a)+sum(f)(a+1,b)</span><br><span class="line"></span><br><span class="line">//柯里化后的sum函数</span><br><span class="line">def sum(f:Int =&gt; Int)(a:Int)(b:Int):Int = if(a&gt;b) 0 else f(a)+sum(f)(a+1)(b)</span><br><span class="line"></span><br><span class="line">//定义复杂函数 阶乘</span><br><span class="line">def fact(n:Int):Int = if（n==0）1 else n*fact(n-1)</span><br><span class="line"></span><br><span class="line">//直接调用高阶函数实现1-10 立方和，平方和以及阶乘和</span><br><span class="line">sum(x =&gt; x*x*x)(1,10)</span><br><span class="line">sum(x =&gt; x*x)(1,10)</span><br><span class="line">sum(x =&gt; fact)(1,10)</span><br><span class="line"></span><br><span class="line">//柯里化后调用</span><br><span class="line">sum(x =&gt; x*x*x)(1)(10)</span><br><span class="line">sum(x =&gt; x*x)(1)(10)</span><br><span class="line">sum(x =&gt; fact)(1)(10)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="8-隐式转换和隐式参数"><a href="#8-隐式转换和隐式参数" class="headerlink" title="8. 隐式转换和隐式参数"></a>8. 隐式转换和隐式参数</h2><ul>
<li>隐式转换用于类型之间的转换</li>
<li>隐式参数列表会要求指定类型的对象。</li>
<li>如果隐式参数是一个单参数的函数，他同时也会被当作隐式转换使用。</li>
</ul>
<h3 id="8-1隐式转换"><a href="#8-1隐式转换" class="headerlink" title="8.1隐式转换"></a>8.1隐式转换</h3><p>所谓隐式转换是指以<strong>implicit关键字声明</strong>的带有单个参数的函数。</p>
<p>这样的函数将会被<strong>自动应用</strong>，<strong>将值的一种类型转换为另一种类型</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">implicit def int2Fraction(n:Int) = Fraction(n,1)</span><br><span class="line"></span><br><span class="line">var result = 3 * Fraction(4,5) </span><br><span class="line">//这里将调用int2Fraction</span><br><span class="line">//这里的隐式转换本质是 此函数 函数名不变，但是执行的行为是转换过的行为。</span><br></pre></td></tr></table></figure>

<h2 id="9-Spark-Scala-算子"><a href="#9-Spark-Scala-算子" class="headerlink" title="9. Spark-Scala 算子"></a>9. Spark-Scala 算子</h2><p>主要将算子分为两大类：Transformations算子 和 Action算子</p>
<p>Transformations算子：</p>
<p>map, </p>
<p>flatmap,</p>
<p> filter, </p>
<p>reduceByKey,</p>
<p>sortBy, </p>
<p>sortByKey, </p>
<p>sample抽样, </p>
<p>join,</p>
<p> leftOuterJoin, </p>
<p>rightOutJoin,</p>
<p>union, </p>
<p>intersection, </p>
<p>subtract, </p>
<p>mapPartitions, </p>
<p>distinct(map+reduceByKey+map), </p>
<p>cogroup, </p>
<p>mapPartitionsWithIndex, </p>
<p>repartition, </p>
<p>zip,</p>
<p>zipwithindex </p>
<p><strong>大致16个</strong></p>
<p>Action算子：</p>
<p>count,</p>
<p>collect, </p>
<p>first, </p>
<p>take, </p>
<p>foreachPartition,</p>
<p> reduce,</p>
<p>countByKey,</p>
<p>countByValue </p>
<p><strong>大致6个</strong></p>
<h3 id="9-1-Transformations算子"><a href="#9-1-Transformations算子" class="headerlink" title="9.1 Transformations算子"></a>9.1 Transformations算子</h3><p>Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。</p>
<h4 id="9-1-1-map-一对一"><a href="#9-1-1-map-一对一" class="headerlink" title="9.1.1 map 一对一"></a>9.1.1 map 一对一</h4><ul>
<li><p>特点：一进一出</p>
</li>
<li><pre><code>lines.map(_+&quot;#&quot;).foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  mapValues</span><br><span class="line"></span><br><span class="line">- 该操作只改动value, 不改变key</span><br><span class="line"></span><br><span class="line">#### 9.1.2 flatMap 一对多</span><br><span class="line"></span><br><span class="line">- 特点：一进多出， 比如按空格split</span><br><span class="line"></span><br></pre></td></tr></table></figure>
lines.flatMap(_.split(&quot; &quot;)).foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- flatMapValues</span><br><span class="line"></span><br><span class="line">- 只操作value, 不改变key</span><br><span class="line"></span><br><span class="line">#### 9.1.3 filter过滤</span><br><span class="line"></span><br><span class="line">- 特点：一进，符合定义规则的出去</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val rdd1 = lines.flatMap(_.split(&quot; &quot;))

rdd1.filter(&quot;hello&quot;.equals(_)).foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.4 reduceByKey和sortBy</span><br><span class="line"></span><br><span class="line">- reduceByKey相当于MR的reduce过程，将相同的key聚合，并执行逻辑。聚合的时候是要对RDD排序的，默认是升序的，如果要想实现降序排列就要用到sortBy了。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val words = lines.flatMap(_.split(&quot; &quot;))

val pairWords = words.map((_,1))

val result = pairWords.reduceByKey(_+_)

result.sortBy(_._2,false).foreach(println) //降序
result.sortBy(_._2).foreach(println) //升序
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.5 sortByKey</span><br><span class="line"></span><br><span class="line">- 使用sortByKey实现sortBy的功能：“hello world”—&gt;“hello” “world”—&gt;（hello，1） （world，1）</span><br><span class="line"></span><br><span class="line">  关键的时候来了，利用tuple的swap反转，（hello 1）—&gt;（1，hello）</span><br><span class="line"></span><br><span class="line">  使用sortByKey来进行排序，然后再利用一次反转</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val words = lines.flatMap(_.split(&quot; &quot;))

val pairWords = words.map((_,1))

val result = pairWords.reduceByKey(_+_)

val transRDD = result.map(_.swap) //反转key value，string，int  变 int，string

val r = transRDD.sortByKey(false) //降序

r.map(_.swap).foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.6 sample 抽样</span><br><span class="line"></span><br><span class="line">- 抽样算子</span><br><span class="line"></span><br></pre></td></tr></table></figure>
/*** sample算子抽样
* true:抽出来一个，完事再放回去，再继续抽。即又放回抽样
* 0.1:抽样的比例 10%
* 100L:指定种子，抽到的数据不管运行多少次都一样
*/

val result = lines.sample(true,0.1,100L)result.foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 9.1.6 join</span><br><span class="line"></span><br><span class="line">- 等值连接 (k,v) (k,w)—&gt;(k,(v,w))，k相同的join在一起</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.join(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 左外连接 leftOuterJoin 以左为主，没有的用None占位</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.leftOuterJoin(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 右外连接rightOuterJoin 以右为主，没有的用None占位</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.rightOuterJoin(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 9.1.7 union</span><br><span class="line"></span><br><span class="line">- 合并两个数据集，类型要一致</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.union(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 9.1.8 intersection</span><br><span class="line"></span><br><span class="line">- 取两个RDD的交集</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.intersection(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 9.1.9 subtract</span><br><span class="line"></span><br><span class="line">- 取差集</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.subtract(rdd2)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 9.1.10 mapPartitions</span><br><span class="line"></span><br><span class="line">- 和map类似，遍历的单位是每个partition上的数据</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.mapPartitions(iter=&gt;&#123;	
    val listBuffer = new ListBuffer[String]()	
    println(&quot;打开&quot;)	
    while (iter.hasNext)&#123;		
        val s = iter.next()		
        println(&quot;插入 &quot;+s)		
        listBuffer.append(s+&quot; #&quot;)	
    &#125;	
    println(&quot;关闭&quot;)	
    listBuffer.iterator
&#125;)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.11 distinct</span><br><span class="line"></span><br><span class="line">- 去重算子（先按照partition去重，总体去重） 流程大致相当于 ，map+reduceByKey+map</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val rdd1 = sc.makeRDD(Array[String](&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;d&quot;, &quot;e&quot;, &quot;a&quot;, &quot;b&quot;))

val result = rdd1.distinct()

val result = rdd1.map((_,1)).reduceByKey(_+_).map(_._1)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.12 cogroup</span><br><span class="line"></span><br><span class="line">- 对多个RDD中的KV元素，每个RDD中相同key中的元素分别聚合成一个集合CompactBuffer。</span><br><span class="line"></span><br><span class="line">  然后将不同RDD的相同key的CompactBuffer（类似链表）组成新的values(类似于集合数组)</span><br><span class="line"></span><br><span class="line">  与reduceByKey不同的是针对两个RDD中相同的key的元素进行合并。(可以运行下示例就能清楚的理解)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = rdd1.cogroup(rdd2,rdd3) //三个rdd都是 key value形式数据

例如：
val DBName=Array(  
    Tuple2(1,&quot;Spark&quot;),  
    Tuple2(2,&quot;Hadoop&quot;),  
    Tuple2(3,&quot;Kylin&quot;),  
    Tuple2(4,&quot;Flink&quot;)
)
    
val numType=Array(  
    Tuple2(1,&quot;String&quot;),  
    Tuple2(2,&quot;int&quot;),  
    Tuple2(3,&quot;byte&quot;),  
    Tuple2(4,&quot;bollean&quot;),  
    Tuple2(5,&quot;float&quot;),  
    Tuple2(1,&quot;34&quot;),  
    Tuple2(1,&quot;45&quot;),  
    Tuple2(2,&quot;47&quot;),  
    Tuple2(3,&quot;75&quot;), 
    Tuple2(4,&quot;95&quot;),  
    Tuple2(5,&quot;16&quot;), 
    Tuple2(1,&quot;85&quot;)
)

val names=sc.parallelize(DBName)
val types=sc.parallelize(numType)
val nameAndType=names.cogroup(types)

nameAndType.collect.foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.13 mapPartitionsWithIndex</span><br><span class="line"></span><br><span class="line">- index 分区号，iter 分区号下的数据</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val rdd2 = rdd1.mapPartitionsWithIndex((index,iter)=&gt;&#123;    
    val list = new ListBuffer[String]()    
    while(iter.hasNext)&#123;        
        val elem = iter.next()        
        list += (s&quot;rdd1 partition = $index, value = $elem&quot;)    
    &#125;    
    list.iterator
&#125;)

rdd2.foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.14 repartition 和 coalesce</span><br><span class="line"></span><br><span class="line">coalesce()：对RDD的分区进行再在分区，（用于分区数据分布不均匀的情况，利用HashPartitioner函数将数据重新分区）</span><br><span class="line"></span><br><span class="line">reparation：与coalesce功能一样，它只是coalesce中shuffle设置为true的简易实现。（数据不经过shuffle是无法将RDD的分区变多的）</span><br><span class="line"></span><br><span class="line">- 可以增多或者减少分区。宽依赖算子，会产生shuffle;</span><br><span class="line"></span><br><span class="line">- 区别于coalesce，coalesce同样可能增加、减少分区。</span><br><span class="line"></span><br><span class="line">- 但是coalesce是窄依赖算子，默认无shuffle，可通过设置true来开启。</span><br><span class="line"></span><br><span class="line">- 可以变相的理解为：repartition常用于增多分区，coalesce常用于减少分区。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val rdd3 = rdd2.repartition(3)

rdd3.mapPartitionsWithIndex((index, iter) =&gt; &#123;	
    val list = new ListBuffer[String]()	
    while (iter.hasNext) &#123;		
        val one = iter.next()		
        list += (s&quot;rdd1 partition = $index ,value = $one&quot;)	
    &#125;	
    list.iterator
&#125;).foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.15 zip&amp;zipwithindex</span><br><span class="line"></span><br><span class="line">- zip:两个RDD可以通过zip压缩在一起，一一对应</span><br><span class="line"></span><br><span class="line">- zipwithindex：RDD的值和各自的下标压缩在一起，形成K-V格式RDD。如：(a,0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
rdd1.zip(rdd2).foreach(println)

val rdd = rdd1.zipWithIndex()

rdd.foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.1.16 其他</span><br><span class="line"></span><br><span class="line">- lookup()</span><br><span class="line"></span><br><span class="line">  查询指定的key, 返回其对应的value</span><br><span class="line"></span><br><span class="line">- top</span><br><span class="line"></span><br><span class="line">  返回最大的k个元素</span><br><span class="line"></span><br><span class="line">- saveAsTextFile</span><br><span class="line"></span><br><span class="line">  将数据输出，存储到 HDFS 的指定目录</span><br><span class="line"></span><br><span class="line">- cache</span><br><span class="line"></span><br><span class="line">  将 RDD 元素从磁盘缓存到内存</span><br><span class="line"></span><br><span class="line">  内部默认会调用persist(StorageLevel.MEMORY_ONLY)，也就是说它无法自定义缓存级别的。</span><br><span class="line"></span><br><span class="line">- persist()</span><br><span class="line"></span><br><span class="line">  与cache一样都是将一个RDD进行缓存，在之后的使用过程汇总不需要重新的计算了。它比cache灵活，可以通过自定义StorageLevel类型参数，来定义缓存的级别。</span><br><span class="line"></span><br><span class="line">\###9.2 Action算子</span><br><span class="line"></span><br><span class="line">#### 9.2.1 count</span><br><span class="line"></span><br><span class="line">- 计算数据的个数</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val linecount = lines.count()

println(linecount)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.2.2 collect</span><br><span class="line"></span><br><span class="line">- 回收计算结果到Driver端的内存</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = lines.collect().foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.2.3 first</span><br><span class="line"></span><br><span class="line">- 取第一条数据。由take(1)实现</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = lines.first()

println(result)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.2.4 take</span><br><span class="line"></span><br><span class="line">- 取指定行的数据</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = lines.take(5)

result.foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.2.5 foreachPartition</span><br><span class="line"></span><br><span class="line">- 遍历每个partition上的数据</span><br><span class="line"></span><br></pre></td></tr></table></figure>
rdd1.foreachPartition(iter=&gt;&#123;	
    println(&quot;开始&quot;)	
    while (iter.hasNext)&#123;		
        val s = iter.next()		
        println(&quot;插入：&quot;+s)	
    &#125;	
    
    println(&quot;结束&quot;)
&#125;)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 9.2.6 reduce&amp;countByKey&amp;countByValue</span><br><span class="line"></span><br><span class="line">- reduce 聚合执行对应的逻辑</span><br><span class="line"></span><br></pre></td></tr></table></figure>
val result = sc.parallelize(List[Int](1,2,3,4,5)).reduce(_+_)

println(result)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">- countByKey 按照key分组，count每个key 对应value的个数</span><br><span class="line"></span><br></pre></td></tr></table></figure>
sc.parallelize(List[(String,Int)]((&quot;a&quot;,100),(&quot;b&quot;,200),(&quot;a&quot;,300),(&quot;d&quot;,400))).countByKey().foreach(println)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">- countByValue: (key,value)整体 进行分组，计算出现次数。输出：((a,100),2)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
sc.parallelize(List[(String,Int)]((&quot;a&quot;,100),(&quot;b&quot;,200),(&quot;a&quot;,300),(&quot;a&quot;,100),(&quot;d&quot;,400))).countByValue().foreach(println)
</code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo start!</title>
    <url>/2018/01/10/hexo-start/</url>
    <content><![CDATA[<h1 id="搭建博客（采用hexo框架-部署到github）"><a href="#搭建博客（采用hexo框架-部署到github）" class="headerlink" title="搭建博客（采用hexo框架+部署到github）"></a>搭建博客（采用hexo框架+部署到github）</h1><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><h3 id="1-下载git"><a href="#1-下载git" class="headerlink" title="1. 下载git"></a>1. 下载git</h3><p>官网下载:  <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></p>
<p>安装与使用：见git笔记</p>
<p>安装后验证：git  –version</p>
<p>安装好git后， 后续命令均采用 git bash 执行。</p>
<h3 id="2-下载并安装node-js"><a href="#2-下载并安装node-js" class="headerlink" title="2. 下载并安装node.js"></a>2. 下载并安装node.js</h3><p>官网下载：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></p>
<p>安装与使用：见node笔记</p>
<p>安装后验证：node -v </p>
<h3 id="3-命令行安装cnpm"><a href="#3-命令行安装cnpm" class="headerlink" title="3. 命令行安装cnpm"></a>3. 命令行安装cnpm</h3><p>命令：npm install -g cnpm –registry&#x3D;&#x3D;<a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a></p>
<p>安装后验证：cnpm -v </p>
<h3 id="4-命令行安装hexo"><a href="#4-命令行安装hexo" class="headerlink" title="4. 命令行安装hexo"></a>4. 命令行安装hexo</h3><p>命令：cnpm install -g hexo-cli</p>
<p>安装后验证：hexo  -v</p>
<h3 id="5-在github上创建仓库"><a href="#5-在github上创建仓库" class="headerlink" title="5. 在github上创建仓库"></a>5. 在github上创建仓库</h3><p>新建一个名为你的用户名.github.io的仓库</p>
<p>比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 <a href="http://test.github.io/">http://test.github.io</a> 了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 配置SSH免密登录</span><br><span class="line">第一步：首先打开电脑文件夹，找到C:\Users\bona\.ssh文件夹并删除</span><br><span class="line"></span><br><span class="line">第二步：在C:\Users\bona 文件夹下右键打开Git Bash Here</span><br><span class="line">输入命令：ssh-keygen -t rsa -C github邮件地址   </span><br><span class="line">生成.ssh秘钥，输入后连敲三次回车</span><br><span class="line"></span><br><span class="line">第三步：最终生成了一个新的 C:\Users\bona\.ssh文件夹，打开这个文件夹，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容</span><br><span class="line"></span><br><span class="line">第四步：打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key，把复制的内容粘贴进去，title随便填，保存即可，我们的公钥就添加成功了</span><br><span class="line"></span><br><span class="line">第五步：检测是否设置成功：</span><br><span class="line">输入命令：  $ ssh -T git@github.com # 注意邮箱地址不用改</span><br><span class="line">如果提示Are you sure you want to continue connecting (yes/no)?，输入yes，然后会看到：</span><br><span class="line">Hi fenghuayangyi! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br><span class="line">看到这个信息说明SSH已配置成功！</span><br><span class="line"></span><br><span class="line">第六步：此时你还需要配置：</span><br><span class="line">$ git config --global user.name &quot;bona&quot;// 你的github用户名，非昵称</span><br><span class="line">$ git config --global user.email  &quot;bona@126.com&quot;// 填写你的github注册邮箱</span><br></pre></td></tr></table></figure>

<h2 id="使用-hexo搭建博客"><a href="#使用-hexo搭建博客" class="headerlink" title="使用 hexo搭建博客"></a>使用 hexo搭建博客</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><ul>
<li><p>新建文件夹 note</p>
</li>
<li><p>git bash</p>
<ul>
<li><p>hexo init</p>
</li>
<li><p>hexo g # 生成</p>
</li>
<li><p>hexo s  #启动服务， 打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容</p>
<p>如果端口冲突，参考这篇文章<a href="https://www.runoob.com/w3cnote/windows-finds-port-usage.html">https://www.runoob.com/w3cnote/windows-finds-port-usage.html</a></p>
</li>
</ul>
</li>
</ul>
<h3 id="npm组件-amp-hexo配置"><a href="#npm组件-amp-hexo配置" class="headerlink" title="npm组件 &amp; hexo配置"></a>npm组件 &amp; hexo配置</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hexo 会默认安装：</span><br><span class="line"></span><br><span class="line">hexo：主程序</span><br><span class="line"></span><br><span class="line">hexo-deployer-git：实现 git 部署方式</span><br><span class="line"></span><br><span class="line">hexo-generator-archive：存档页面生成器</span><br><span class="line"></span><br><span class="line">hexo-generator-category：分类页面生成器</span><br><span class="line"></span><br><span class="line">hexo-generator-index：index 生成器</span><br><span class="line"></span><br><span class="line">hexo-generator-tag：标签页面生成器</span><br><span class="line"></span><br><span class="line">hexo-renderer-ejs：支持 EJS 渲染</span><br><span class="line"></span><br><span class="line">hexo-renderer-marked：Markdown 引擎</span><br><span class="line"></span><br><span class="line">hexo-renderer-stylus：支持 stylus 渲染</span><br><span class="line"></span><br><span class="line">hexo-server：支持本地预览，默认地址 localhost:4000</span><br></pre></td></tr></table></figure>



<ul>
<li><p>npm install hexo-deployer-git –save</p>
<p>必须安装后，才能使用 : hexo d</p>
</li>
<li><p>编辑 hexocode目录下的 _config.yml 文件, 在文件末尾添加如下内容</p>
<p>deploy:<br>  type: ‘git’<br>  repository: <a href="mailto:&#x67;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#99;&#x6f;&#109;">&#x67;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#99;&#x6f;&#109;</a>:zshlovely&#x2F;zshlovely.github.io.git<br>  branch: master</p>
</li>
<li><p>报错和 time有关时，需要安装该组件</p>
</li>
<li><p>npm install hexo-reading-time –save</p>
</li>
<li><p>安装后，才能使用搜索功能</p>
</li>
<li><p>npm install hexo-generator-searchdb –save</p>
</li>
<li><p>默认首页，分类，标签页显示文章数为10，想分页设置文章数操作如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在总的配置文件 _config.yml 中修改</span><br><span class="line">------------------------------————————————————</span><br><span class="line"># Algolia Search</span><br><span class="line"># For more information: https://www.algolia.com</span><br><span class="line">algolia_search:</span><br><span class="line">  enable: false</span><br><span class="line">  hits:</span><br><span class="line">    per_page: 15</span><br><span class="line"></span><br><span class="line">#主页每页显示文章数</span><br><span class="line">index_generator:</span><br><span class="line">    per_page: 15</span><br><span class="line">#archive分页每页显示文章数</span><br><span class="line">archive_generator:</span><br><span class="line">    per_page: 15</span><br><span class="line">#tag分页每页显示文章数</span><br><span class="line">tag_generator:</span><br><span class="line">    per_page: 15</span><br><span class="line">#category分页每页显示文章数</span><br><span class="line">category_generator: </span><br><span class="line">    per_page: 15</span><br><span class="line">————————————————————————————————————————————————</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">其他插件</span><br><span class="line">npm install hexo-server --save             	#本地服务器</span><br><span class="line">npm install hexo-deployer-git --save       	#git部署</span><br><span class="line">npm install hexo-generator-feed@1 --save   	#生成rss</span><br><span class="line">npm install hexo-generator-sitemap@1 --save	#生成站点地图</span><br></pre></td></tr></table></figure>


</li>
<li><p>自定义排序</p>
<p>在某一类别下，排序比较混乱，需要按照文章的date排序，或者按照中文的一、二、三等命名。</p>
<p>npm install hexo-generator-topindex –save</p>
</li>
<li><p>创建分类</p>
<p>hexo new page categories</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: categories</span><br><span class="line">date: 2020-04-03 16:19:59</span><br><span class="line">type: categories</span><br><span class="line">layout: &quot;categories&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>


</li>
<li><p>创建标签</p>
<p>hexo new page  tags</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date: 2020-04-03 16:19:59</span><br><span class="line">type: tags</span><br><span class="line">layout: &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>


</li>
<li><p>创建 about</p>
<p>hexo new page  about</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date: 2020-04-03 16:19:59</span><br><span class="line">type: about</span><br><span class="line">layout: &quot;about&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>


</li>
<li><p>创建搜索</p>
<p>hexo new page  search</p>
</li>
<li><p>创建新文章</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// [layout] 为布局，可选项为 `post`、`page`、`draft`，这将决定文章所在文件路径。</span><br><span class="line">// &lt;title&gt; 为文章标题</span><br><span class="line">hexo new [layout] &lt;title&gt;</span><br><span class="line"></span><br><span class="line">eg. hexo new post &quot;hello_word&quot;</span><br></pre></td></tr></table></figure>


</li>
<li><p>文章例子</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 每天一个linux命令</span><br><span class="line">date: 2017-01-23 11:41:48</span><br><span class="line">author: shaohua</span><br><span class="line">top: 1</span><br><span class="line">categories:</span><br><span class="line">- linux</span><br><span class="line">tags:</span><br><span class="line">- linux命令</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul>
<li>hexo init</li>
<li>hexo clean</li>
<li>hexo g (generate)</li>
<li>hexo s (start)</li>
<li>hexo d (deploy)</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm ls 与 npm fund 的区别，ls 只列出包名，而 fund 还列出了捐赠平台及其 url。</span><br><span class="line"></span><br><span class="line">node -v		// node版本</span><br><span class="line">npm -v		// npm版本</span><br><span class="line">cnpm -v		// cnpm是否正常</span><br></pre></td></tr></table></figure>





<h3 id="部署优化"><a href="#部署优化" class="headerlink" title="部署优化"></a>部署优化</h3><h3 id="一些问题解决"><a href="#一些问题解决" class="headerlink" title="一些问题解决"></a>一些问题解决</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. warning: LF will be replaced by CRLF in js/utils.js.</span><br><span class="line">解决方法:</span><br><span class="line">git config --global core.autocrlf false</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>template</title>
    <url>/2018/01/01/a.Template/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>doc</category>
      </categories>
      <tags>
        <tag>doc</tag>
      </tags>
  </entry>
  <entry>
    <title>毕业季刷题总结</title>
    <url>/2019/03/04/%E6%AF%95%E4%B8%9A%E5%AD%A3%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="1-字符串"><a href="#1-字符串" class="headerlink" title="1.字符串"></a>1.字符串</h1><h2 id="1-1-替换空格"><a href="#1-1-替换空格" class="headerlink" title="1.1 替换空格"></a>1.1 替换空格</h2><ol>
<li><p>题目表述</p>
<p>请实现一个函数，把字符串中的每个空格替换成”%20”。例如输入“We are happy.”，则输出“We%20are%20happy.”。</p>
</li>
<li><p>解题思路</p>
<p>先计算出来替换后的字符串长度，然后从尾至头逐个填写字符。这种方法的时间复杂度是O(N)。</p>
</li>
<li><p>代码</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class Solution &#123;</span><br><span class="line">    public String replaceSpace(StringBuffer str) &#123;</span><br><span class="line">        String str1 = str.toString();</span><br><span class="line">        if (str1.equals(&quot;&quot;)) </span><br><span class="line">            return str1;</span><br><span class="line">        int numSpace = 0;</span><br><span class="line">        char[] strArray = str1.toCharArray();</span><br><span class="line">        for (int i = 0; i &lt; strArray.length; i++) &#123;</span><br><span class="line">            if (strArray[i] == &#x27; &#x27;) numSpace++;</span><br><span class="line">        &#125;</span><br><span class="line">        int newlens = strArray.length + numSpace * 2;</span><br><span class="line">        char[] newStrArr = new char[newlens];</span><br><span class="line">        int i = strArray.length - 1, j = newStrArr.length - 1;</span><br><span class="line">        while (i &gt;= 0) &#123;</span><br><span class="line">            if (strArray[i] != &#x27; &#x27;) &#123;</span><br><span class="line">            	newStrArr[j--] = strArray[i--];</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                newStrArr[j--] = &#x27;0&#x27;;</span><br><span class="line">                newStrArr[j--] = &#x27;2&#x27;;</span><br><span class="line">                newStrArr[j--] = &#x27;%&#x27;;</span><br><span class="line">                i--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return new String(newStrArr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="1-2-字符串全排列"><a href="#1-2-字符串全排列" class="headerlink" title="1.2 字符串全排列"></a>1.2 字符串全排列</h2><ol>
<li><p>题目表述</p>
<p>输入一个字符串，打印出该字符串中字符的所有排列。例如输入字符串 abc，则打印出由字符 a、b、c 所能排列出来的所有字符串 abc、acb、bac、bca、cab 和 cba。</p>
</li>
<li><p>解题思路</p>
<ol>
<li>先字典序获取字符串的数组</li>
<li>然后递归实现逐个替换排列</li>
</ol>
</li>
<li><p>代码</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">public class Solution &#123;</span><br><span class="line">    ArrayList&lt;String&gt; ret = new ArrayList&lt;String&gt;();</span><br><span class="line">    public ArrayList&lt;String&gt; Permutation(String str) &#123;</span><br><span class="line">       if(str.length() == 0)</span><br><span class="line">           return ret;</span><br><span class="line">        char[] chars = str.toCharArray();</span><br><span class="line">        Arrays.sort(chars);</span><br><span class="line">        backtracking(chars,new boolean[chars.length],new StringBuilder());</span><br><span class="line">        return ret;</span><br><span class="line">    &#125;</span><br><span class="line">    private void backtracking(char[] chars, boolean[] hasUsed, StringBuilder s)&#123;</span><br><span class="line">        if(s.length()==chars.length)&#123;</span><br><span class="line">            ret.add(s.toString());</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        for(int i=0; i&lt;chars.length;i++)&#123;</span><br><span class="line">            if(hasUsed[i])</span><br><span class="line">                continue;</span><br><span class="line">            if(i!=0&amp;&amp;chars[i]==chars[i-1]&amp;&amp;!hasUsed[i-1])//保证不重复</span><br><span class="line">                continue;</span><br><span class="line">            hasUsed[i] = true;</span><br><span class="line">            s.append(chars[i]);</span><br><span class="line">            backtracking(chars,hasUsed,s);</span><br><span class="line">            s.deleteCharAt(s.length()-1);</span><br><span class="line">            hasUsed[i] = false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h2 id="1-3-反转单词顺序"><a href="#1-3-反转单词顺序" class="headerlink" title="1.3 反转单词顺序"></a>1.3 反转单词顺序</h2><h2 id="1-4-表示数值的字符串"><a href="#1-4-表示数值的字符串" class="headerlink" title="1.4 表示数值的字符串"></a>1.4 表示数值的字符串</h2><h1 id="2-查找"><a href="#2-查找" class="headerlink" title="2 查找"></a>2 查找</h1><h2 id="2-1-旋转数组最小的数字"><a href="#2-1-旋转数组最小的数字" class="headerlink" title="2.1 旋转数组最小的数字"></a>2.1 旋转数组最小的数字</h2><h2 id="2-2-数字在排序数组中出现的次数"><a href="#2-2-数字在排序数组中出现的次数" class="headerlink" title="2.2 数字在排序数组中出现的次数"></a>2.2 数字在排序数组中出现的次数</h2><h2 id="2-3-二分查找"><a href="#2-3-二分查找" class="headerlink" title="2.3 二分查找"></a>2.3 二分查找</h2><h1 id="3-链表"><a href="#3-链表" class="headerlink" title="3. 链表"></a>3. 链表</h1>]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法与数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop之MapReduce</title>
    <url>/2019/04/12/Hadoop/Hadoop%E4%B9%8BMapReduce/</url>
    <content><![CDATA[<h1 id="MapReduce概述"><a href="#MapReduce概述" class="headerlink" title="MapReduce概述"></a>MapReduce概述</h1><h2 id="1-MapReduce分布式方案考虑的问题"><a href="#1-MapReduce分布式方案考虑的问题" class="headerlink" title="1. MapReduce分布式方案考虑的问题"></a>1. MapReduce分布式方案考虑的问题</h2><p> （1）运算逻辑要不要先分后合？</p>
<p> （2）程序如何分配运算任务（切片）？</p>
<p> （3）两阶段的程序如何启动？如何协调？</p>
<p> （4）整个程序运行过程中的监控？容错？重试？</p>
<p> 分布式方案需要考虑很多问题，但是我们可以将分布式程序中的公共功能封装成框 架，让开发人员将精力集中于业务逻辑上。而mapreduce就是这样一个分布式程序的通用框架。</p>
<h2 id="2-MapReduce核心思想"><a href="#2-MapReduce核心思想" class="headerlink" title="2. MapReduce核心思想"></a>2. MapReduce核心思想</h2><p>以wordcount为例：</p>
<p>需求：统计文件中每一个单词出现的总次数（查询结果a-p一个文件, q-z一个文件）</p>
<p><a href="20220710-1.jpg"><img src="/../../../../images/20220710-1.jpg" alt="mapreduce流程.jpg"></a></p>
<ul>
<li><p>总述：</p>
<p>1）分布式的运算程序往往需要分成至少2个阶段</p>
<p>2）第一个阶段的maptask并发实例，完全并行运行，互不相干</p>
<p>3）第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出</p>
<p>4）MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行</p>
</li>
<li><p>若干细节问题：</p>
<ol>
<li>Map task 如何进行任务分配</li>
<li>Reduce task 如何进行任务分配</li>
<li>Map task 和 Reduce task 如何衔接</li>
<li>Map task 如何都要自己负责数据的分区，很麻烦</li>
</ol>
</li>
</ul>
<h2 id="3-MapReduce-进程"><a href="#3-MapReduce-进程" class="headerlink" title="3. MapReduce 进程"></a>3. MapReduce 进程</h2><p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
<ol>
<li>MrAppMaster: 负责整个程序的过程调度以及状态协调。</li>
<li>MapTask: 负责map阶段的整个数据处理流程。</li>
<li>ReduceTask：负责Reduce阶段的整个数据处理流程。</li>
</ol>
<h2 id="4-MapReduce-编程规范"><a href="#4-MapReduce-编程规范" class="headerlink" title="4. MapReduce 编程规范"></a>4. MapReduce 编程规范</h2><p>户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)</p>
<p>1）Mapper阶段</p>
<p> （1）用户自定义的Mapper要继承自己的父类</p>
<p> （2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p>
<p> （3）Mapper中的业务逻辑写在map()方法中</p>
<p> （4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p>
<p> （5）<strong>map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次</strong></p>
<p>2）Reducer阶段</p>
<p> （1）用户自定义的Reducer要继承自己的父类</p>
<p> （2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</p>
<p> （3）Reducer的业务逻辑写在reduce()方法中</p>
<p> （4）<strong>Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</strong></p>
<p>3）Driver阶段</p>
<p> 整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p>
<h2 id="5-MapReduce程序运行流程分析"><a href="#5-MapReduce程序运行流程分析" class="headerlink" title="5. MapReduce程序运行流程分析"></a>5. MapReduce程序运行流程分析</h2><p> 1）在MapReduce程序读取文件的输入目录上存放相应的文件。</p>
<p> 2）客户端程序在submit()方法执行前，获取待处理的数据信息，然后根据集群中参数的配置形成一个任务分配规划。</p>
<p> 3）客户端提交job.split、jar包、job.xml等文件给yarn，yarn中resourcemanager启动MRAppMaster。</p>
<p> 4）MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程。</p>
<p> 5）maptask利用客户指定的inputformat来读取数据，形成输入KV对。</p>
<p> 6）maptask将输入KV对传递给客户定义的map()方法，做逻辑运算</p>
<p> 7）<strong>map()运算完毕后将KV对收集到maptask缓存</strong>。</p>
<p> 8）<strong>maptask缓存中的KV对 按照K分区排序 后不断写到磁盘文件</strong></p>
<p> 9）MRAppMaster监控到所有maptask进程任务完成之后，<strong>会根据客户指定的参数启动相应数量的reducetask进程</strong>，并告知reducetask进程要处理的数据分区。</p>
<p> 10）Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，<strong>从若干台maptask运行所在机器上获取到若干个maptask输出结果文件</strong>，并在本地进行<strong>重新归并排序</strong>，然后按照<strong>相同key的KV为一个组</strong>，<strong>调用客户定义的reduce()方法</strong>进行逻辑运算。</p>
<p> 11）Reducetask运算完毕后，调用客户指定的outputformat将结果数据输出到外部存储。</p>
<h1 id="框架原理"><a href="#框架原理" class="headerlink" title="框架原理"></a>框架原理</h1><h2 id="1-MapReduce工作流程"><a href="#1-MapReduce工作流程" class="headerlink" title="1. MapReduce工作流程"></a>1. MapReduce工作流程</h2><ul>
<li><p><strong>流程步骤</strong></p>
<ol>
<li><p>待处理文本</p>
</li>
<li><p>客户端程序在submit()方法执行前，获取待处理的数据信息，然后根据集群中参数的配置形成一个任务分配规划。</p>
<p>如： test1.txt 0-128</p>
<p> test1.txt 128-240</p>
<p> test2.txt</p>
</li>
<li><p>提交切片信息（客户端提交job.split、jar包、job.xml等文件给yarn）</p>
</li>
<li><p>计算出maptask的数量</p>
</li>
<li><p>根据inputformat来读取数据</p>
</li>
<li><p>map(),进行逻辑运算</p>
</li>
<li><p>运算完毕后将KV对收集到maptask缓存（默认100M）</p>
</li>
<li><p>根据key分区，排序</p>
</li>
<li><p>缓冲区溢出，写入文件（分区且区内有序）</p>
</li>
<li><p>归并排序，将溢出的文件合并成大文件</p>
</li>
<li><p>所有map任务完成后，启动相应数量的reducetask, 并告知reducetask处理数据的范围（数据分区）</p>
</li>
<li><p>reducetask下载待处理数据到本地磁盘</p>
</li>
<li><p>归并排序，合并文件</p>
</li>
<li><p>一次读取一组</p>
</li>
<li><p>分组（groupingComparator）</p>
</li>
<li><p>outputformat将结果数据输出到外部存储。</p>
</li>
</ol>
</li>
<li><p><strong>shuffle流程详解 (7-16步)</strong></p>
<p>1）maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p>2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p>3）多个溢出文件会被合并成大的溢出文件</p>
<p><strong>4）在溢出过程中，及合并的过程中，都要调用partitioner进行分区和针对key进行排序</strong></p>
<p><strong>5）reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</strong></p>
<p><strong>6）reducetask会取到同一个分区的来自不同maptask的结果文件， reducetask会将这些文件再进行合并（归并排序）</strong></p>
<p><strong>7）合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</strong></p>
</li>
<li><p><strong>注意</strong></p>
<p>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，<strong>缓冲区越大，磁盘io的次数越少，执行速度就越快。</strong></p>
<p><strong>缓冲区的大小可以通过参数调整，参数：io.sort.mb 默认100M</strong></p>
</li>
</ul>
<h2 id="2-Writable序列化"><a href="#2-Writable序列化" class="headerlink" title="2. Writable序列化"></a>2. Writable序列化</h2><p> 序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。</p>
<p> 反序列化就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。</p>
<p> <strong>Java的序列化是一个重量级序列化框架（Serializable）</strong>，一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），<strong>不便于在网络中高效传输</strong>。所以，<strong>hadoop自己开发了一套序列化机制（Writable），精简、高效。</strong></p>
<h3 id="2-1-常用数据序列化类型"><a href="#2-1-常用数据序列化类型" class="headerlink" title="2.1 常用数据序列化类型"></a>2.1 常用数据序列化类型</h3><p>常用的数据类型对应的hadoop数据序列化类型</p>
<p><a href="20220710-2.jpg"><img src="/../../../../images/20220710-2.jpg" alt="writable.jpg"></a></p>
<p>###　2.2 自定义bean对象实现序列化接口</p>
<ul>
<li><p>自定义bean对象要想序列化传输，必须实现序列化接口，需要注意以下7项。</p>
<p><strong>（1）必须实现Writable接口</strong></p>
<p><strong>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</strong></p>
<p><strong>（3）重写序列化方法</strong></p>
<p><strong>（4）重写反序列化方法</strong></p>
<p><strong>（5）注意反序列化的顺序和序列化的顺序完全一致</strong></p>
<p><strong>（6）要想把结果显示在文件中，需要重写toString()，且用”\t”分开，方便后续用</strong></p>
<p><strong>（7）如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序</strong></p>
</li>
</ul>
<p>以统计每一个手机号耗费的总上行流量、下行流量、总流量（序列化），为例**</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 1 必须实现Writable接口</span><br><span class="line">public class FlowBean implements Writable &#123;	</span><br><span class="line">	private long upFlow;	</span><br><span class="line">	private long downFlow;	</span><br><span class="line">	private long sumFlow;	</span><br><span class="line">	</span><br><span class="line">	//2 反序列化时，需要反射调用空参构造函数，所以必须有	</span><br><span class="line">	public FlowBean() &#123;		</span><br><span class="line">		super();	</span><br><span class="line">	&#125;	</span><br><span class="line">	</span><br><span class="line">	/**	 </span><br><span class="line">	* 3重写序列化方法	 </span><br><span class="line">	* 	 </span><br><span class="line">	* @param out	 </span><br><span class="line">	* @throws IOException	 </span><br><span class="line">	*/	</span><br><span class="line">	@Override	</span><br><span class="line">	public void write(DataOutput out) throws IOException &#123;		</span><br><span class="line">		out.writeLong(upFlow);		</span><br><span class="line">		out.writeLong(downFlow);		</span><br><span class="line">		out.writeLong(sumFlow);	</span><br><span class="line">	&#125;	</span><br><span class="line">	</span><br><span class="line">	/**	 </span><br><span class="line">	* 4 重写反序列化方法 </span><br><span class="line">	* 5 注意反序列化的顺序和序列化的顺序完全一致	 </span><br><span class="line">	* 	 </span><br><span class="line">	* @param in	 </span><br><span class="line">	* @throws IOException	 </span><br><span class="line">	*/	</span><br><span class="line">	@Override	</span><br><span class="line">	public void readFields(DataInput in) throws IOException &#123;		</span><br><span class="line">		upFlow = in.readLong();		</span><br><span class="line">		downFlow = in.readLong();		</span><br><span class="line">		sumFlow = in.readLong();	</span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	// 6要想把结果显示在文件中，需要重写toString()，且用”\t”分开，方便后续用	</span><br><span class="line">	@Override	</span><br><span class="line">	public String toString() &#123;		</span><br><span class="line">		return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;	</span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	//7 如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，</span><br><span class="line">	//因为mapreduce框中的shuffle过程一定会对key进行排序	</span><br><span class="line">	@Override	</span><br><span class="line">	public int compareTo(FlowBean o) &#123;		</span><br><span class="line">		// 倒序排列，从大到小		</span><br><span class="line">		return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-InputFormat数据切片机制"><a href="#3-InputFormat数据切片机制" class="headerlink" title="3. InputFormat数据切片机制"></a>3. InputFormat数据切片机制</h2><h3 id="3-1-job提交流程源码详解"><a href="#3-1-job提交流程源码详解" class="headerlink" title="3.1 job提交流程源码详解"></a>3.1 job提交流程源码详解</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）job提交流程源码详解</span><br><span class="line"></span><br><span class="line">waitForCompletion()</span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line">// 1建立连接	</span><br><span class="line">	connect();			</span><br><span class="line">		// 1）创建提交job的代理		</span><br><span class="line">		new Cluster(getConfiguration());	</span><br><span class="line">        </span><br><span class="line">		// 2）判断是本地yarn还是远程		</span><br><span class="line">		initialize(jobTrackAddr, conf); </span><br><span class="line">		</span><br><span class="line">// 2 提交jobsubmitter.submitJobInternal(Job.this, cluster)	</span><br><span class="line">	// 1）创建给集群提交数据的Stag路径	</span><br><span class="line">	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);	</span><br><span class="line">	</span><br><span class="line">	// 2）获取jobid ，并创建job路径	</span><br><span class="line">	JobID jobId = submitClient.getNewJobID();	</span><br><span class="line">	</span><br><span class="line">	// 3）拷贝jar包到集群</span><br><span class="line">	copyAndConfigureFiles(job, submitJobDir);		</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line">	</span><br><span class="line">	// 4）计算切片，生成切片规划文件</span><br><span class="line">	writeSplits(job, submitJobDir);	</span><br><span class="line">	maps = writeNewSplits(job, jobSubmitDir);		</span><br><span class="line">	input.getSplits(job);</span><br><span class="line">	</span><br><span class="line">	// 5）向Stag路径写xml配置文件</span><br><span class="line">	writeConf(conf, submitJobFile);	</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line">	</span><br><span class="line">	// 6）提交job,返回提交状态</span><br><span class="line">	status = submitClient.submitJob(jobId, submitJobDir.toString(),job.getCredentials());</span><br></pre></td></tr></table></figure>

<h3 id="3-2-FileInputFormat源码解析-input-getSplits-job"><a href="#3-2-FileInputFormat源码解析-input-getSplits-job" class="headerlink" title="3.2 FileInputFormat源码解析(input.getSplits(job))"></a>3.2 FileInputFormat源码解析(input.getSplits(job))</h3><p><a href="20220710-3.jpg"><img src="/../../../../images/20220710-3.jpg" alt="FileInputFormat.jpg"></a></p>
<p>（1）找到你数据存储的目录。</p>
<p>（2）开始遍历处理（规划切片）目录下的每一个文件</p>
<p>（3）遍历第一个文件ss.txt</p>
<p> a）获取文件大小fs.sizeOf(ss.txt);</p>
<p> b）计算切片大小 computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M</p>
<p> c）默认情况下，切片大小&#x3D;blocksize</p>
<p> d）开始切，形成第1个切片：ss.txt—0:128M第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片）</p>
<p> e）将切片信息写到一个切片规划文件中</p>
<p> f）整个切片的核心过程在getSplit()方法中完成。</p>
<p> g）数据切片只是在逻辑上对输入数据进行分片，并不会再磁盘上将其切分成分片进行存储。InputSplit只记录了分片的元数据信息，比如起始位置、长度以及所在的节点列表等。</p>
<p>h）注意：block是HDFS上物理上存储的存储的数据，切片是对数据逻辑上的划分。</p>
<p>（4）提交切片规划文件到yarn上，yarn上的MrAppMaster就可以根据切片规划文件计算开启maptask个数。</p>
<h3 id="3-3-FileInputFormat中默认的切片机制："><a href="#3-3-FileInputFormat中默认的切片机制：" class="headerlink" title="3.3 FileInputFormat中默认的切片机制："></a>3.3 FileInputFormat中默认的切片机制：</h3><p>（1）简单地按照文件的内容长度进行切片</p>
<p>（2）切片大小，默认等于block大小</p>
<p>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p>
<p>比如待处理数据有两个文件：</p>
<p> file1.txt 320M</p>
<p> file2.txt 10M</p>
<p>经过FileInputFormat的切片机制运算后，形成的切片信息如下：</p>
<p> file1.txt.split1– 0~128</p>
<p> file1.txt.split2– 128~256</p>
<p> file1.txt.split3– 256~320</p>
<p> file2.txt.split1– 0~10M</p>
<h3 id="3-4-FileInputFormat切片大小的参数配置"><a href="#3-4-FileInputFormat切片大小的参数配置" class="headerlink" title="3.4 FileInputFormat切片大小的参数配置"></a>3.4 FileInputFormat切片大小的参数配置</h3><p>（1）通过分析源码，在FileInputFormat中，计算切片大小的逻辑：Math.max(minSize,Math.min(maxSize, blockSize));</p>
<p>切片主要由这几个值来运算决定:</p>
<p>mapreduce.input.fileinputformat.split.minsize&#x3D;1默认值为1</p>
<p>mapreduce.input.fileinputformat.split.maxsize&#x3D;Long.MAXValue 默认值Long.MAXValue</p>
<p>因此，默认情况下，切片大小&#x3D;blocksize。</p>
<p> maxsize（切片最大值）：参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值。</p>
<p> minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blocksize还大。</p>
<p>（2）获取切片信息API</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 根据文件类型获取切片信息</span><br><span class="line">FileSplit inputSplit = (FileSplit) context.getInputSplit();</span><br><span class="line">// 获取切片的文件名称</span><br><span class="line">String name = inputSplit.getPath().getName();</span><br></pre></td></tr></table></figure>

<h3 id="3-5-CombineTextInputFormat切片机制"><a href="#3-5-CombineTextInputFormat切片机制" class="headerlink" title="3.5 CombineTextInputFormat切片机制"></a>3.5 CombineTextInputFormat切片机制</h3><p>关于大量小文件的优化策略</p>
<p>1）默认情况下TextInputformat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样如果有大量小文件，就会产生大量的maptask，处理效率极其低下。</p>
<p>2）优化策略</p>
<p> （1）最好的办法，在数据处理系统的最前端（预处理&#x2F;采集），将小文件先合并成大文件，再上传到HDFS做后续分析。</p>
<p> （2）补救措施：如果已经是大量小文件在HDFS中了，可以使用另一种InputFormat来做切片（CombineTextInputFormat），它的切片逻辑跟TextFileInputFormat不同：它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个maptask。</p>
<p> （3）优先满足最小切片大小，不超过最大切片大小</p>
<p> CombineTextInputFormat.<em>setMaxInputSplitSize</em>(job,4194304);&#x2F;&#x2F; 128m</p>
<p> CombineTextInputFormat.<em>setMinInputSplitSize</em>(job,2097152);&#x2F;&#x2F; 2m</p>
<p> 举例：0.5m+1m+0.3m+5m&#x3D;2m + 4.8m&#x3D;2m + 4m + 0.8m</p>
<p>3）具体实现步骤</p>
<p> &#x2F;&#x2F;如果不设置InputFormat,它默认用的是TextInputFormat.class</p>
<p> job.setInputFormatClass(CombineTextInputFormat.<strong>class</strong>)</p>
<p> CombineTextInputFormat.<em>setMaxInputSplitSize</em>(job,4194304);&#x2F;&#x2F; 4m</p>
<p> CombineTextInputFormat.<em>setMinInputSplitSize</em>(job,2097152);&#x2F;&#x2F; 2m</p>
<h3 id="3-6-自定义InputFormat"><a href="#3-6-自定义InputFormat" class="headerlink" title="3.6 自定义InputFormat"></a>3.6 自定义InputFormat</h3><p><strong>概述</strong></p>
<p>（1）自定义一个类继承FileInputFormat</p>
<p>（2）改写RecordReader，实现一次读取一个完整文件封装为KV</p>
<p>（3）在输出时使用SequenceFileOutPutFormat输出合并文件</p>
<h2 id="4-MapTask工作机制"><a href="#4-MapTask工作机制" class="headerlink" title="4. MapTask工作机制"></a>4. MapTask工作机制</h2><h2 id="5-Shuffle机制"><a href="#5-Shuffle机制" class="headerlink" title="5. Shuffle机制"></a>5. Shuffle机制</h2><h2 id="6-ReduceTask工作机制"><a href="#6-ReduceTask工作机制" class="headerlink" title="6. ReduceTask工作机制"></a>6. ReduceTask工作机制</h2><h2 id="7-自定义OutputFormat"><a href="#7-自定义OutputFormat" class="headerlink" title="7. 自定义OutputFormat"></a>7. 自定义OutputFormat</h2><h2 id="8-计数器应用"><a href="#8-计数器应用" class="headerlink" title="8. 计数器应用"></a>8. 计数器应用</h2><h2 id="9-数据清洗"><a href="#9-数据清洗" class="headerlink" title="9. 数据清洗"></a>9. 数据清洗</h2><h1 id="MapReduce与Yarn"><a href="#MapReduce与Yarn" class="headerlink" title="MapReduce与Yarn"></a>MapReduce与Yarn</h1>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop入门</title>
    <url>/2018/12/28/Hadoop/Hadoop%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="Hadoop框架"><a href="#Hadoop框架" class="headerlink" title="Hadoop框架"></a>Hadoop框架</h2><h3 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h3><ul>
<li>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。</li>
<li>主要解决，<strong>海量数据的存储</strong>和<strong>海量数据的分析计算</strong>问题。</li>
<li>HADOOP通常是指一个更广泛的概念——HADOOP生态圈。</li>
</ul>
<h3 id="Hadoop三大发行版本"><a href="#Hadoop三大发行版本" class="headerlink" title="Hadoop三大发行版本"></a>Hadoop三大发行版本</h3><p>Hadoop 三大发行版本: Apache、Cloudera、Hortonworks。</p>
<ul>
<li>Apache版本最原始（最基础）的版本，对于入门学习最好。</li>
<li>Cloudera在大型互联网企业中用的较多。</li>
<li>Hortonworks文档较好。</li>
</ul>
<h3 id="Hadoop的优势"><a href="#Hadoop的优势" class="headerlink" title="Hadoop的优势"></a>Hadoop的优势</h3><p>1）<strong>高可靠性</strong>：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。</p>
<p>2）<strong>高扩展性</strong>：在集群间分配任务数据，可方便的扩展数以千计的节点。</p>
<p>3） <strong>高效性</strong>：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p>
<p>4）<strong>高容错性</strong>：自动保存多份副本数据，并且能够自动将失败的任务重新分配。</p>
<h3 id="Hadoop组成"><a href="#Hadoop组成" class="headerlink" title="Hadoop组成"></a>Hadoop组成</h3><p>1）Hadoop HDFS：一个高可靠、高吞吐量的<strong>分布式文件系统</strong>。</p>
<p>2）Hadoop MapReduce：一个<strong>分布式的离线并行计算框架</strong>。</p>
<p>3）Hadoop YARN：<strong>作业调度与集群资源管理的框架</strong>。</p>
<p>4）Hadoop Common：<strong>支持其他模块的工具模块</strong>。</p>
<h4 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h4><p>1）NameNode（nn）：<strong>存储文件的元数据，如文件名，文件目录结构，文件属性</strong>（生成时间、副本数、文件权限），<strong>以及每个文件的块列表和块所在的DataNode等</strong>。</p>
<p>2）DataNode(dn)：在本地文件系统<strong>存储文件块数据</strong>，以及块数据的校验和。</p>
<p>3）Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，<strong>每隔一段时间获取HDFS元数据的快照</strong>。</p>
<h4 id="YARN架构概述"><a href="#YARN架构概述" class="headerlink" title="YARN架构概述"></a>YARN架构概述</h4><p>1）ResourceManager(rm)：处理客户端请求、启动&#x2F;监控ApplicationMaster、<strong>监控NodeManager</strong>、<strong>资源分配与调度</strong>；</p>
<p>2）NodeManager(nm)：单个节点上的资源管理、<strong>处理来自ResourceManager的命令</strong>、处理来自ApplicationMaster的命令；</p>
<p>3）ApplicationMaster：<strong>数据切分、为应用程序申请资源</strong>，并分配给内部任务、任务监控与容错。</p>
<p>4）Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。</p>
<h4 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h4><p>MapReduce将计算过程分为两个阶段：Map和Reduce。</p>
<p>1）Map阶段并行处理输入数据。</p>
<p>2）Reduce阶段对Map结果进行汇总。</p>
<h3 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h3><p><a href="20220707-3"><img src="/../../../../images/20220707-3.jpg" alt="img"></a></p>
<p>名词解释如下：</p>
<p>1）**Sqoop(数据传递)**：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p>
<p>2）<strong>Flume(日志收集)<strong>：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量</strong>日志采集、聚合和传输的系统</strong>，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>
<p>3）Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，如下特性：</p>
<p>4）**Storm(实时计算)**：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。</p>
<p>5）Spark：Spark是当前最流行的开源大数据内存计算框架。</p>
<p> 可以基于Hadoop上存储的大数据进行计算。</p>
<p>6）Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。</p>
<p>7）Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p>
<p>8）Hive：hive是基于Hadoop的一个数据仓库工具</p>
<ul>
<li>可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能</li>
<li>可以将sql语句转换为MapReduce任务进行运行。</li>
</ul>
<p>其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>
<p>9）R语言：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。</p>
<p>10）Mahout: Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例：</p>
<ul>
<li>推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。</li>
<li>聚集：收集文件并进行相关文件分组。<br>分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标 签的文档进行正确的归类。</li>
<li>频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。</li>
</ul>
<p>11）ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。</p>
<ul>
<li>它是一个针对大型<strong>分布式系统的可靠协调系统</strong>，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。</li>
<li>ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</li>
</ul>
<h2 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h2><ul>
<li><p>官方网址：<a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
</li>
<li><p>各个版本归档库地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a></p>
</li>
<li><p>hadoop2.7.2版本详情介绍：<a href="http://hadoop.apache.org/docs/r2.7.2/">http://hadoop.apache.org/docs/r2.7.2/</a></p>
<p>Hadoop运行模式：</p>
<p>（1）本地模式（默认模式）：不需要启用单独进程，直接可以运行，测试和开发时使用。</p>
<p>（2）伪分布式模式：等同于完全分布式，只有一个节点。</p>
<p>（3）完全分布式模式：多个节点一起运行。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce笔记</title>
    <url>/2019/10/01/Hadoop/MapReduce%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="1-MapReduce二次排序过程"><a href="#1-MapReduce二次排序过程" class="headerlink" title="1. MapReduce二次排序过程"></a>1. MapReduce二次排序过程</h1><p>二次排序(<code>secondary sort</code>)问题是指在<code>Reduce</code>阶段对某个键关联的值排序。<strong>利用二次排序技术,可以对传入Reduce的 值 完成 升序&#x2F;降序 排序</strong>。</p>
<p><code>MapReduce</code>框架会自动<strong>对Map生成的键完成排序</strong>. 所以, 在启动Reduce之前,中间文件 <code>key-value</code> 是按照<strong>key有序的(而不是按照值有序)</strong>.它们的值的顺序有可能是任意的.</p>
<h2 id="二次排序问题引入"><a href="#二次排序问题引入" class="headerlink" title="二次排序问题引入"></a>二次排序问题引入</h2><p>对于Reduce的值进行排序至少有两种方案，这两种方案在<code>MapReduce/Hadoop</code> 和 <code>Spark</code>框架中都可以使用。</p>
<ul>
<li><p>第一种方案是让<code>Reduce</code>读取和缓存给定<code>key</code>的所有的<code>value</code>, 然后在<code>Reduce</code>中对这些值完成排序.</p>
<p>(例如: 把一个<code>key</code>对应的所有<code>value</code>放到一个<code>Array</code>或<code>List</code>中,再排序). 但是这种方式有局限性, 如果数据量较少还可以使用,如果数据量太大,一个<code>Reduce</code>中放不下所有的值,就会导致内存溢出(<code>OutOfMemory</code>).</p>
</li>
<li><p>第二种方式是使用<code>MapReduce</code>框架来对值进行排序。因为<code>MapReduce</code>框架会自动对<code>Map</code>生成的文件的<code>key</code>进行排序, 所以我们把需要排序的<code>value</code>增加到这个<code>key</code>上,这样让框架对这个<code>new_key</code>进行排序,来实现我们的目标.</p>
</li>
</ul>
<h2 id="二次排序方法小结"><a href="#二次排序方法小结" class="headerlink" title="二次排序方法小结"></a>二次排序方法小结</h2><ol>
<li>使用键值转换的设计模式，来构造一个组合key（key, v1）。其中<code>v1</code>是次键(<code>secondary key</code>)。</li>
<li>让<code>MapReduce</code>执行框架完成排序.</li>
<li>重写分区器（GroupComparator）,根据组合key<code>(k, v1)</code> 中的 <code>k</code> 进行分区.（这样才能实现既能以key为一个组分配同一个reduce，同时还实现了对v1的排序）</li>
</ol>
<h1 id="2-hashcode方法重写"><a href="#2-hashcode方法重写" class="headerlink" title="2. hashcode方法重写"></a>2. hashcode方法重写</h1><p>在MapReduce中如果需要用到javabean作为key来接收和传递数据，最好对javabean重写hashcode方法，目的是shuffle阶段在进行分区时会根据key进行hash, 重写hash可以尽量避免同一个key的数据分区错误。</p>
<h1 id="3-关于迭代器的理解"><a href="#3-关于迭代器的理解" class="headerlink" title="3. 关于迭代器的理解"></a>3. 关于迭代器的理解</h1><ol>
<li>迭代器只能迭代一次，然后再调用就没有数据了。</li>
<li>Reduce中的迭代器迭代过程可以理解为不走内存，所以使用迭代器不用考虑数据的大小，不会导致内存溢出。</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Java IO</title>
    <url>/2019/02/12/Java/Java%20IO/</url>
    <content><![CDATA[<h1 id="1-IO-基础"><a href="#1-IO-基础" class="headerlink" title="1. IO 基础"></a>1. IO 基础</h1><p><a href="20220708-3.jpg"><img src="/../../../../images/20220708-3.jpg" alt="Java SE框架.jpg"></a></p>
<h2 id="1-1-java-io-file的使用"><a href="#1-1-java-io-file的使用" class="headerlink" title="1.1 java.io.file的使用"></a>1.1 java.io.file的使用</h2><p>java.io.File类：文件和目录路径名的抽象表示形式。</p>
<ul>
<li>File 能<strong>新建、删除、重命名文件和目录</strong>，但File 不能访问文件内容本身。如果需要访问文件内容本身，则需要使用输入&#x2F;输出流。</li>
<li>File对象可以作为参数传递给流的构造函数</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">File win = new File(&quot;C:\\Windows&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(win.isDirectory()); // true</span><br><span class="line"></span><br><span class="line">File notepad = new File(&quot;C:\\Windows\\notepad.exe&quot;);</span><br><span class="line">System.out.println(notepad.isFile()); // true</span><br><span class="line"></span><br><span class="line">File dir = new File(&quot;C:\\abc\\xyz&quot;);</span><br><span class="line">System.out.println(dir.mkdir()); // -&gt; mkdirs</span><br><span class="line"></span><br><span class="line">File readme = new File(&quot;./src/readme.txt&quot;);</span><br><span class="line">System.out.println(readme.isFile()); //true</span><br><span class="line"></span><br><span class="line">System.out.println(readme.getAbsolutePath());</span><br><span class="line">System.out.println(readme.getCanonicalPath());</span><br></pre></td></tr></table></figure>

<p><a href="20220708-4.jpg"><img src="/../../../../images/20220708-4.jpg" alt="20220708-4.jpg"></a></p>
<h2 id="1-2-IO原理以及流的分类"><a href="#1-2-IO原理以及流的分类" class="headerlink" title="1.2 IO原理以及流的分类"></a>1.2 IO原理以及流的分类</h2><ul>
<li>IO流用来处理设备之间的数据传输。</li>
<li>Java对于数据的输入&#x2F;输出操作以”流(stream)”的方式进行。</li>
<li>java.io包下提供了各种“流”类和接口, 通过标准的方法输入或输出数据。<ul>
<li>输入input：读取外部数据（磁盘、光盘等存储设备的数据）到程序（内存）中。</li>
<li>输出output：将程序（内存）数据输出到磁盘、光盘等存储设备中。</li>
</ul>
</li>
</ul>
<h3 id="1-2-1-流的分类"><a href="#1-2-1-流的分类" class="headerlink" title="1.2.1 流的分类"></a>1.2.1 流的分类</h3><ul>
<li>按操作数据单位不同分为：字节流(8bit)，字符流(16bit)</li>
<li>按数据流的流向不同分为：输入流，输出流</li>
<li>按流的角色的不同分为：节点流，处理流</li>
</ul>
<table>
<thead>
<tr>
<th align="center">抽象基类</th>
<th align="center">字节流</th>
<th>字符流</th>
</tr>
</thead>
<tbody><tr>
<td align="center">输入流</td>
<td align="center">InputStream</td>
<td>Reader</td>
</tr>
<tr>
<td align="center">输出流</td>
<td align="center">OutputStream</td>
<td>Writer</td>
</tr>
</tbody></table>
<p>字节流：以byte为单位传输</p>
<p>字符流：以char为单位传输</p>
<ul>
<li>节点流可以从一个特定的数据源读写数据。</li>
<li>处理流是“连接”在已存在的流（节点流或处理流）之上，通过对数据的处理为程序提供更为强大的读写功能。</li>
</ul>
<p>Java的IO流共涉及40多个类，实际上非常规则，都是从如下4个抽象基类派生的。</p>
<ul>
<li><p>IO流体系</p>
<p><a href="20220708-5.jpg"><img src="/../../../../images/20220708-5.jpg" alt="20220708-5.jpg"></a></p>
</li>
</ul>
<h3 id="1-2-2-InputStream-amp-Reader"><a href="#1-2-2-InputStream-amp-Reader" class="headerlink" title="1.2.2 InputStream&amp; Reader"></a>1.2.2 InputStream&amp; Reader</h3><p>InputStream 和 Reader是所有输入流的基类。</p>
<p>InputStream（典型实现：FileInputStream）</p>
<ul>
<li>intread()</li>
<li>int read(byte[] b)</li>
<li>intread(byte[] b, int off,int len)</li>
</ul>
<p>Reader（典型实现：FileReader）</p>
<ul>
<li>intread()</li>
<li>int read(char [] c)</li>
<li>intread(char [] c, int off,int len)</li>
</ul>
<p>注意：程序中打开的文件 IO 资源不属于内存里的资源，垃圾回收机制无法回收该资源，所以应该显式关闭文件IO 资源。</p>
<h3 id="1-2-3-OutputStream-amp-Writer"><a href="#1-2-3-OutputStream-amp-Writer" class="headerlink" title="1.2.3 OutputStream&amp; Writer"></a>1.2.3 OutputStream&amp; Writer</h3><p>OutputStream 和 Writer也非常相似：</p>
<ul>
<li>void write(int b&#x2F;int c);</li>
<li>void write(byte[] b&#x2F;char[]cbuf);</li>
<li>void write(byte[] b&#x2F;char[]buff, int off, int len);</li>
<li>void flush();</li>
<li>void close(); 需要先刷新，再关闭此流</li>
</ul>
<p>因为字符流直接以字符作为操作单位，所以 Writer可以用字符串来替换字符数组，即以String对象作为参数</p>
<p>void write(String str);</p>
<p>void write(String str, intoff, intlen);</p>
<h1 id="2-文件流"><a href="#2-文件流" class="headerlink" title="2. 文件流"></a>2. 文件流</h1><ol>
<li><p>读取文件</p>
<p>1.建立一个流对象，将已存在的一个文件加载进流。</p>
<p>FileReader fr &#x3D; new FileReader(“Test.txt”);</p>
<p>2.创建一个临时存放数据的数组。</p>
<p>char[] ch &#x3D; new char[1024];</p>
<p>3.调用流对象的读取方法将流中的数据读入到数组中。</p>
<p>fr.read(ch);</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FileReader fr = null;	</span><br><span class="line"></span><br><span class="line">try&#123;		</span><br><span class="line">	fr = new FileReader(&quot;c:\\test.txt&quot;);		</span><br><span class="line">	char[] buf = new char[1024];		</span><br><span class="line">	int len= 0;		</span><br><span class="line">	while((len=fr.read(buf))!=-1)&#123;			</span><br><span class="line">		System.out.println(new String(buf ,0,len));			</span><br><span class="line">	&#125;	</span><br><span class="line">&#125;catch (IOException e)&#123;		</span><br><span class="line">	System.out.println(&quot;read-Exception :&quot;+e.toString());		</span><br><span class="line">&#125;finally&#123;		</span><br><span class="line">	if(fr!=null)&#123;			</span><br><span class="line">		try&#123;				</span><br><span class="line">			fr.close();			</span><br><span class="line">		&#125;catch (IOException e)&#123;				</span><br><span class="line">			System.out.println(&quot;close-Exception :&quot;+e.toString());			</span><br><span class="line">		&#125; 		</span><br><span class="line">	&#125; 	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>写入文件</p>
<p>1.创建流对象，建立数据存放文件</p>
<p>FileWriter fw &#x3D; new FileWriter(“Test.txt”);</p>
<p>2.调用流对象的写入方法，将数据写入流</p>
<p>fw.write(“text”);</p>
<p>3.关闭流资源，并将流中的数据清空到文件中。</p>
<p>fw.close();</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FileWriter fw = null;	</span><br><span class="line"></span><br><span class="line">try&#123;		</span><br><span class="line">	fw = new FileWriter(&quot;Test.txt&quot;);		</span><br><span class="line">	fw.write(&quot;text&quot;);	</span><br><span class="line">&#125;catch (IOException e)&#123;		</span><br><span class="line">	System.out.println(e.toString());	</span><br><span class="line">&#125;finally&#123;		</span><br><span class="line">	if(fw!=null)&#123;		</span><br><span class="line">		try&#123;		 </span><br><span class="line">			fw.close();		</span><br><span class="line">		&#125;catch (IOException e)&#123;			</span><br><span class="line">			System.out.println(e.toString());		</span><br><span class="line">		&#125;		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注 意:</p>
<ul>
<li>定义文件路径时，注意：可以用“&#x2F;”或者“\”。</li>
<li>在写入一个文件时，如果目录下有同名文件将被覆盖。</li>
<li>在读取文件时，必须保证该文件已存在，否则出异常。</li>
</ul>
</li>
</ol>
<h1 id="3-缓冲流-处理流"><a href="#3-缓冲流-处理流" class="headerlink" title="3. 缓冲流(处理流)"></a>3. 缓冲流(处理流)</h1><p>为了提高数据读写的速度，JavaAPI提供了带缓冲功能的流类，在使用这些流类时，会创建一个内部缓冲区数组。</p>
<p>根据数据操作单位可以把缓冲流分为：</p>
<ul>
<li>BufferedInputStream 和 BufferedOutputStream</li>
<li>BufferedReader 和 BufferedWriter</li>
</ul>
<p>缓冲流要“套接”在相应的节点流之上，对读写的数据提供了缓冲的功能，提高了读写的效率，同时增加了一些新的方法。</p>
<p><strong>对于输出的缓冲流，写出的数据会先在内存中缓存，使用flush()将会使内存中的数据立刻写出。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BufferedReader br = null;</span><br><span class="line">BufferedWriter bw = null;		</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">//step1:创建缓冲流对象：它是过滤流，是对节点流的包装	</span><br><span class="line">	br = new  BufferedReader(new FileReader(&quot;d:\\IOTest\\source.txt&quot;));	</span><br><span class="line">	bw = new BufferedWriter(new FileWriter(&quot;d:\\IOTest\\destBF.txt&quot;));	</span><br><span class="line">	String str = null;	</span><br><span class="line">	</span><br><span class="line">	while ((str = br.readLine()) != null) &#123; </span><br><span class="line">		//一次读取字符文本文件的一行字符				</span><br><span class="line">		bw.write(str); //一次写入一行字符串		</span><br><span class="line">		bw.newLine();  //写入行分隔符	</span><br><span class="line">	&#125; 	</span><br><span class="line">	bw.flush();  </span><br><span class="line">	</span><br><span class="line">	//step2:刷新缓冲区</span><br><span class="line">&#125; catch (IOException e) &#123;	</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">	// step3: 关闭IO流对象	</span><br><span class="line">	try &#123;		</span><br><span class="line">		if (bw != null) &#123;			</span><br><span class="line">			bw.close();  //关闭过滤流时,会自动关闭它所包装的底层节点流		</span><br><span class="line">		&#125;	</span><br><span class="line">	&#125; catch (IOException e) &#123;		</span><br><span class="line">		e.printStackTrace();	</span><br><span class="line">	&#125;	</span><br><span class="line">	try &#123;		</span><br><span class="line">		if (br != null) &#123;		</span><br><span class="line">			br.close();		</span><br><span class="line">		&#125;  	</span><br><span class="line">	&#125; catch (IOException e) &#123;		</span><br><span class="line">		e.printStackTrace();	</span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>常见的编码表</p>
<ul>
<li>ASCII：美国标准信息交换码。用一个字节的7位可以表示。</li>
<li>ISO8859-1：拉丁码表。欧洲码表。用一个字节的8位表示。</li>
<li>GB2312：中国的中文编码表。</li>
<li>GBK：中国的中文编码表升级，融合了更多的中文文字符号。</li>
<li>Unicode：国际标准码，融合了多种文字。所有文字都用两个字节来表示,Java语言使用的就是unicode</li>
<li>UTF-8：最多用三个字节来表示一个字符。</li>
</ul>
<p><strong>编码：字符串—&gt;字节数组</strong></p>
<p><strong>解码：字节数组—&gt;字符串</strong></p>
<h1 id="4-对象流"><a href="#4-对象流" class="headerlink" title="4. 对象流"></a>4. 对象流</h1><ul>
<li>ObjectInputStream和OjbectOutputSteam</li>
<li>用于存储和读取对象的处理流。它的强大之处就是可以把Java中的对象写入到数据源中，也能把对象从数据源中还原回来。</li>
<li>序列化(Serialize)：用ObjectOutputStream类将一个Java对象写入IO流中</li>
<li>反序列化(Deserialize)：用ObjectInputStream类从IO流中恢复该Java对象</li>
</ul>
<p>ObjectOutputStream和ObjectInputStream不能序列化static和transient修饰的成员变量。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title>java面试84讲</title>
    <url>/2019/01/10/Java/java%E9%9D%A2%E8%AF%9584%E8%AE%B2/</url>
    <content><![CDATA[<h1 id="1-Java基础部分"><a href="#1-Java基础部分" class="headerlink" title="1. Java基础部分"></a>1. Java基础部分</h1><h2 id="1-1-跨平台原理"><a href="#1-1-跨平台原理" class="headerlink" title="1.1 跨平台原理"></a>1.1 跨平台原理</h2><p>由于操作系统的指令集不完全一致，同一程序在不同的操作系统中需要执行不同的程序代码。</p>
<p>java通过java虚拟机屏蔽各个系统之间的差异。java虚拟机将.java文件编译成.class文件，然后不同的操作系统对应的java虚拟机略有不同，有java虚拟机将.class文件翻译成机器码交由操作系统运行。</p>
<p>java通过不同系统，不同位数的java虚拟机屏蔽操作系统之间的差异。因此对于外界来说，java是跨平台的。</p>
<h2 id="1-2-java中int-数据占几个字节"><a href="#1-2-java中int-数据占几个字节" class="headerlink" title="1.2 java中int 数据占几个字节"></a>1.2 java中int 数据占几个字节</h2><p>Java中有8种基本数据类型</p>
<p>数据类型 二进制位数(字节数) 范围</p>
<p>byte 8（1） -128 - 127</p>
<p>short 16（2） -32768 - 32768</p>
<p>int 32（4）</p>
<p>long 64（8）</p>
<p>float 32（4）</p>
<p>double 64（8）</p>
<p>char 16（2）</p>
<p>boolean 1</p>
<h2 id="1-3-面向对象的特征有哪些方面"><a href="#1-3-面向对象的特征有哪些方面" class="headerlink" title="1.3 面向对象的特征有哪些方面"></a>1.3 面向对象的特征有哪些方面</h2><p>有三大基本特征：封装，继承，多态</p>
<ul>
<li><p>封装：将描述一个对象的属性和行为封装成一个类，把具体的业务逻辑功能实现封装成一个方法。封装的意义：把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。</p>
<p>—-&gt;减少了大量的冗余代码<br>—-&gt;封装将复杂的功能封装起来，对外开放一个接口，简单调用即可。</p>
</li>
<li><p>继承：所有的子类所共有的行为和属性抽取为一个父类，实现代码的复用。所有的子类继承该类可具备父类的属性和行为，继承具有单一性和传递性。</p>
<p>—-&gt;减少了类的冗余代码<br>—-&gt;让类与类之间产生关系，为多态打下基础</p>
</li>
<li><p>多态：多态性体现在父类中定义的属性和方法被子类继承后，子类可以具有不同的属性或表现方式。</p>
<p>—–&gt;虚方法 virtual override<br>—–&gt;抽象类 abstract override<br>—–&gt;接口 interface</p>
<p>多态可分为行为多态和对象多态。</p>
<ul>
<li>行为多态：同一个run( ){ }方法，不同的对象调用时会有不同的实现。</li>
<li>对象多态：同一个对象，可以被造型为不同的类型。定义一个引用变量，他所指向的具体类型和通过该引用变量调用的方法在编程时并不确定，只有<strong>在程序运行期间才确定</strong>，即一个引用变量具体指向哪个类的实例对象。</li>
</ul>
</li>
</ul>
<h2 id="1-4-为什么需要包装类"><a href="#1-4-为什么需要包装类" class="headerlink" title="1.4 为什么需要包装类"></a>1.4 为什么需要包装类</h2><p>包装类是使得基本数据类型具有类的性质。jdk1.5以后自动装箱和拆箱。</p>
<p>原因：java是面向对象的语言，而基本数据类型不具有对象的特征，为了让基本类型也具有对象的特征，就出现了包装类型。</p>
<p>为什么存在这两种类型呢？</p>
<p>在Java语言中，new一个对象存储在堆里，我们通过栈中的引用来使用这些对象；但是对于经常用到的一系列类型如int，如果我们用new将其存储在堆里就不是很有效——特别是简单的小的变量。所以就出现了基本类型，对于这些类型不是用new关键字来创建，而是直接将<strong>变量的值存储在栈中</strong>，因此更加高效。</p>
<h2 id="1-5-x3D-x3D-和equals的区别？"><a href="#1-5-x3D-x3D-和equals的区别？" class="headerlink" title="1.5 &#x3D;&#x3D; 和equals的区别？"></a>1.5 &#x3D;&#x3D; 和equals的区别？</h2><p>基本数据类型的话，&#x3D;&#x3D; 比较的是两个变量的值是否相等。</p>
<p>引用数据类型的话，&#x3D;&#x3D; 比较的是两个变量的内存地址是否相等。</p>
<p>equals的话 用来比较两个对象是否长得一样，本质就是调用对象的equals方法。（需要重写object的equals方法，如果不重写的话，比较的也是内存地址）</p>
<p>ps:基本数据类型没有equals方法，他是object的一个方法。</p>
<h2 id="1-6-String-StringBuilder-StringBuffer的区别？"><a href="#1-6-String-StringBuilder-StringBuffer的区别？" class="headerlink" title="1.6 String,StringBuilder,StringBuffer的区别？"></a>1.6 String,StringBuilder,StringBuffer的区别？</h2><p>String类提供了数值不可改变的字符串。final类</p>
<p>StringBuilder,StringBuffer是内容可以改变的字符串。底层使用的是可变字符数组。</p>
<p>StringBuilder线程不安全，高效，StringBuffer线程安全，效率不高（synchronized修饰）</p>
<h2 id="1-7-讲一下java中的集合"><a href="#1-7-讲一下java中的集合" class="headerlink" title="1.7 讲一下java中的集合"></a>1.7 讲一下java中的集合</h2><p>Java中集合分两种：value和key-value两种。</p>
<p>存储值的又分为：<strong>List和Set</strong></p>
<ul>
<li>List是有序的，可以重复的</li>
<li>Set是无序的，不可重复的，根据equals和hashcode判断。ps:如果一个对象要存在set中，必须重写equals和hashcode方法。</li>
</ul>
<p>存储key-value的有：<strong>map</strong></p>
<h2 id="1-8-ArrayList-和-LinkList的区别？"><a href="#1-8-ArrayList-和-LinkList的区别？" class="headerlink" title="1.8 ArrayList 和 LinkList的区别？"></a>1.8 ArrayList 和 LinkList的区别？</h2><p>ArrayList 底层数组实现。LinkList底层链表实现。</p>
<p>数组查询快，插入和删除比较慢。（数组在内存中是一块连续的内存，插入和删除需要移动数据）</p>
<p>链表不要求内存连续，因此插入和删除快（只需要改变引用即可），查找慢。</p>
<p>ArrayList 使用场景：查询多，修改和删除较少，反之LinkList。</p>
<h2 id="1-9-HashMap和HashTable的区别？"><a href="#1-9-HashMap和HashTable的区别？" class="headerlink" title="1.9 HashMap和HashTable的区别？"></a>1.9 HashMap和HashTable的区别？</h2><p>相同点：HashMap和Hashtable都用来存储key-value数据。</p>
<p>区别：</p>
<p>HashMap最多只允许一条记录的键为Null;允许多条记录的值为 Null;而Hashtable不允许为空。</p>
<p>HashMap不支持线程的同步（线程不安全），效率较高，Hashtable支持线程的同步（线程安全），效率较低。</p>
<p>如果既想要线程安全有想要高效，使用ConcurrentHashMap（jdk1.5以后）。</p>
<p>原理：将一个hashmap分为几块,每一小块都是线程安全的，一定程度上将锁的区域减小，在线程安全的基础上，提高效率。</p>
<h2 id="1-10-实现一个文件拷贝的工具类，使用字节流还是字符流？"><a href="#1-10-实现一个文件拷贝的工具类，使用字节流还是字符流？" class="headerlink" title="1.10 实现一个文件拷贝的工具类，使用字节流还是字符流？"></a>1.10 实现一个文件拷贝的工具类，使用字节流还是字符流？</h2><p>因为文件拷贝不只包含字符流，比如图像，声音等，因此使用字节流。</p>
<h2 id="1-11-线程的几种实现方式？怎么启动？怎么区分？线程池的作用？"><a href="#1-11-线程的几种实现方式？怎么启动？怎么区分？线程池的作用？" class="headerlink" title="1.11 线程的几种实现方式？怎么启动？怎么区分？线程池的作用？"></a>1.11 线程的几种实现方式？怎么启动？怎么区分？线程池的作用？</h2><p>线程的2种常用实现方式：</p>
<ul>
<li><p>继承Thread类，重写run方法，实现一个线程</p>
</li>
<li><p>实现Runnable接口，重写run方法，实现一个线程。</p>
<p>使用new Thread(new Runnable实现类) 这种方式来生成线程对象，这个时候线程对象中的run方法才会去执行我们自己实现的Runnable接口中的run方法。</p>
</li>
</ul>
<p>怎么启动？</p>
<ul>
<li><p>继承Thread类。</p>
<p>MyThread thread &#x3D; new MyThread();</p>
<p>thread .start();</p>
</li>
<li><p>实现Runnable接口(MyThread)</p>
<p>Thread thread &#x3D; new Thread(new MyThread);</p>
<p>thread .start();</p>
<p>启动线程使用start方法， 启动以后执行的是run方法。</p>
</li>
</ul>
<p>怎么区分线程？thread .setName(“MyThread”);</p>
<p>线程池的作用？</p>
<p> 在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。</p>
<p> 线程的创建是耗时的，因此在应用启用后，预先启动一定数量的线程，当需要的时候，取一个分配给他，执行结束再还给线程池。</p>
<p>作用：</p>
<ul>
<li><strong>限定线程的个数</strong>，不由由于线程过多导致系统运行缓慢或者崩溃。</li>
<li><strong>降低资源消耗</strong>。不需要频繁的创建和销毁，节约资源。</li>
<li><strong>提高响应速度</strong>。当任务到达时，任务可以不需要等到线程创建就能立即执行。</li>
<li><strong>提高线程的可管理性</strong>。</li>
</ul>
<h2 id="1-12-有没有使用过线程并发库？"><a href="#1-12-有没有使用过线程并发库？" class="headerlink" title="1.12 有没有使用过线程并发库？"></a>1.12 有没有使用过线程并发库？</h2><p>简单使用过。jdk1.5以后增加的。对Java线程的管理和使用提供了很大的便利性。</p>
<p>java.util.current包，包含了对线程优化，管理的各项操作。</p>
<p><strong>java中如何创建线程池</strong>？</p>
<ul>
<li>newCachedThreadPool创建一个<strong>可缓存线程池</strong>，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。</li>
<li>newFixedThreadPool 创建一个<strong>定长线程池</strong>，可控制线程最大并发数，超出的线程会在队列中等待。</li>
<li>newScheduledThreadPool 创建一个<strong>定长线程池</strong>，支持定时及周期性任务执行。</li>
<li>newSingleThreadExecutor 创建一个<strong>单线程化的线程池</strong>，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。</li>
</ul>
<h1 id="2-java容器"><a href="#2-java容器" class="headerlink" title="2. java容器"></a>2. java容器</h1><p>Java容器可分为两大类：</p>
<ul>
<li><p>Collection</p>
</li>
<li><ul>
<li>List</li>
<li><ul>
<li><strong>ArrayList</strong></li>
<li>LinkedList</li>
<li>Vector(了解，已过时)</li>
</ul>
</li>
</ul>
</li>
<li></li>
<li><p>Set</p>
</li>
<li><ul>
<li>TreeSet</li>
<li><strong>HashSet</strong></li>
<li><ul>
<li>LinkedHashSet</li>
</ul>
</li>
</ul>
</li>
<li><p>Map</p>
</li>
<li><ul>
<li><strong>HashMap</strong></li>
<li><ul>
<li>LinkedHashMap</li>
</ul>
</li>
<li>TreeMap</li>
<li>ConcurrentHashMap</li>
<li>Hashtable(了解，，已过时)</li>
</ul>
</li>
</ul>
<h2 id="2-1-Collection"><a href="#2-1-Collection" class="headerlink" title="2.1 Collection"></a>2.1 Collection</h2><h3 id="2-1-1-数组和集合的区别"><a href="#2-1-1-数组和集合的区别" class="headerlink" title="2.1.1 数组和集合的区别"></a>2.1.1 数组和集合的区别</h3><ul>
<li>1.长度的区别</li>
<li><ul>
<li><strong>数组的长度固定</strong></li>
<li><strong>集合的长度可变</strong></li>
</ul>
</li>
<li>2.元素的数据类型</li>
<li><ul>
<li>数组可以存储基本数据类型,也可以存储引用类型</li>
<li><strong>集合只能存储引用类型(你存储的是简单的int，它会自动装箱成Integer)</strong></li>
</ul>
</li>
</ul>
<p>###2.1.2 Collection</p>
<p>Collection接口 继承 Iterator接口， 因此<strong>遍历集合(Collection)的元素都可以使用Iterator</strong>。</p>
<p><strong>List（有序，可重复）:</strong></p>
<ul>
<li><strong>ArrayList</strong>：底层数据结构是数组。线程不安全</li>
<li><strong>Vector</strong>：底层数据结构是数组。线程安全</li>
<li><strong>LinkedList</strong>：底层数据结构是链表。线程不安全</li>
</ul>
<p><strong>Set（元素不可重复）: Set集合实际上就是HashMap来构建的!</strong></p>
<ul>
<li><strong>HashSet</strong>：底层数据结构是哈希表(是一个元素为链表的数组)，链地址法解决冲突。</li>
<li><strong>TreeSet</strong>：底层数据结构是红黑树(是一个自平衡的二叉树)，保证元素的排序方式。</li>
<li><strong>LinkedHashSet</strong>：底层数据结构由哈希表和链表组成。</li>
</ul>
<p>###</p>
<ul>
<li><p>Vector与ArrayList区别(<strong>底层都是数组实现</strong>)：</p>
</li>
<li><p>add(E e), add(int index, E element), get(int index),set(int index, E e),remove(int index)</p>
<ul>
<li><p>Vector底层也是数组，与ArrayList最大的区别就是：<strong>同步(线程安全)</strong></p>
<p>Vector的方法使用synchronized的修饰。</p>
</li>
<li><p><strong>ArrayList在底层数组不够用时在原来的基础上扩展0.5倍，Vector是扩展1倍。</strong></p>
</li>
</ul>
</li>
</ul>
<p>如果<strong>想要ArrayList实现同步</strong>，可以使用Collections（集合的工具类）的方法：</p>
<p><code>List list =Collections.synchronizedList(new ArrayList(...));</code>，就可以实现同步了~</p>
<ul>
<li><p>LinkedList（底层是</p>
<p>双向链表</p>
<p>）</p>
<ul>
<li><strong>LinkedList实现了Deque接口</strong>，可以<strong>操作LinkedList像操作队列和栈一样</strong>。</li>
<li>add(E e), remove(Object o), get(nt index),set(int index, E e)</li>
</ul>
</li>
</ul>
<h2 id="2-2-Map"><a href="#2-2-Map" class="headerlink" title="2.2 Map"></a>2.2 Map</h2><p><strong>HashMap, HashTable, ConcurrentHashMap, LinkedHashMap, TreeMap</strong></p>
<p>Map特点：</p>
<p>将键映射到值的对象，一个映射不能包含重复的键，每个键至多只能一个值。</p>
<p>Map与Collection的区别：</p>
<ol>
<li>Map存储元素是成对出现的，键是唯一的，值可以重复。</li>
<li>Collection存储元素是单独出现的，Set的元素是唯一的，List是可重复的。</li>
</ol>
<p>HashMap: put(key,value), get(key), remove(key)</p>
<ul>
<li><p><strong>散列表介绍</strong></p>
<p>无论是Set还是Map，我们会发现都会有对应的–&gt;<strong>Hash</strong>Set,<strong>Hash</strong>Map</p>
<p>原理：散列表<strong>为每个对象计算出一个整数，称为散列码</strong>。<strong>根据</strong>这些计算出来的<strong>整数(散列码)保存在对应的位置上</strong>！</p>
<p><strong>在Java中，散列表用的是链表数组实现的，每个列表称之为桶。</strong></p>
<ul>
<li>如果散列表太满，<strong>是需要对散列表再散列，创建一个桶数更多的散列表，并将原有的元素插入到新表中，丢弃原来的表</strong>~</li>
<li>装填因子(load factor)<strong>决定了何时</strong>对散列表再散列~，装填因子默认为0.75，如果表中<strong>超过了75%的位置</strong>已经填入了元素，那么这个表就会用<strong>双倍的桶数</strong>自动进行再散列</li>
</ul>
</li>
</ul>
<h4 id="2-1-3-1-HashMap和Hashtable的区别"><a href="#2-1-3-1-HashMap和Hashtable的区别" class="headerlink" title="2.1.3.1 HashMap和Hashtable的区别"></a>2.1.3.1 HashMap和Hashtable的区别</h4><p><strong>共同点：</strong></p>
<ul>
<li>从存储结构和实现来讲基本上都是相同的，都是实现Map接口~</li>
</ul>
<p><strong>区别：</strong></p>
<ul>
<li><p><strong>同步性：</strong></p>
</li>
<li><ul>
<li>HashMap是非同步的</li>
<li>Hashtable是同步的</li>
</ul>
</li>
<li><p><strong>是否允许为null：</strong></p>
</li>
<li><ul>
<li>HashMap允许为null</li>
<li>Hashtable不允许为null</li>
</ul>
</li>
<li><p><strong>继承不同：</strong></p>
</li>
<li><ul>
<li><p>HashMap</p>
<p>extends AbstractMap</p>
</li>
<li><p>public class Hashtable</p>
<p>extends Dictionary</p>
</li>
</ul>
</li>
</ul>
<h2 id="2-3-Set集合"><a href="#2-3-Set集合" class="headerlink" title="2.3 Set集合"></a>2.3 Set集合</h2><p>Set集合实际上就是HashMap来构建的!</p>
<p>Set里的元素是不能重复的，那么用什么方法来区分重复与否呢? 是用&#x3D;&#x3D;还是equals()?</p>
<p> <strong>&#x3D;&#x3D; 和 equals()方法都有使用</strong>！</p>
<ul>
<li><p>Set集合实际<strong>大都使用的是Map集合的put方法来添加元素</strong>。</p>
<p>以HashSet为例，添加元素的时候，如果key(也对应的Set集合的元素)相等，那么则修改value值。而在Set集合中，value值仅仅是一个Object对象罢了(<strong>该对象对Set本身而言是无用的</strong>)。</p>
<p>因此，Set集合如果添加的元素相同时，**是根本没有插入的(仅修改了一个无用的value值)**！</p>
</li>
</ul>
<h1 id="3-数据库部分"><a href="#3-数据库部分" class="headerlink" title="3. 数据库部分"></a>3. 数据库部分</h1><h2 id="3-1-介绍数据库的三范式？"><a href="#3-1-介绍数据库的三范式？" class="headerlink" title="3.1 介绍数据库的三范式？"></a>3.1 介绍数据库的三范式？</h2><p>一范式：列不可再分。</p>
<p>二范式：满足一范式的条件下，非主属性完全依赖于码。（码：唯一确定一个元组的某个属性（或者属性组））</p>
<p>三范式：满足二范式的条件下，不存在传递函数依赖。</p>
<p>总结：</p>
<ul>
<li>第一范式：简单说 列不能再分</li>
<li>第二范式：简单说 建立在第一范式基础上，消除部分依赖</li>
<li>第三范式：简单说 建立在第二范式基础上，消除传递依赖。</li>
</ul>
<h2 id="3-2-事务的四个基本特征"><a href="#3-2-事务的四个基本特征" class="headerlink" title="3.2 事务的四个基本特征"></a>3.2 事务的四个基本特征</h2><p>事务是并发控制的单位，是一个操作序列，要么都做，要么都不做。</p>
<p>原子性，一致性，隔离性，持久性。</p>
<ul>
<li>原子性：事务内操作不可分割。</li>
<li>一致性：要么都做，要么都不做。</li>
<li>隔离性：事务开始后，不受其他事务的影响。</li>
<li>持久性：事务一旦提交，其更改是永久性的，即使数据库系统崩溃也能恢复。</li>
</ul>
<h2 id="3-3-mysql数据库的默认最大连接数"><a href="#3-3-mysql数据库的默认最大连接数" class="headerlink" title="3.3 mysql数据库的默认最大连接数"></a>3.3 mysql数据库的默认最大连接数</h2><p>默认：100</p>
<p>为什么需要最大连接数？</p>
<p> 连接过多导致性能下降，严重影响数据库的服务。</p>
<h2 id="3-4-数据库分页"><a href="#3-4-数据库分页" class="headerlink" title="3.4 数据库分页"></a>3.4 数据库分页</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql:  -- limit offset,size</span><br><span class="line">select * from student order by id limit pagesize*(pagenum-1),pagesize;</span><br><span class="line"></span><br><span class="line">oracle:</span><br><span class="line">select * from	</span><br><span class="line">		(select *,rownum rid from</span><br><span class="line">					(select * from student order by id)     </span><br><span class="line">		where rid&lt;= pagesize*pagenum as t )</span><br><span class="line">where t &gt; pagesize*(pagenum-1)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell编程</title>
    <url>/2019/02/01/Linux/Linux%20Shell%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Shell是一个命令行解释器，它为用户提供了一个向Linux内核发送请求以便运行程序的界面系统级程序。</p>
<p>用户可以用Shell来启动、挂起、停止甚至是编写一些程序。</p>
<p><a href="20220708-2.jpg"><img src="/../../../../images/20220708-2.jpg" alt="img"></a></p>
<ul>
<li>Shell还是一个<strong>功能相当强大的编程语言</strong>，易编写、易调试、灵活性强。</li>
<li>Shell是解释执行的脚本语言，在Shell中可以调用Linux系统命令。</li>
</ul>
<h2 id="shell脚本的执行方式"><a href="#shell脚本的执行方式" class="headerlink" title="shell脚本的执行方式"></a>shell脚本的执行方式</h2><ul>
<li><p>echo输出内容到控制台</p>
<ul>
<li><p>基本语法：</p>
<p>echo [ 选项] [输出内容]</p>
<p>选项：-e： 支持反斜线控制的字符转换</p>
<p><a href="http://ww1.sinaimg.cn/large/a3a0cfd7ly1g6cu543o7aj20hp0dxmxk.jpg"><img src="http://ww1.sinaimg.cn/large/a3a0cfd7ly1g6cu543o7aj20hp0dxmxk.jpg" alt="img"></a></p>
</li>
<li><p>案例</p>
<blockquote>
<p>echo “helloworld”   –输出helloworld</p>
</blockquote>
</li>
</ul>
</li>
<li><p>脚本格式</p>
<ol>
<li>脚本以 #!&#x2F;bin&#x2F;bash 开头</li>
<li>脚本必须有可执行权限</li>
</ol>
</li>
<li><p>第一个shell脚本  helloworld.sh</p>
<p>touch &#x2F;opt&#x2F;shellcode&#x2F;helloworld.sh</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash   </span><br><span class="line">echo &quot;helloworld&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>脚本的常用执行方式</p>
<ol>
<li><p>输入脚本的绝对路径或相对路径</p>
<ol>
<li><p>赋予helloworld.sh 脚本的+x权限</p>
<p>chmod 777 helloworld.sh</p>
</li>
<li><p>执行脚本</p>
<ul>
<li>&#x2F;opt&#x2F;shellcode&#x2F;helloWorld.sh</li>
<li>.&#x2F;helloWorld.sh</li>
</ul>
</li>
</ol>
</li>
<li><p>bash或sh+脚本（不用赋予脚本+x权限）</p>
<ul>
<li>sh &#x2F;root&#x2F;helloWorld.sh</li>
<li>sh helloWorld.sh</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="shell中的变量"><a href="#shell中的变量" class="headerlink" title="shell中的变量"></a>shell中的变量</h2><p> 1）Linux Shell中的变量分为，系统变量和用户自定义变量。</p>
<p> 2）系统变量：$HOME、$PWD、$SHELL、$USER等等</p>
<p> 3）显示当前shell中所有变量：set</p>
<h3 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h3><ul>
<li><p>基本语法：</p>
<ol>
<li>定义变量：变量&#x3D;值</li>
<li>撤销变量：unset 变量</li>
<li>声明静态变量：readonly变量，注意：不能unset</li>
</ol>
</li>
<li><p>变量定义规则</p>
<ol>
<li>变量名称可以由字母、数字和下划线组成，但是不能以数字开头。</li>
<li><strong>等号两侧不能有空格</strong></li>
<li>变量名称一般习惯为大写</li>
</ol>
</li>
<li><p>案例</p>
<ul>
<li><p>定义变量A</p>
<blockquote>
<p>A&#x3D;8</p>
</blockquote>
</li>
<li><p>撤销变量A</p>
<blockquote>
<p>unsetA</p>
</blockquote>
</li>
<li><p>声明静态的变量B&#x3D;2，不能unset</p>
<blockquote>
<p>readonlyB &#x3D; 2</p>
</blockquote>
</li>
<li><p>可把变量提升为全局环境变量，可供其他shell程序使用</p>
<blockquote>
<p>export 变量名</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="将命令的返回值赋值给变量"><a href="#将命令的返回值赋值给变量" class="headerlink" title="将命令的返回值赋值给变量"></a>将命令的返回值赋值给变量</h3><ul>
<li>A&#x3D;ls − la 反引号，运行里面的命令，并把结果返回给变量A</li>
<li>A&#x3D;$(ls -la) 等价于反引号</li>
</ul>
<h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><ul>
<li><p>基本语法</p>
<ol>
<li>export 变量名&#x3D;变量值 （功能描述：设置环境变量的值）</li>
<li>source 配置文件 （功能描述：让修改后的配置信息立即生效）</li>
<li>echo $变量名 （功能描述：查询环境变量的值）</li>
</ol>
</li>
<li><p>案例</p>
<ol>
<li><p>在&#x2F;etc&#x2F;profile文件中定义JAVA_HOME环境变量</p>
<ul>
<li>export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</li>
<li>export PATH&#x3D;PATH:PATH:JAVA_HOME&#x2F;bin</li>
</ul>
</li>
<li><p>查看环境变量JAVA_HOME的值</p>
<blockquote>
<p>echo $JAVA_HOME</p>
</blockquote>
</li>
</ol>
</li>
</ul>
<h3 id="设置位置变量"><a href="#设置位置变量" class="headerlink" title="设置位置变量"></a>设置位置变量</h3><ul>
<li><p>基本语法</p>
<ul>
<li>$n （功能描述：n为数字，$0代表命令本身，$1-$9代表第一到第九个参数，十以上的参数需要用大括号包含，如${10}）</li>
<li>$ *（功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体）</li>
<li>$@ （功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待）</li>
<li>$# （功能描述：这个变量代表命令行中所有参数的个数）</li>
</ul>
</li>
<li><p>案例</p>
<ol>
<li><p>输出 输入的参数1，参数2，所有参数，参数个数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">echo &quot;$0  $1   $2&quot;</span><br><span class="line">echo &quot;$*&quot;</span><br><span class="line">echo &quot;$@&quot;</span><br><span class="line">echo &quot;$#&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>∗与∗与@的区别</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash </span><br><span class="line"></span><br><span class="line">for i in &quot;$*&quot; </span><br><span class="line"># $*中的所有参数看成是一个整体，所以这个for循环只会循环一次         </span><br><span class="line">	do                 </span><br><span class="line">		echo &quot;The parameters is: $i&quot;         </span><br><span class="line">	done </span><br><span class="line"></span><br><span class="line">x=1 </span><br><span class="line"></span><br><span class="line">for y in &quot;$@&quot; </span><br><span class="line"># $@中的每个参数都看成是独立的，所以“$@”中有几个参数，就会循环几次         </span><br><span class="line">	do                 </span><br><span class="line">		echo &quot;The parameter$x is: $y&quot;                 </span><br><span class="line">		x=$(( $x +1 ))         </span><br><span class="line">	done</span><br></pre></td></tr></table></figure>

<ul>
<li>$*和$@都表示传递给函数或脚本的所有参数，不被双引号“ ”包含时，都以$1 $2 …$n的形式输出所有参数。</li>
<li>当它们被双引号“ ”包含时，“$*”会将所有的参数作为一个整体，以“$1 $2<br>…$n” 的形式输出所有参数；“$@”会将各个参数分开，以“$1” “$2”…”$n”的形式输出所有参数。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="预定义变量"><a href="#预定义变量" class="headerlink" title="预定义变量"></a>预定义变量</h3><ul>
<li><p>基本语法：</p>
<ul>
<li>$？ （功能描述：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值为非0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确了。）</li>
<li>$$ （功能描述：当前进程的进程号（PID））</li>
<li>$! （功能描述：后台运行的最后一个进程的进程号（PID））</li>
</ul>
</li>
<li><p>案例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">echo &quot;$$&quot;</span><br><span class="line"></span><br><span class="line">./helloworld.sh &amp;</span><br><span class="line"></span><br><span class="line">echo &quot;$!&quot;</span><br><span class="line">echo &quot;$?&quot;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><ul>
<li><p>基本语法：</p>
<ol>
<li>“$((运算式))”或“$[运算式]”</li>
<li>expr m + n –注意expr运算符间要有空格</li>
<li>expr m - n</li>
<li>expr *, &#x2F;, % 乘，除，取余</li>
</ol>
</li>
<li><p>案例：计算（2+3）X4的值</p>
<ul>
<li><p>采用$[运算式]方式</p>
<blockquote>
<p>S&#x3D;$[(2+3)*4]</p>
<p>echo $S</p>
</blockquote>
</li>
<li><p>expr分布计算</p>
<blockquote>
<p>S&#x3D;expr2+3expr2+3</p>
<p>expr $S * 4</p>
</blockquote>
</li>
<li><p>expr一步完成计算</p>
<blockquote>
<p>expr expr2+3expr2+3 * 4</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h3><h4 id="判断语句"><a href="#判断语句" class="headerlink" title="判断语句"></a>判断语句</h4><ul>
<li><p>基本语法：</p>
<p>[ condition ]（注意condition前后要有空格）</p>
<p>非空返回true，可使用$?验证（0为true，&gt;1为false）</p>
</li>
<li><p>案例：</p>
<p>[ S ] 返回true</p>
</li>
</ul>
<p>[] 返回false</p>
<p>[ condition ] &amp;&amp; echo OK || echo notok 条件满足，执行后面的语句</p>
<h4 id="常用判断条件"><a href="#常用判断条件" class="headerlink" title="常用判断条件"></a>常用判断条件</h4><ol>
<li><p>两个整数之间比较</p>
<blockquote>
<p>&#x3D; 字符串比较</p>
</blockquote>
<blockquote>
<p>-lt 小于</p>
</blockquote>
<blockquote>
<p>-le 小于等于</p>
</blockquote>
<blockquote>
<p>-eq 等于</p>
</blockquote>
<blockquote>
<p>-gt 大于</p>
</blockquote>
<blockquote>
<p>-ge 大于等于</p>
</blockquote>
<blockquote>
<p>-ne 不等于</p>
</blockquote>
</li>
<li><p>按照文件权限进行判断</p>
<blockquote>
<p>-r 有读的权限</p>
</blockquote>
<blockquote>
<p>-w 有写的权限</p>
</blockquote>
<blockquote>
<p>-x 有执行的权限</p>
</blockquote>
</li>
<li><p>按照文件类型进行判断</p>
<blockquote>
<p>-f 文件存在并且是一个常规的文件</p>
</blockquote>
<blockquote>
<p>-e 文件存在</p>
</blockquote>
<blockquote>
<p>-d 文件存在并是一个目录</p>
</blockquote>
</li>
<li><p>案例</p>
<ol>
<li><p>23是否大于等于22</p>
<blockquote>
<p>[ 23 -ge 22 ]</p>
</blockquote>
</li>
<li><p>student.txt是否具有写权限</p>
<blockquote>
<p>[ -w student.txt ]</p>
</blockquote>
</li>
<li><p>&#x2F;root&#x2F;install.log目录中的文件是否存在</p>
<blockquote>
<p>[ -e &#x2F;root&#x2F;install.log ]</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h3><h4 id="if判断"><a href="#if判断" class="headerlink" title="if判断"></a>if判断</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if [ 条件判断式 ]	then   </span><br><span class="line">	程序 </span><br><span class="line">fi </span><br><span class="line"></span><br><span class="line">或者 </span><br><span class="line"></span><br><span class="line">if [ 条件判断式 ]	then     </span><br><span class="line">		程序 </span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>注意事项：其中[ 条件判断式 ]，中括号和条件判断式之间必须有空格</p>
</li>
<li><p>案例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">if [ $1 -eq &quot;123&quot; ]	then        </span><br><span class="line">	echo &quot;123&quot;</span><br><span class="line">elif [ $1 -eq &quot;456&quot; ]	then        </span><br><span class="line">	echo &quot;456&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="case语句"><a href="#case语句" class="headerlink" title="case语句"></a>case语句</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">case $变量名 in   </span><br><span class="line">	&quot;值1&quot;）     </span><br><span class="line">		如果变量的值等于值1，则执行程序1     </span><br><span class="line">	;;   </span><br><span class="line">	&quot;值2&quot;）     </span><br><span class="line">		如果变量的值等于值2，则执行程序2     </span><br><span class="line">	;;   </span><br><span class="line">	…省略其他分支…   </span><br><span class="line">	*）    </span><br><span class="line">    	如果变量的值都不是以上的值，则执行此程序     </span><br><span class="line">    ;; </span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">!/bin/bash</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">	&quot;1&quot;)        </span><br><span class="line">		echo &quot;1&quot;</span><br><span class="line">	;;</span><br><span class="line">	&quot;2&quot;)        </span><br><span class="line">		echo &quot;2&quot;</span><br><span class="line">	;;</span><br><span class="line">	*)        </span><br><span class="line">		echo &quot;other&quot;</span><br><span class="line">	;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for 变量 in 值1 值2 值3…   </span><br><span class="line">	do     </span><br><span class="line">		程序   </span><br><span class="line">	done </span><br><span class="line">	</span><br><span class="line">或者 </span><br><span class="line"></span><br><span class="line">for (( 初始值;循环控制条件;变量变化 ))  </span><br><span class="line">	do     </span><br><span class="line">		程序   </span><br><span class="line">	done</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例 –打印输出参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">#打印数字</span><br><span class="line">for i in &quot;$*&quot;    </span><br><span class="line">	do      </span><br><span class="line">		echo &quot;The num is $i &quot;    </span><br><span class="line">	done</span><br><span class="line"></span><br><span class="line">for j in &quot;$@&quot;        </span><br><span class="line">	do        </span><br><span class="line">		echo &quot;The num is $j&quot;        </span><br><span class="line">	done</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例 – 从1加到100</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">s=0</span><br><span class="line"></span><br><span class="line">for((i=0;i&lt;=100;i++))</span><br><span class="line">	do        </span><br><span class="line">		s=$[$s+$i]</span><br><span class="line">	done</span><br><span class="line">	</span><br><span class="line">echo &quot;$s&quot;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while [ 条件判断式 ]   </span><br><span class="line">	do     </span><br><span class="line">		程序   </span><br><span class="line">	done</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例 – 从1加到100</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">s=0</span><br><span class="line">i=1</span><br><span class="line"></span><br><span class="line">while [ $i -le 100 ]</span><br><span class="line">	do        </span><br><span class="line">		s=$[$s+$i]        </span><br><span class="line">		i=$[$i+1]</span><br><span class="line">	done</span><br><span class="line">	</span><br><span class="line">echo $s</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="read-读取控制台输入"><a href="#read-读取控制台输入" class="headerlink" title="read 读取控制台输入"></a>read 读取控制台输入</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">read(选项)(参数)</span><br><span class="line">选项：</span><br><span class="line">-p：指定读取值时的提示符；</span><br><span class="line">-t：指定读取值时等待的时间（秒）。</span><br><span class="line"></span><br><span class="line">参数       </span><br><span class="line">变量：指定读取值的变量名</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">read -t 7 -p &quot;please 7 miao input your name &quot; NAME</span><br><span class="line"></span><br><span class="line">echo $NAME</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><h4 id="系统函数"><a href="#系统函数" class="headerlink" title="系统函数"></a>系统函数</h4><ul>
<li><p>basename基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">basename [pathname] [suffix]		</span><br><span class="line"></span><br><span class="line">功能描述：basename命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。</span><br><span class="line"></span><br><span class="line">选项：suffix为后缀，如果suffix被指定了，basename会将pathname或string中的suffix去掉。</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例</p>
<blockquote>
<p>basename &#x2F;opt&#x2F;test.txt</p>
<p>basename &#x2F;opt&#x2F;test.txt .txt</p>
</blockquote>
</li>
<li><p>dirname基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dirname 文件绝对路径		</span><br><span class="line"></span><br><span class="line">功能描述：从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分）</span><br></pre></td></tr></table></figure>
</li>
<li><p>案例</p>
<blockquote>
<p>dirname &#x2F;opt&#x2F;test.txt</p>
</blockquote>
</li>
</ul>
<h4 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h4><ul>
<li><p>基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ function ] funname[()]&#123;	</span><br><span class="line">	Action;	</span><br><span class="line">	[return int;]</span><br><span class="line">&#125;	</span><br><span class="line"></span><br><span class="line">funname</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p> （1）必须在调用函数地方之前，先声明函数，shell脚本是逐行运行。不会像其它语言一样先编译。</p>
<p> （2）函数返回值，只能通过$?系统变量获得，可以显示加：return返回，如果不加，将以最后一条命令运行结果，作为返回值。return后跟数值n(0-255)</p>
</li>
<li><p>案例 –计算输入参数的和</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">function sum()&#123;    </span><br><span class="line">	s=0    </span><br><span class="line">	s=$[ $1 + $2 ]    </span><br><span class="line">	echo &quot;$s&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read -p &quot;Please input the number1: &quot; n1;</span><br><span class="line">read -p &quot;Please input the number2: &quot; n2;</span><br><span class="line"></span><br><span class="line">sum $n1 $n2;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux 初学习</title>
    <url>/2018/12/31/Linux/Linux%20%E5%88%9D%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="Linux入门"><a href="#Linux入门" class="headerlink" title="Linux入门"></a>Linux入门</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Linux是一套免费使用和自由传播的类Unix操作系统。</p>
<p>目前知名的发行版有：Ubuntu、RedHat、CentOS、Debain、Fedora、SuSE、OpenSUSE</p>
<h3 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h3><p>centos下载地址：</p>
<ul>
<li>网易镜像：<a href="http://mirrors.163.com/centos/6/isos/">http://mirrors.163.com/centos/6/isos/</a></li>
<li>搜狐镜像：<a href="http://mirrors.sohu.com/centos/6/isos/">http://mirrors.sohu.com/centos/6/isos/</a></li>
</ul>
<h3 id="Linux特点"><a href="#Linux特点" class="headerlink" title="Linux特点"></a>Linux特点</h3><ul>
<li>Linux里面一切皆是文件</li>
<li>Linux里面没有后缀名这一说</li>
</ul>
<h3 id="Linux目录结构"><a href="#Linux目录结构" class="headerlink" title="Linux目录结构"></a>Linux目录结构</h3><ul>
<li><p>&#x2F;bin：是Binary的缩写，这个目录存放着系统必备执行命令</p>
</li>
<li><p>&#x2F;boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件，自己的安装别放这里</p>
</li>
<li><p>&#x2F;dev：Device(设备)的缩写，该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。</p>
</li>
<li><p>&#x2F;etc：所有的系统管理所需要的配置文件和子目录。</p>
</li>
<li><p>&#x2F;home：存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。</p>
</li>
<li><p>&#x2F;lib：系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p>
</li>
<li><p>&#x2F;opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。</p>
</li>
<li><p>&#x2F;root：该目录为系统管理员，也称作超级权限者的用户主目录。</p>
</li>
<li><p>&#x2F;sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。</p>
</li>
<li><p>&#x2F;tmp：这个目录是用来存放一些临时文件的。</p>
</li>
<li><p>&#x2F;usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。</p>
</li>
<li><p>&#x2F;var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。</p>
</li>
</ul>
<h3 id="VI-x2F-VIM编辑器"><a href="#VI-x2F-VIM编辑器" class="headerlink" title="VI&#x2F;VIM编辑器"></a>VI&#x2F;VIM编辑器</h3><ul>
<li><p>Vim编辑器三种模式</p>
<ul>
<li><p>指令模式：控制光标移动，可对文本进行复制、粘贴、删除和查找等工作。</p>
</li>
<li><p>编辑模式：正常的文本录入。</p>
</li>
<li><p>末行模式：保存或退出文档，以及设置编辑环境。</p>
<p><a href="20220707-2"><img src="/../../../../images/20220707-2.jpg" alt="img"></a></p>
</li>
<li><p>命令模式中最常用的一些命令</p>
<ul>
<li>dd 删除（剪切）光标所在整行<br>5dd 删除（剪切）从光标处开始的5行<br>yy 复制光标所在整行<br>5yy 复制从光标处开始的5行<br>u 撤销上一步的操作<br><strong>p</strong> 将之前删除（dd）或复制（yy）过的数据粘贴到光标后面</li>
<li>shirft+g 跳转到最后一行</li>
</ul>
</li>
<li><p>末行模式常用的一些命令</p>
<ul>
<li>:q! 强制退出（放弃对文档的修改内容）<br>:wq! 强制保存退出<br>:set nu 显示行号<br>:set nonu 不显示行号<br>:s&#x2F;one&#x2F;two 将当前光标所在行的第一个one替换成two<br>:s&#x2F;one&#x2F;two&#x2F;g 将当前光标所在行的所有one替换成two<br>:%s&#x2F;one&#x2F;two&#x2F;g 将全文中的所有one替换成two<br>?字符串 在文本中从下至上搜索该字符串<br>&#x2F;字符串 在文本中从上至下搜索该字符串</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="系统管理操作"><a href="#系统管理操作" class="headerlink" title="系统管理操作"></a>系统管理操作</h3><ul>
<li><p>查看ip ：ifconfig</p>
</li>
<li><p>查看主机名：hostname</p>
</li>
<li><p>修改此主机名： vim &#x2F;etc&#x2F;hosts</p>
</li>
<li><p>防火墙</p>
<ul>
<li>service iptables status （功能描述：查看防火墙状态）</li>
<li>chkconfig iptables -list （功能描述：查看防火墙开机启动状态）</li>
<li>service iptables stop （功能描述：临时关闭防火墙）</li>
<li>chkconfig iptables off （功能描述：关闭防火墙开机启动）</li>
<li>chkconfig iptables on （功能描述：开启防火墙开机启动）</li>
</ul>
</li>
<li><p>关机重启</p>
<p>linux大多用在服务器上，很少遇到关机的操作。</p>
<ul>
<li><p>shutdown[选项] 时间</p>
<p>选项：</p>
<p> -h：关机</p>
<p> -r：重启</p>
</li>
<li><p>halt（功能描述：关闭系统）等同shutdown -h now 和 poweroff</p>
</li>
<li><p>reboot（功能描述：就是重启，等同于 shutdown -r now）</p>
</li>
</ul>
</li>
</ul>
<h2 id="常用基本命令"><a href="#常用基本命令" class="headerlink" title="常用基本命令"></a>常用基本命令</h2><h3 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h3><ul>
<li><p>man[命令或配置文件] 获得帮助信息</p>
</li>
<li><p>help 命令 获得shell内置命令的帮助信息</p>
</li>
<li><p>常用快捷键</p>
<p>1）ctrl+ c：停止进程</p>
<p>2）ctrl+l：清屏</p>
<p>3）ctrl+ q：退出</p>
<p>4）善于用tab键</p>
<p>5）上下键：查找执行过的命令</p>
<p>6）ctrl+alt：linux和Windows之间切换</p>
</li>
</ul>
<h3 id="文件目录类"><a href="#文件目录类" class="headerlink" title="文件目录类"></a>文件目录类</h3><ul>
<li><p>pwd 显示当前工作目录的绝对路径</p>
</li>
<li><p>ll 列出目录的内容</p>
</li>
<li><p>mkdir [-p] 要创建的目录</p>
<p> 选项：-p ：创建多层目录</p>
</li>
<li><p>rmdir 删除一个空的目录</p>
</li>
<li><p>touch 文件名称 –创建空文件</p>
</li>
<li><p>cd 切换目录</p>
</li>
</ul>
<p> （1）cd ~或者cd （功能描述：回到自己的家目录）</p>
<p> （2）cd - （功能描述：回到上一次所在目录）</p>
<p> （3）cd .. （功能描述：回到当前目录的上一级目录）</p>
<ul>
<li><p>cp 复制文件或目录</p>
<p>（1）cp source dest （功能描述：复制source文件到dest）</p>
<p>（2）cp -r source target （功能描述：递归复制整个文件夹）</p>
</li>
<li><p>rm 移除文件或目录</p>
<p>（1）rmdir deleteEmptyFolder （功能描述：删除空目录）</p>
<p>（2）rm -rf deleteFile （功能描述：递归删除目录中所有内容）</p>
</li>
<li><p>mv 移动文件与目录或重命名</p>
<p>（1）mv oldNameFile newNameFile （功能描述：重命名）</p>
<p>（2）mv &#x2F;movefile &#x2F;targetFolder （功能描述：递归移动文件）</p>
</li>
<li><p>cat 查看文件内容</p>
<p>cat [选项] 要查看的文件</p>
<p>选项：</p>
<p>-A：相当于 -vET 的整合选项，可列出一些特殊字符而不是空白而已；</p>
<p>-b：列出行号，仅针对非空白行做行号显示，空白行不标行号！</p>
<p>-E：将结尾的断行字节 $ 显示出来；</p>
<p>-n ：列出行号，连同空白行也会有行号，与 -b 的选项不同；</p>
<p>-T：将 [tab] 按键以 ^I 显示出来；</p>
<p>-v ：列出一些看不出来的特殊字符</p>
</li>
<li><p>tac 查看文件内容</p>
<p>查看文件内容，从最后一行开始显示，可以看出 tac 是 cat 的倒著写。</p>
</li>
<li><p>more 查看文件内容</p>
<p>功能使用说明：</p>
<p>空白键 (space)：代表向下翻一页；</p>
<p>Enter:代表向下翻『一行』；</p>
<p>q:代表立刻离开 more ，不再显示该文件内容。</p>
<p>Ctrl+F 向下滚动一屏</p>
<p>Ctrl+B 返回上一屏</p>
<p>&#x3D; 输出当前行的行号</p>
<p>:f 输出文件名和当前行的行号</p>
</li>
<li><p>less 查看文件内容</p>
<p>less 的作用与 more 十分相似，都可以用来浏览文字档案的内容，不同的是 less 允许使用pageup，pagedown往回滚动。</p>
</li>
<li><p>head查看文件内容</p>
<p>查看文件内容，只看头几行。</p>
<p>基本语法 ：head -n 10 文件（功能描述：查看文件头10行内容，10可以是任意行数）</p>
</li>
<li><p>tail 查看文件内容</p>
<p>查看文件内容，只看尾巴几行。</p>
<p>基本语法</p>
<p>（1）tail -n 10 文件 （功能描述：查看文件头10行内容，10可以是任意行数）</p>
<p>（2）tail -f 文件 （功能描述：实时追踪该文档的所有更新）</p>
</li>
<li><p><strong>重定向命令</strong></p>
<p>基本语法：</p>
<p>（1）ls -l &gt;文件 （功能描述：列表的内容写入文件a.txt中（覆盖写））</p>
<p>（2）ls -al &gt;&gt;文件 （功能描述：列表的内容追加到文件aa.txt的末尾）</p>
</li>
<li><p>echo</p>
<p>基本语法：</p>
<p>（1）echo 要显示的内容 &gt;&gt; 存储内容的的文件 （功能描述：将要显 示的内容，存储到文件中）</p>
<p>（2）echo 变量（功能描述：显示变量的值）</p>
</li>
<li><p>ln软链接(相当于快捷方式)</p>
<p>基本语法：ln -s 原文件 目标文件</p>
<p>（功能描述：给原文件创建一个软链接，软链接存放在目标文件目录）</p>
<p>删除软链接： rm -rf atguigu，而不是rm -rf atguigu&#x2F;</p>
</li>
<li><p>history 查看所敲命令历史</p>
</li>
</ul>
<h3 id="时间日期类"><a href="#时间日期类" class="headerlink" title="时间日期类"></a>时间日期类</h3>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux 常用命令</title>
    <url>/2018/12/10/Linux/Linux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="文件和目录常用命令"><a href="#文件和目录常用命令" class="headerlink" title="文件和目录常用命令"></a>文件和目录常用命令</h2><h3 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h3><ul>
<li><p>查看目录 : ls，ll</p>
<p>.&#x2F; 当前目录 ..&#x2F; 父级目录 &#x2F; 根目录</p>
</li>
<li><p>切换目录 : cd</p>
</li>
<li><p>创建目录 : mkdir dirname</p>
</li>
<li><p>删除目录 : rm -rf dirname</p>
</li>
<li><p>拷贝目录 : cp -r dirsource dirtarget</p>
</li>
<li><p>移动目录 : mv -r dirsource dirtarget</p>
</li>
</ul>
<h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><ul>
<li><p>查看文件内容</p>
<p>cat filename (查看文件内容、创建文件、文件合并、追加文件内容 等功能)</p>
<p>more filename (分屏显示文件内容，每次只显示一页内容)</p>
<ul>
<li>空格键 显示手册页的下一屏<br>Enter 键 一次滚动手册页的一行<br>b 回滚一屏<br>f 前滚一屏<br>q 退出<br>&#x2F;word 搜索 word 字符串</li>
</ul>
</li>
<li><p><strong>创建文件</strong> : touch filename</p>
</li>
<li><p>删除文件 : rm -f filename</p>
</li>
<li><p>拷贝目录 : cp filesource filetarget</p>
</li>
<li><p>移动目录 : mv filesource filetarget</p>
</li>
<li><p>文本搜索 : grep</p>
<ul>
<li>-n 显示匹配行及行号<br>-v 显示不包含匹配文本的所有行（相当于求反）<br>-i 忽略大小写</li>
</ul>
</li>
<li><p>常用的两种模式查找\</p>
<ul>
<li>^a 行首，搜寻以 a 开头的行<br>ke$ 行尾，搜寻以 ke 结束的行</li>
</ul>
</li>
<li><p>查看当前文件大小的命令</p>
<ul>
<li><p>ls -lht 列出每个文件的大小和当前目录所有文件大小总和</p>
</li>
<li><p>du -sh * 列出当前文件夹下的所有子文件的大小</p>
<p>hdfs查看文件大小</p>
<p>hadoop fs -du -h file&#x2F;dir</p>
</li>
</ul>
</li>
</ul>
<h3 id="jar包常用操作"><a href="#jar包常用操作" class="headerlink" title="jar包常用操作"></a>jar包常用操作</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 查看 jar 包中的文件列表，并进行重定向</span><br><span class="line">jar -tvf a.jar &gt; a.txt </span><br><span class="line"></span><br><span class="line">-- 更新文件到 jar 中，目录需对应</span><br><span class="line">jar -uf a.jar com/a.class</span><br><span class="line">a.class 文件在 jar 包中的目录是 com/a.class。</span><br><span class="line">a.class 文件在本地路径，相对 a.jar 包，也是 com/a.class。</span><br><span class="line"></span><br><span class="line">-- 增加文件到 jar 中，目录需对应   </span><br><span class="line">与修改一致，jar 中原来没有的目录，会自动创建。</span><br><span class="line"></span><br><span class="line">jar -uf a.jar com/test/a.class</span><br><span class="line"></span><br><span class="line">用法：jar &#123;ctxu&#125;[vfm0Mi] [jar-文件] [manifest-文件] [-C 目录] 文件名 ... 　　</span><br><span class="line">	选项： 　　</span><br><span class="line">	-c 创建新的存档　　</span><br><span class="line">	-t 列出存档内容的列表　　</span><br><span class="line">	-x 展开存档中的命名的（或所有的〕文件　　</span><br><span class="line">	-u 更新已存在的存档　　</span><br><span class="line">	-v 生成详细输出到标准输出上　　</span><br><span class="line">	-f 指定存档文件名　　</span><br><span class="line">	-m 包含来自标明文件的标明信息　　</span><br><span class="line">	-0 只存储方式；未用zip压缩格式　　</span><br><span class="line">	-M 不产生所有项的清单（manifest〕文件　　</span><br><span class="line">	-i 为指定的jar文件产生索引信息　　</span><br><span class="line">	-C 改变到指定的目录，并且包含下列文件　　</span><br><span class="line">	</span><br><span class="line">jar包解压 jar -xvf xxx.jar</span><br><span class="line">重新打包  jar cf xxx.jar *</span><br><span class="line">查看jar包中的文件列表  jar -tvf xxx.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">------------------------------提取zip或jar文件中的某个文件</span><br><span class="line">假如有个压缩包 abc.jar, 里面文件如下 （可以用unzip -l abc.jar 查看）：    </span><br><span class="line">data/1.txt    </span><br><span class="line">data/2.txt</span><br><span class="line">提取里面指定的文件到指定的位置，但上级目录将不会被创建。</span><br><span class="line"></span><br><span class="line">不加-d参数就解压到当前目录，-d参数可以指定不存在的目录，会自动创建。</span><br><span class="line">解压得到的文件名不变。</span><br><span class="line"></span><br><span class="line">unzip -j abc.jar data/2.txt -d /tmp/data_in_abc</span><br><span class="line">---------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><p>echo 会在终端中显示参数指定的文字</p>
</li>
<li><p><strong>重定向 &gt; 和 &gt;&gt;</strong></p>
<ul>
<li>&gt; 表示输出，会覆盖文件原有的内容</li>
<li>&gt;&gt; 表示追加，会将内容追加到已有文件的末尾</li>
</ul>
</li>
<li><p><strong>管道 |</strong></p>
<p>一个命令的输出 可以通过管道 做为 另一个命令的输入</p>
<p>常用的管道命令有：<br>more：分屏显示内容<br>grep：在命令执行结果的基础上查询指定的文本</p>
</li>
</ul>
<h2 id="远程管理常用命令"><a href="#远程管理常用命令" class="headerlink" title="远程管理常用命令"></a>远程管理常用命令</h2><ul>
<li><p>关机&#x2F;重启</p>
<ul>
<li><p>shutdown 选项 时间 : 关机</p>
<p>选项 含义<br>-r 重新启动</p>
</li>
<li><p><strong>halt</strong> 关机</p>
</li>
</ul>
</li>
<li><p>查看或配置网卡信息</p>
<ul>
<li>ifconfig</li>
<li>ping</li>
</ul>
</li>
<li><p>远程登录</p>
<ul>
<li>ssh 用户名@ip</li>
</ul>
</li>
<li><p>复制文件</p>
<ul>
<li>scp</li>
</ul>
</li>
<li><p>su命令与su - 命令的区别：</p>
<p>su只是切换了root身份，但Shell环境仍然是普通用户的Shell；</p>
<p>su -连用户和Shell环境一起切换成root身份了。</p>
<p>PS:只有切换了Shell环境才不会出现PATH环境变量错误，报command not found的错误。</p>
</li>
</ul>
<h2 id="用户权限"><a href="#用户权限" class="headerlink" title="用户权限"></a>用户权限</h2><ul>
<li><p>基本概念</p>
<p>序号 权限 英文 缩写 数字代号<br>01 读 read r 4<br>02 写 write w 2<br>03 执行 excute x 1</p>
</li>
<li><p>组<br>为了方便用户管理，提出了 组 的概念<br>在实际应用中，可以预先针对 组 设置好权限，<br>然后 将不同的用户添加到对应的组中，从而不用依次为每一个用户设置权限</p>
</li>
<li><p><strong>切换用户 su username</strong></p>
</li>
<li><p>退出 exit</p>
</li>
<li><p><strong>修改文件权限</strong></p>
<p> 序号 命令 作用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">01            chown             修改拥有者</span><br><span class="line">02            chgrp             修改组</span><br><span class="line">03            chmod             修改权限</span><br></pre></td></tr></table></figure>

<p>ex. chmod 修改 用户／组 对 文件／目录 的权限</p>
<p> chmod -rwx 文件名|目录名</p>
<ul>
<li><p>递归修改文件|目录的组</p>
<p>chgrp -R 组名 文件名|目录名</p>
</li>
<li><p>递归修改文件权限</p>
<p>chmod -R 755 文件名|目录名</p>
<p><a href="20220707-1"><img src="/../../../../images/20220707-1.jpg" alt="img"></a></p>
</li>
</ul>
</li>
<li><p>sudo</p>
<p>sudo 命令用来以其他身份来执行命令，预设的身份为 root.</p>
<p>使用 sudo 时，必须先输入密码，之后有 5 分钟的有效期限.</p>
</li>
<li><p>组管理</p>
<ul>
<li>添加组 : groupadd 组名</li>
<li>删除组 : groupdel 组名<br>确认组信息 : cat &#x2F;etc&#x2F;group</li>
<li>递归修改文件&#x2F;目录的所属组 : chgrp -R 组名 文件&#x2F;目录名</li>
</ul>
</li>
<li><p>用户管理</p>
<ul>
<li><p><strong>添加新用户</strong> : useradd -m -g 组 新建用户名</p>
<p>-m 自动建立home目录</p>
<p>-g 指定用户所在的组</p>
</li>
<li><p><strong>设置用户密码</strong> : passwd 用户名</p>
</li>
<li><p>删除用户 : userdel -r 用户名</p>
<p>-r 选项会自动删除用户家目录</p>
</li>
<li><p>确认用户信息 cat &#x2F;etc&#x2F;passwd | grep 用户名</p>
<p>新建用户后，用户信息会保存在 &#x2F;etc&#x2F;passwd 文件中</p>
</li>
<li><p><strong>查看用户信息</strong></p>
<p>who 查看当前所有登录的用户列表<br>whoami 查看当前登录用户的账户名</p>
</li>
<li><p>which 命令 ：查看执行命令所在位置</p>
<p>ex. which ls</p>
</li>
</ul>
</li>
</ul>
<h2 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h2><ul>
<li><p>时间和日期</p>
<ul>
<li>date 查看系统时间</li>
<li>cal &#x2F; calendar 查看日历，-y 选项可以查看一年的日历</li>
</ul>
</li>
<li><p>磁盘和目录空间</p>
<ul>
<li><p>df ：disk free 显示磁盘剩余空间</p>
<p>df -h</p>
</li>
<li><p>du：disk usage 显示目录下的文件大小</p>
<p>du -h [目录名]</p>
</li>
</ul>
</li>
<li><p><strong>进程信息</strong>：</p>
<ul>
<li><p>找出占用端口进程的pid</p>
<p>lsof -i:port</p>
</li>
</ul>
</li>
<li><p>ps : process status 查看进程的详细状况</p>
<ul>
<li><p><strong>ps aux</strong></p>
<p>选项 含义<br>a 显示终端上的所有进程，包括其他用户的进程<br>u 显示进程的详细状态<br>x 显示没有控制终端的进程</p>
</li>
</ul>
</li>
<li><p><strong>top</strong> : 动态显示运行中的进程并且排序</p>
</li>
<li><p><strong>kill</strong></p>
<ul>
<li><p>kill [-9] 进程代号</p>
<p>终止指定代号的进程，-9 表示强行终止</p>
</li>
</ul>
</li>
</ul>
<h2 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h2><ul>
<li><p>查找文件 ：find</p>
<p>ex. find [路径] -name “*.py”</p>
<p>查找指定路径下扩展名是 .py 的文件，包括子目录</p>
<p>如果省略路径，表示在当前文件夹下查找</p>
</li>
<li><p>软链接 通俗的方式讲类似于 Windows 下的快捷方式</p>
<p>ln -s 被链接的源文件 链接文件</p>
<p>注意:</p>
<ul>
<li>没有 -s 选项建立的是一个 硬链接文件</li>
<li>源文件要使用绝对路径，不能使用相对路径</li>
</ul>
<p>ln -snf 被链接的源文件 链接文件 –更改软连接</p>
</li>
<li><p>打包和压缩</p>
<p>不同操作系统中，常用的打包压缩方式是不同的。</p>
<ul>
<li>Windows 常用 rar</li>
<li>Mac 常用 zip</li>
<li>Linux 常用 tar.gz</li>
</ul>
<p><strong>打包 ／ 解包</strong>（含压缩）</p>
<ul>
<li><p><strong>打包文件</strong></p>
<p>tar czf 压缩文件名 要压缩的文件夹</p>
<p>ex. tar czf test.tar.gz .&#x2F;opt&#x2F;</p>
</li>
<li><p><strong>解包文件</strong>（-C参数 表示更换目录的意思 ）</p>
<p>tar -zxf 待解压文件 -C 解压到的文件夹</p>
<p>ex. tar -zxf test.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</p>
</li>
<li><p>tar 选项说明<br>选项 含义<br>c 生成档案文件，创建打包文件<br>x 解开档案文件<br>v 列出归档解档的详细过程，显示进度<br>f 指定文件名，f 后面一定是 .tar 文件，必须放选项最后</p>
<p>z 调用 gzip, 实现压缩和解压缩的功能</p>
</li>
</ul>
</li>
<li><p>软件安装</p>
<p>apt 是 Advanced Packaging Tool，是 Linux 下的一款安装包管理工具</p>
<ul>
<li>安装软件 apt-get install 软件包</li>
<li>卸载软件 apt-get remove 软件名</li>
<li>更新已安装的包 apt-get upgrade</li>
</ul>
<p>配置软件源</p>
<ul>
<li><p>在软件和更新中，选项ubuntu软件</p>
<p>设置下载自：<a href="http://mirrors.aliyun.com/ubuntu">http://mirrors.aliyun.com/ubuntu</a></p>
</li>
</ul>
</li>
</ul>
<h2 id="vi-编辑"><a href="#vi-编辑" class="headerlink" title="vi 编辑"></a>vi 编辑</h2><p>很多 Linux 发行版中，直接把 vi 做成 vim 的软连接</p>
<ul>
<li><p>查询软连接命令（知道）</p>
<p>$ which vi</p>
</li>
<li><p>打开和新建文件</p>
<p>vi filename</p>
<ul>
<li>如果文件已经存在，会直接打开该文件</li>
<li>如果文件不存在，会新建一个文件</li>
</ul>
</li>
<li><p>光标上下左右</p>
<p>h j k l<br>左下右上</p>
</li>
<li><p>Vim编辑器三种模式</p>
<ul>
<li><p>命令模式：控制光标移动，可对文本进行复制、粘贴、删除和查找等工作。</p>
</li>
<li><p>输入模式：正常的文本录入。</p>
</li>
<li><p>末行模式：保存或退出文档，以及设置编辑环境。</p>
<p><a href="20220707-2"><img src="/../../../../images/20220707-2.jpg" alt="img"></a></p>
</li>
<li><p>命令模式中最常用的一些命令</p>
<ul>
<li>dd 删除（剪切）光标所在整行<br>5dd 删除（剪切）从光标处开始的5行<br>yy 复制光标所在整行<br>5yy 复制从光标处开始的5行<br>u 撤销上一步的操作<br><strong>p</strong> 将之前删除（dd）或复制（yy）过的数据粘贴到光标后面</li>
<li>shirft+g 跳转到最后一行</li>
</ul>
</li>
<li><p>末行模式常用的一些命令</p>
<ul>
<li>:q! 强制退出（放弃对文档的修改内容）<br>:wq! 强制保存退出<br>:set nu 显示行号<br>:set nonu 不显示行号<br>:s&#x2F;one&#x2F;two 将当前光标所在行的第一个one替换成two<br>:s&#x2F;one&#x2F;two&#x2F;g 将当前光标所在行的所有one替换成two<br>:%s&#x2F;one&#x2F;two&#x2F;g 将全文中的所有one替换成two<br>?字符串 在文本中从下至上搜索该字符串<br>&#x2F;字符串 在文本中从上至下搜索该字符串</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>SparkSQL</title>
    <url>/2018/01/01/Spark/SparkSQL/</url>
    <content><![CDATA[<h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>Spark SQL是Spark用来<strong>处理结构化数据</strong>的一个模块，</p>
<p>它提供了2个编程抽象：<strong>DataFrame</strong>和<strong>DataSet</strong>，并且作为<strong>分布式SQL查询引擎</strong>的作用。</p>
<h3 id="1-1-特点"><a href="#1-1-特点" class="headerlink" title="1.1 特点"></a>1.1 特点</h3><ul>
<li>易整合</li>
<li>统一的数据访问方式</li>
<li>兼容Hive</li>
<li>标准的数据连接</li>
</ul>
<h3 id="1-2-DataFrame"><a href="#1-2-DataFrame" class="headerlink" title="1.2 DataFrame"></a>1.2 DataFrame</h3><p>DataFrame也是一个分布式数据容器。</p>
<p>但DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。</p>
<p>同时，与Hive类似，<strong>DataFrame也支持嵌套数据类型</strong>（struct、array和map）。</p>
<p>DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。</p>
<p> 性能上比RDD要高，主要原因：</p>
<p> 优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。</p>
<h3 id="1-3-DataSet"><a href="#1-3-DataSet" class="headerlink" title="1.3 DataSet"></a>1.3 DataSet</h3><p>DataSet是</p>
<p> 1)Dataframe API的一个扩展，是Spark最新的数据抽象。</p>
<p> 2)用户友好的API风格，既具有类型安全检查也具有Dataframe的查询优化特性。</p>
<p> 3)Dataset支持编解码器，当需要访问非堆上的数据时可以避免反序列化整个对象，提高了效率。</p>
<p> 4)样例类被用来在Dataset中定义数据的结构信息，<strong>样例类中每个属性的名称直接映射到DataSet中的字段名称</strong>。</p>
<p> 5)Dataframe是Dataset的特列，DataFrame&#x3D;Dataset[Row] ，所以可以通过as方法将Dataframe转换为Dataset。Row是一个类型，跟Car、Person这些的类型一样，所有的表结构信息我都用Row来表示。</p>
<p> 6)DataSet是强类型的。比如可以有Dataset[Car]，Dataset[Person].</p>
<p> 7)DataFrame只是知道字段，但是不知道字段的类型，所以在执行这些操作的时候是没办法在编译的时候检查是否类型失败的，比如你可以对一个String进行减法操作，在执行的时候才报错，而DataSet不仅仅知道字段，而且知道字段类型，所以有更严格的错误检查。就跟JSON对象和类对象之间的类比。</p>
<h2 id="2-SparkSQL编程"><a href="#2-SparkSQL编程" class="headerlink" title="2. SparkSQL编程"></a>2. SparkSQL编程</h2><h3 id="2-1-SparkSession"><a href="#2-1-SparkSession" class="headerlink" title="2.1 SparkSession"></a>2.1 SparkSession</h3><p>在<strong>老spark的版本</strong>中，SparkSQL提供两种SQL查询起始点：一个叫<strong>SQLContext</strong>，用于Spark自己提供的SQL查询；一个叫<strong>HiveContext</strong>，用于连接Hive的查询。</p>
<p><strong>SparkSession</strong>是Spark最新的SQL查询起始点，实质上<strong>是SQLContext和HiveContext的组合</strong>，所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。<strong>SparkSession内部封装了sparkContext</strong>，所以计算实际上是由sparkContext完成的。</p>
<h3 id="2-2-DataFrame（DataSet基本一致）"><a href="#2-2-DataFrame（DataSet基本一致）" class="headerlink" title="2.2 DataFrame（DataSet基本一致）"></a>2.2 DataFrame（DataSet基本一致）</h3><h4 id="2-2-1-创建"><a href="#2-2-1-创建" class="headerlink" title="2.2.1 创建"></a>2.2.1 创建</h4><p>在Spark SQL中SparkSession是创建DataFrame和执行SQL的入口，</p>
<p>创建DataFrame有三种方式：</p>
<ul>
<li>通过Spark的数据源进行创建</li>
<li>从一个存在的RDD进行转换</li>
<li>从Hive Table进行查询返回</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 从Spark数据源进行创建</span><br><span class="line">1)查看Spark数据源进行创建的文件格式	</span><br><span class="line">	spark.read.	</span><br><span class="line">	csv   format   jdbc   json   load   option   options   orc	parquet   </span><br><span class="line">	schema   table   text   textFile</span><br><span class="line">	</span><br><span class="line">2)读取json文件创建DataFrame	</span><br><span class="line">	val df=spark.read.json(&quot;/opt/module/spark/.../people.json&quot;)</span><br><span class="line">	</span><br><span class="line">3）展示结果	df.show</span><br><span class="line"></span><br><span class="line">2. 从RDD进行转换</span><br><span class="line">注意：如果需要RDD与DF或者DS之间操作，那么都需要引入 import spark.implicits._  </span><br><span class="line">【spark不是包名，而是sparkSession对象的名称】</span><br><span class="line"></span><br><span class="line">import spark.implicits._</span><br><span class="line">val peopleRDD = sc.textFile(&quot;examples/src/main/resources/people.txt&quot;)</span><br><span class="line"></span><br><span class="line">1)手动转换</span><br><span class="line">peopleRDD.map&#123;x=&gt;    </span><br><span class="line">	val para = x.split(&quot;,&quot;);			  				 		、、、、、</span><br><span class="line">	(para(0),para(1).trim.toInt)	</span><br><span class="line">	&#125;.toDF(&quot;name&quot;,&quot;age&quot;)</span><br><span class="line">	</span><br><span class="line">2）通过反射确定（需要用到样例类）	</span><br><span class="line">	（1）创建一个样例类	</span><br><span class="line">		case class People(name:String, age:Int)	</span><br><span class="line">	（2）根据样例类将RDD转换为DataFrame	</span><br><span class="line">		peopleRDD.map&#123; x =&gt; 	</span><br><span class="line">			val para = x.split(&quot;,&quot;);	</span><br><span class="line">			People(para(0),para(1).trim.toInt)	</span><br><span class="line">		&#125;.toDF</span><br><span class="line">		</span><br><span class="line">3）通过编程的方式（--了解--）	</span><br><span class="line">	（1）导入所需的类型	</span><br><span class="line">		import org.apache.spark.sql.types._	</span><br><span class="line">	（2）创建Schema	</span><br><span class="line">		val structType: StructType = </span><br><span class="line">		StructType(StructField(&quot;name&quot;, StringType) </span><br><span class="line">			:: StructField(&quot;age&quot;, IntegerType) :: Nil)	</span><br><span class="line">			</span><br><span class="line">	（3）导入所需的类型	</span><br><span class="line">		import org.apache.spark.sql.Row	</span><br><span class="line">		</span><br><span class="line">	（4）根据给定的类型创建二元组RDD	</span><br><span class="line">		val data = peopleRDD.map&#123; x =&gt; 	</span><br><span class="line">			val para = x.split(&quot;,&quot;);	</span><br><span class="line">			Row(para(0),para(1).trim.toInt)</span><br><span class="line">		&#125;	</span><br><span class="line">		</span><br><span class="line">	（5）根据数据及给定的schema创建DataFrame	</span><br><span class="line">		val dataFrame = spark.createDataFrame(data, structType)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 从Hive Table进行查询返回</span><br></pre></td></tr></table></figure>

<h4 id="2-2-2-SQL风格语法"><a href="#2-2-2-SQL风格语法" class="headerlink" title="2.2.2 SQL风格语法"></a>2.2.2 SQL风格语法</h4><ol>
<li><p>创建DF</p>
<p>spark.read.json(“”)</p>
</li>
<li><p>对DataFrame创建一个临时表</p>
<p>df.createOrReplaceTempView(“people”)</p>
</li>
<li><p>通过SQL语句实现查询全表</p>
<p>val sqlDF &#x3D; spark.sql(“SELECT * FROM people”)</p>
</li>
<li><p>结果展示</p>
<p>sqlDF.show</p>
</li>
</ol>
<p>注意：临时表是Session范围内的，Session退出后，表就失效了。</p>
<p>如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，</p>
<p>如：global_temp.people</p>
<ol>
<li><p>对于DataFrame创建一个全局表</p>
<p>df.createGlobalTempView(“people”)</p>
</li>
<li><p>通过SQL语句实现查询全表</p>
<p>spark.sql(“SELECT * FROM global_temp.people”).show()</p>
<p>spark.newSession().sql(“SELECT * FROM global_temp.people”).show()</p>
</li>
</ol>
<h3 id="2-3-DataFrame与DataSet的互操作"><a href="#2-3-DataFrame与DataSet的互操作" class="headerlink" title="2.3 DataFrame与DataSet的互操作"></a>2.3 DataFrame与DataSet的互操作</h3><p>在使用一些特殊的操作时，一定要加上 import spark.implicits._</p>
<p>不然toDF、toDS无法使用。</p>
<ol>
<li><p>DataFrame转换为DataSe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）创建一个DateFrame</span><br><span class="line">val df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)</span><br><span class="line"></span><br><span class="line">2）创建一个样例类</span><br><span class="line">case class Person(name: String, age: Long)</span><br><span class="line"></span><br><span class="line">3）将DateFrame转化为DataSet</span><br><span class="line">df.as[Person]</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataSet转换为DataFrame</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）创建一个样例类</span><br><span class="line">case class Person(name: String, age: Long)</span><br><span class="line"></span><br><span class="line">2）创建DataSet</span><br><span class="line">val ds = Seq(Person(&quot;Andy&quot;, 32)).toDS()</span><br><span class="line"></span><br><span class="line">3）将DataSet转化为DataFrame</span><br><span class="line">val df = ds.toDF4)展示df.show</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-4-RDD、DataFrame、DataSet"><a href="#2-4-RDD、DataFrame、DataSet" class="headerlink" title="2.4 RDD、DataFrame、DataSet"></a>2.4 RDD、DataFrame、DataSet</h3><p>在SparkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。</p>
<p>他们和RDD有什么区别呢？首先从版本的产生上来看：</p>
<p> RDD (Spark1.0) —&gt; Dataframe(Spark1.3) —&gt;Dataset(Spark1.6)</p>
<p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。</p>
<p>在后期的Spark版本中，DataSet会逐步取代RDD和DataFrame成为唯一的API接口。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark参数调优</title>
    <url>/2019/10/15/Spark/Spark%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h1 id="Spark参数调优"><a href="#Spark参数调优" class="headerlink" title="Spark参数调优"></a>Spark参数调优</h1><p>参考文献：<a href="https://blog.csdn.net/zyzzxycj/article/details/81011540">https://blog.csdn.net/zyzzxycj/article/details/81011540</a></p>
<p>因为每个集群规模都不一样，只有理解了参数的用途，调试出符合自己业务场景集群环境，并且能在扩大集群、业务的情况下，能够跟着修改参数才算是正确的参数调优。我的目标就是能够熟练的进行参数调优。</p>
<h2 id="1-Application-Properties-应用基本属性"><a href="#1-Application-Properties-应用基本属性" class="headerlink" title="1*. Application Properties 应用基本属性"></a>1*. Application Properties 应用基本属性</h2><p>这些参数比较重要，执行spark的shell 一般都需要配置一下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.driver.cores  	</span><br><span class="line">	driver端分配的核数，默认为1,资源充足的话可以尽量给多。</span><br><span class="line">	</span><br><span class="line">spark.driver.memory	</span><br><span class="line">	driver端分配的内存数，默认为1g，资源充足的话可以尽量给多。</span><br><span class="line">	</span><br><span class="line">spark.executor.memory	</span><br><span class="line">	每个executor分配的内存数，默认1g，会受到yarn CDH的限制，</span><br><span class="line">	和memoryOverhead相加 不能超过总内存限制。</span><br><span class="line"></span><br><span class="line">spark.driver.maxResultSize	</span><br><span class="line">	driver端接收的最大结果大小，默认1GB，最小1MB，设置0为无限。	</span><br><span class="line">	这个参数不建议设置的太大,如果要做数据可视化,更应该控制在20-30MB以内,</span><br><span class="line">	过大会导致OOM(out of memory)。</span><br><span class="line">	</span><br><span class="line">spark.extraListeners.(不常用)	</span><br><span class="line">	默认none，随着SparkContext被创建而创建，用于监听单参数、无参数构造函数的创建，并抛出异常。</span><br><span class="line">	可用于自定义监听，实现监控spark的任务进度。</span><br></pre></td></tr></table></figure>

<h2 id="2-Runtime-Environment-运行环境"><a href="#2-Runtime-Environment-运行环境" class="headerlink" title="2. Runtime Environment 运行环境"></a>2. <strong>Runtime Environment 运行环境</strong></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">主要是一些日志，jvm参数的额外配置，jars等一些自定义的配置(待补充)</span><br></pre></td></tr></table></figure>

<h2 id="3-Shuffle-Behavior"><a href="#3-Shuffle-Behavior" class="headerlink" title="3. Shuffle Behavior"></a>3. Shuffle Behavior</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.reducer.maxSizeInFlight	</span><br><span class="line">	默认48m。从每个reduce任务同时拉取的最大map数，</span><br><span class="line">	每个reduce都会在完成任务后，需要一个堆外内存的缓冲区来存放结果，</span><br><span class="line">	如果没有充裕的内存就尽可能把这个调小一点。</span><br><span class="line">	相反，堆外内存充裕，调大些就能节省gc时间。</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">spark.reducer.maxBlocksInFlightPerAddress(一般不会改)	</span><br><span class="line">	限制了每个主机每次reduce可以被多少台远程主机拉取文件块，</span><br><span class="line">	调低这个参数可以有效减轻node manager的负载。（默认值Int.MaxValue）</span><br><span class="line"></span><br><span class="line">spark.reducer.maxReqsInFlight	</span><br><span class="line">	限制远程机器拉取本机器文件块的请求数，随着集群增大，需要对此做出限制。</span><br><span class="line">	否则可能会使本机负载过大而挂掉。（默认值为Int.MaxValue）</span><br><span class="line">	</span><br><span class="line">spark.reducer.maxReqSizeShuffleToMem	</span><br><span class="line">	shuffle请求的文件块大小 超过这个参数值，就会被强行落盘，</span><br><span class="line">	防止一大堆并发请求把内存占满。（默认Long.MaxValue）</span><br><span class="line">	</span><br><span class="line">spark.shuffle.compress	</span><br><span class="line">	是否压缩map输出文件，默认压缩 true</span><br><span class="line">	</span><br><span class="line">spark.shuffle.spill.compress	</span><br><span class="line">	shuffle过程中溢出的文件是否压缩，默认true，使用spark.io.compression.codec压缩。</span><br><span class="line">	</span><br><span class="line">spark.shuffle.file.buffer	</span><br><span class="line">	在内存输出流中 每个shuffle文件占用内存大小，适当提高 可以减少磁盘读写 io次数，初始值为32k。</span><br><span class="line">	</span><br><span class="line">spark.shuffle.memoryFraction	</span><br><span class="line">	该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。	</span><br><span class="line">	cache少且内存充足时，可以调大该参数，给shuffle read的聚合操作更多内存，</span><br><span class="line">	以避免由于内存不足导致聚合过程中频繁读写磁盘。</span><br><span class="line">	</span><br><span class="line">spark.shuffle.manager	</span><br><span class="line">	当ShuffleManager为SortShuffleManager时，</span><br><span class="line">	如果shuffle read task的数量小于这个阈值（默认是200），	 </span><br><span class="line">	则shuffle write过程中不会进行排序操作，</span><br><span class="line">	而是直接按照未经优化的HashShuffleManager的方式去写数据，</span><br><span class="line">	但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。	</span><br><span class="line">	当使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，</span><br><span class="line">	大于shuffle read 	task的数量。那么此时就会自动启用bypass机制，</span><br><span class="line">	map-side就不会进行排序了，减少了排序的性能开销。</span><br><span class="line">	但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">spark.shuffle.consolidateFiles	</span><br><span class="line">	如果使用HashShuffleManager，该参数有效。</span><br><span class="line">	如果设置为true，那么就会开启consolidate机制，会大幅度合并	 </span><br><span class="line">	shuffle write的输出文件，对于shuffle read task数量特别多的情况下，</span><br><span class="line">	这种方法可以极大地减少磁盘IO开销，提升性能。</span><br><span class="line">	</span><br><span class="line">spark.shuffle.io.maxRetries（重试次数）	</span><br><span class="line">	shuffle read task从shuffle write task所在节点拉取属于自己的数据时，</span><br><span class="line">	如果因为网络异常导致拉取失败，是会自动进行重试的。</span><br><span class="line">	该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，</span><br><span class="line">	就可能会导致作业执行失败。	</span><br><span class="line">	</span><br><span class="line">spark.shuffle.io.retryWait	</span><br><span class="line">	同上，默认5s，建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark.io.encryption.enabled</span><br><span class="line">spark.io.encryption.keySizeBits</span><br><span class="line"></span><br><span class="line">spark.io.encryption.keygen.algorithm	</span><br><span class="line">	io加密，默认关闭</span><br></pre></td></tr></table></figure>

<h2 id="4-Spark-UI"><a href="#4-Spark-UI" class="headerlink" title="4. Spark UI"></a>4. Spark UI</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这一块配置，是有关于spark日志的。日志开关，日志输出路径，是否压缩。(待补充)</span><br></pre></td></tr></table></figure>

<h2 id="5-Compression-and-Serialization压缩与序列化"><a href="#5-Compression-and-Serialization压缩与序列化" class="headerlink" title="5. Compression and Serialization压缩与序列化"></a>5. Compression and Serialization压缩与序列化</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.broadcast.compress	</span><br><span class="line">	广播变量前是否会先进行压缩。默认true （spark.io.compression.codec）</span><br><span class="line">	</span><br><span class="line">spark.io.compression.codec	</span><br><span class="line">	压缩RDD数据、日志、shuffle输出等的压缩格式 默认lz4</span><br><span class="line">	</span><br><span class="line">spark.io.compression.lz4.blockSize	</span><br><span class="line">	使用lz4压缩时，每个数据块大小 默认32k</span><br><span class="line">	</span><br><span class="line">spark.rdd.compress	</span><br><span class="line">	rdd是否压缩 默认false，节省memory_cache大量内存 消耗更多的cpu资源（时间）。</span><br><span class="line">	</span><br><span class="line">spark.serializer.objectStreamReset	</span><br><span class="line">	当使用JavaSerializer序列化时，会缓存对象防止写多余的数据，但这些对象就不会被gc，</span><br><span class="line">	可以输入reset 清空缓存。默认缓存100个对象，修改成-1则不缓存任何对象。</span><br></pre></td></tr></table></figure>

<p>压缩以后节省内存资源，消耗cpu资源。</p>
<h2 id="6-Memory-Management-内存管理"><a href="#6-Memory-Management-内存管理" class="headerlink" title="6. Memory Management 内存管理"></a>6. <strong>Memory Management 内存管理</strong></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.memory.fraction	</span><br><span class="line">	执行内存和缓存内存（堆）占jvm总内存的比例，</span><br><span class="line">	剩余的部分是spark留给用户存储内部源数据、数据结构、异常大的结果数据。</span><br><span class="line">	默认值0.6，调小会导致频繁gc，调大容易造成oom。</span><br><span class="line">	</span><br><span class="line">spark.memory.storageFraction	</span><br><span class="line">	用于存储的内存在堆中的占比，默认0.5。</span><br><span class="line">	调大会导致执行内存过小，执行数据落盘，影响效率；调小会导致缓存内存不够，缓存到磁盘上去，影响效率。</span><br><span class="line">	另外，执行内存和缓存内存公用java堆，当执行内存没有使用时，会动态分配给缓存内存使用，</span><br><span class="line">	反之也是这样。</span><br><span class="line">	如果执行内存不够用，可以将存储内存释放移动到磁盘上（最多释放不能超过本参数划分的比例），</span><br><span class="line">	但存储内存不能把执行内存抢走。</span><br><span class="line">	</span><br><span class="line">spark.memory.offHeap.enabled	</span><br><span class="line">	是否允许使用堆外内存来进行某些操作。默认false</span><br><span class="line">	</span><br><span class="line">spark.memory.offHeap.size	</span><br><span class="line">	允许使用进行操作的堆外内存的大小，单位bytes 默认0</span><br><span class="line">	</span><br><span class="line">spark.storage.replication.proactive	</span><br><span class="line">	针对失败的executor，主动去cache 有关的RDD中的数据。默false</span><br><span class="line">	</span><br><span class="line">spark.cleaner.periodicGC.interval	</span><br><span class="line">	控制触发gc的频率，默认30min</span><br><span class="line">	</span><br><span class="line">spark.cleaner.referenceTracking	</span><br><span class="line">	是否进行context cleaning，默认true</span><br><span class="line">	</span><br><span class="line">spark.cleaner.referenceTracking.blocking	</span><br><span class="line">	清理线程是否应该阻止清理任务，默认true</span><br><span class="line">	</span><br><span class="line">spark.cleaner.referenceTracking.blocking.shuffle	</span><br><span class="line">	清理线程是否应该阻止shuffle的清理任务，默false</span><br><span class="line">	</span><br><span class="line">spark.cleaner.referenceTracking.cleanCheckpoints	</span><br><span class="line">	清理线程是否应该清理依赖超出范围的检查点文件，默认false</span><br></pre></td></tr></table></figure>

<h2 id="7-Executor-behavior"><a href="#7-Executor-behavior" class="headerlink" title="7. Executor behavior"></a>7. Executor behavior</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.broadcast.blockSize	</span><br><span class="line">	TorrentBroadcastFactory中的每一个block大小，默认4m	</span><br><span class="line">	过大会减少广播时的并行度，过小会导致BlockManager 产生 performance hit.</span><br><span class="line">	（暂时没懂这是干啥用的）</span><br><span class="line">	</span><br><span class="line">spark.executor.cores	</span><br><span class="line">	每个executor的核数，默认yarn下1核，standalone下为所有可用的核。</span><br><span class="line">	</span><br><span class="line">spark.default.parallelism	</span><br><span class="line">	默认RDD的分区数、并行数。	</span><br><span class="line">	像reduceByKey和join等这种需要分布式shuffle的操作中，最大父RDD的分区数；	</span><br><span class="line">	像parallelize之类没有父RDD的操作，则取决于运行环境下得cluster manager：		</span><br><span class="line">	如果为单机模式，本机核数；		</span><br><span class="line">	集群模式为所有executor总核数与2 中最大的一个。</span><br><span class="line">	</span><br><span class="line">spark.executor.heartbeatInterval	</span><br><span class="line">	executor和driver心跳发送间隔，默认10s，</span><br><span class="line">	必须远远小于spark.network.timeoutspark.files.fetchTimeout	</span><br><span class="line">	从driver端执行SparkContext.addFile() 抓取添加的文件的超时时间，</span><br><span class="line">	默认60s</span><br><span class="line">	</span><br><span class="line">spark.files.useFetchCache	</span><br><span class="line">	默认true，如果设为true，拉取文件时会在同一个application中本地持久化，</span><br><span class="line">	被若干个executors共享。这使得当同一个主机下有多个executors时，执行任务效率提高。</span><br><span class="line">	</span><br><span class="line">spark.files.overwrite	</span><br><span class="line">	默认false，是否在执行SparkContext.addFile() 添加文件时，覆盖已有的内容有差异的文件。</span><br><span class="line">	</span><br><span class="line">spark.files.maxPartitionBytes	</span><br><span class="line">	单partition中最多能容纳的文件大小，单位Bytes </span><br><span class="line">	默认134217728 (128 MB)</span><br><span class="line">	</span><br><span class="line">spark.files.openCostInBytes	</span><br><span class="line">	小文件合并阈值，小于该参数就会被合并到一个partition内。	</span><br><span class="line">	默认4194304 (4 MB) 。</span><br><span class="line">	这个参数在将多个文件放入一个partition时被用到，宁可设置的小一些，</span><br><span class="line">	因为在partition操作中，小文件肯定会比大文件快。</span><br><span class="line">	</span><br><span class="line">spark.storage.memoryMapThreshold	</span><br><span class="line">	从磁盘上读文件时，最小单位不能少于该设定值，默认2m，小于或者接近操作系统的每个page的大小。</span><br></pre></td></tr></table></figure>

<h2 id="8-Networking网络"><a href="#8-Networking网络" class="headerlink" title="8. Networking网络"></a>8. Networking网络</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">网络超时或者ip端口的一些配置</span><br></pre></td></tr></table></figure>

<h2 id="9-Scheduling调度"><a href="#9-Scheduling调度" class="headerlink" title="9. Scheduling调度"></a>9. Scheduling调度</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.scheduler.maxRegisteredResourcesWaitingTime	</span><br><span class="line">	在执行前最大等待申请资源的时间，默认30s。</span><br><span class="line">	</span><br><span class="line">spark.scheduler.minRegisteredResourcesRatio	</span><br><span class="line">	实际注册的资源数占预期需要的资源数的比例，默认0.8</span><br><span class="line">	</span><br><span class="line">spark.scheduler.mode</span><br><span class="line">	其他进阶的配置如下：		</span><br><span class="line">	调度模式，默认FIFO 先进队列先调度，可以选择FAIR。</span><br><span class="line">	</span><br><span class="line">spark.scheduler.revive.interval	</span><br><span class="line">	work回复重启的时间间隔，默认1s</span><br><span class="line">	</span><br><span class="line">spark.scheduler.listenerbus.eventqueue.capacity	</span><br><span class="line">	spark事件监听队列容量，默认10000，必须为正值，增加可能会消耗更多内存</span><br><span class="line">	spark.blacklist.enabled***************************************************************	</span><br><span class="line">	是否列入黑名单，默认false。如果设成true，当一个executor失败好几次时，会被列入黑名单，防止后续task		派发到这个executor。可以进一步调节spark.blacklist以下相关的参数：	</span><br><span class="line">	（均为测试参数 Experimental）	</span><br><span class="line">	spark.blacklist.timeout    </span><br><span class="line">	spark.blacklist.task.maxTaskAttemptsPerExecutor    	</span><br><span class="line">	spark.blacklist.task.maxTaskAttemptsPerNode    </span><br><span class="line">	spark.blacklist.stage.maxFailedTasksPerExecutor    </span><br><span class="line">	spark.blacklist.application.maxFailedExecutorsPerNode    </span><br><span class="line">	spark.blacklist.killBlacklistedExecutors</span><br><span class="line">	spark.blacklist.application.fetchFailure.enabled</span><br><span class="line"></span><br><span class="line">spark.speculation************************************************************************	推测，如果有task执行的慢了，就会重新执行它。默认false.	</span><br><span class="line"></span><br><span class="line">	详细相关配置如下：	</span><br><span class="line">	spark.speculation.interval		检查task快慢的频率，推测间隔，默认100ms。	</span><br><span class="line">	spark.speculation.multiplier		推测比均值慢几次算是task执行过慢，默认1.5.	</span><br><span class="line">	spark.speculation.quantile		在某个stage，完成度必须达到该参数的比例，才能被推测，默认0.75</span><br><span class="line">	spark.task.cpus	每个task分配的cpu数，默认1</span><br><span class="line">	spark.task.maxFailures	在放弃这个job前允许的最大失败次数，默认4</span><br><span class="line">	spark.task.reaper.enabled</span><br><span class="line">		(原先有 job失败了但一直显示有task在running，总算找到这个参数了)********	</span><br><span class="line">	赋予spark监控有权限去kill那些失效的task，默认false</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">其他进阶的配置如下：	</span><br><span class="line">	spark.task.reaper.pollingInterval		</span><br><span class="line">	轮询被kill掉的task的时间间隔，如果还在running，就会打warn日志，默认10s。	</span><br><span class="line">	</span><br><span class="line">	spark.task.reaper.threadDump		</span><br><span class="line">	线程回收是是否产生日志，默认true。	</span><br><span class="line">	</span><br><span class="line">	spark.task.reaper.killTimeout		</span><br><span class="line">	当一个被kill的task过了多久还在running，就会把那个executor给kill掉，默认-1。	</span><br><span class="line">	</span><br><span class="line">	spark.stage.maxConsecutiveAttempts		</span><br><span class="line">	在终止前，一个stage连续尝试次数，默认4。</span><br></pre></td></tr></table></figure>

<h2 id="10-Dynamic-Allocation动态分配"><a href="#10-Dynamic-Allocation动态分配" class="headerlink" title="10. Dynamic Allocation动态分配"></a>10. Dynamic Allocation动态分配</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.dynamicAllocation.enabled(这个配置只能动态调整executor的数量)	</span><br><span class="line">	是否开启动态资源配置，根据工作负载来衡量是否应该增加或减少executor，默认false</span><br><span class="line">	</span><br><span class="line">	以下相关参数：	</span><br><span class="line">	spark.dynamicAllocation.minExecutors		</span><br><span class="line">	动态分配最小executor个数，在启动时就申请好的，默认0	</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.maxExecutors		</span><br><span class="line">	动态分配最大executor个数，默认infinity	</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.initialExecutors</span><br><span class="line">	</span><br><span class="line">	动态分配初始executor个数默认值为</span><br><span class="line">	spark.dynamicAllocation.minExecutors</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.executorIdleTimeout	</span><br><span class="line">	当某个executor空闲超过这个设定值，就会被kill，默认60s</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.cachedExecutorIdleTimeout	</span><br><span class="line">	当某个缓存数据的executor空闲时间超过这个设定值，就会被kill，默认infinity</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.schedulerBacklogTimeout	</span><br><span class="line">	任务队列非空，资源不够，申请executor的时间间隔，默认1s</span><br><span class="line">	</span><br><span class="line">	spark.dynamicAllocation.sustainedSchedulerBacklogTimeout	</span><br><span class="line">	同schedulerBacklogTimeout，是申请了新executor之后继续申请的间隔，</span><br><span class="line">	默认=schedulerBacklogTimeout</span><br></pre></td></tr></table></figure>

<h2 id="11-Spark-Streaming"><a href="#11-Spark-Streaming" class="headerlink" title="11. Spark Streaming"></a>11. <strong>Spark Streaming</strong></h2><p><a href="https://blog.csdn.net/zyzzxycj/article/details/82428031">https://blog.csdn.net/zyzzxycj/article/details/82428031</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Spark Streaming</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark笔记-RDD&amp;SQL</title>
    <url>/2019/12/15/Spark/Spark%E7%AC%94%E8%AE%B0-RDD&amp;SQL/</url>
    <content><![CDATA[<h1 id="spark笔记"><a href="#spark笔记" class="headerlink" title="spark笔记"></a>spark笔记</h1><h1 id="1-RDD知识"><a href="#1-RDD知识" class="headerlink" title="1. RDD知识"></a>1. RDD知识</h1><h2 id="1-1-RDD基础"><a href="#1-1-RDD基础" class="headerlink" title="1.1 RDD基础"></a>1.1 RDD基础</h2><p>RDD 可以理解为一个分布式对象集合，本质上是一个只读的分区记录集合。</p>
<p><strong>RDD 具有容错机制，并且只读不能修改，可以执行确定的转换操作创建新的 RDD。</strong></p>
<p>特点：</p>
<ul>
<li>只读，弹性（计算过程中内存不够时它会和磁盘进行数据交换）</li>
<li>分布式（RDD分区的概念），基于内存（可以全部或部分缓存在内存中，在多次计算间重用）</li>
</ul>
<h2 id="1-2-RDD基本操作"><a href="#1-2-RDD基本操作" class="headerlink" title="1.2 RDD基本操作"></a>1.2 RDD基本操作</h2><p>转化（Transformation）操作和行动（Action）操作。</p>
<ul>
<li>Transformation：从一个 RDD 产生一个新的 RDD。</li>
<li>Action：进行实际的计算。</li>
</ul>
<p><strong>RDD和普通HDFS的对比：</strong></p>
<p>RDD 实质上是一种更为通用的迭代并行计算框架，用户可以显示控制计算的中间结果，然后将其自由运用于之后的计算。</p>
<p> 在大数据实际应用开发中存在许多迭代算法，如机器学习、图算法等，和交互式数据挖掘工具。<br>这些应用场景的共同之处是在不同计算阶段之间会重用中间结果，即一个阶段的输出结果会作为下一个阶段的输入。</p>
<p> RDD 正是为了满足这种需求而设计的。</p>
<p> <strong>虽然 MapReduce 具有自动容错、负载平衡和可拓展性的优点，但是其最大的缺点是采用非循环式的数据流模型，使得在迭代计算时要进行大量的磁盘 I&#x2F;O 操作。</strong></p>
<h3 id="1-2-1-RDD的构建"><a href="#1-2-1-RDD的构建" class="headerlink" title="1.2.1 RDD的构建"></a>1.2.1 RDD的构建</h3><ul>
<li><p>内存构建</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val rdd01 = sc.makeRDD(List(1,2,3,4,5,6))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val rdd = sc.parallelize(Array(1,2,2,1),4) </span><br><span class="line">//参数1：待并行化处理的集合；参数2：分区个数</span><br></pre></td></tr></table></figure>
</li>
<li><p>文件系统构建&#x2F;加载外部数据集</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val rdd = sc.textFile(“file:///D:/sparkdata.txt”,1)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//用textFile方法加载</span><br><span class="line">//该方法返回一个RDD，该RDD代表的数据集每个元素都是一个字符串，每个字符串代表输入文件中的一行</span><br><span class="line"></span><br><span class="line">val rddText = sc.textFile(&quot;helloSpark.txt&quot;)</span><br><span class="line">//用wholeTextfiles方法加载</span><br><span class="line">//这个方法读取目录下的所有文本文件，然后返回一个KeyValue对RDD（每一个键值对对应一个文件，key为文件路径，value为文件内容）</span><br><span class="line"></span><br><span class="line">val rddW = sc.wholeTextFile(&quot;path/to/my-data/*.txt&quot;)</span><br><span class="line">//用sequenceFile方法加载//此方法要求从SequenceFile文件中获取键值对数据，返回一个KeyValue对RDD（使用此方法时，还需要提供类型）</span><br><span class="line"></span><br><span class="line">val rdd = sc.sequenceFile[String,String](&quot;some-file&quot;)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-2-2-Transformation（转换操作）"><a href="#1-2-2-Transformation（转换操作）" class="headerlink" title="1.2.2 Transformation（转换操作）"></a>1.2.2 Transformation（转换操作）</h3><p>RDD 的转换操作是返回新的 RDD 的操作。<strong>转换出来的 RDD 是惰性求值的，只有在Action操作中用到这些 RDD 时才会被计算</strong>。</p>
<p><em>许多转换操作都是针对各个元素的，也就是说，这些<strong>转换操作每次只会操作 RDD 中的一个元素</strong>，不过并不是所有的转换操作都是这样的。</em></p>
<p> <strong>表 1 RDD转换操作（rdd1&#x3D;{1, 2, 3, 3}，rdd2&#x3D;{3,4,5})</strong></p>
<table>
<thead>
<tr>
<th>函数名</th>
<th>作用</th>
<th>示例</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>map()</td>
<td>将函数应用于 RDD 的每个元素，返回值是新的 RDD</td>
<td>rdd1.map(x&#x3D;&gt;x+l)</td>
<td>{2,3,4,4}</td>
</tr>
<tr>
<td>flatMap()</td>
<td>将函数应用于 RDD 的每个元素，将元素数据进行拆分，变成迭代器，返回值是新的 RDD</td>
<td>rdd1.flatMap(x&#x3D;&gt;x.to(3)) x.to(3) 从x打印到3</td>
<td>{1,2,3,2,3,3,3}</td>
</tr>
<tr>
<td>filter()</td>
<td>函数会过滤掉不符合条件的元素，返回值是新的 RDD</td>
<td>rdd1.filter(x&#x3D;&gt;x!&#x3D;1)</td>
<td>{2,3,3}</td>
</tr>
<tr>
<td>distinct()</td>
<td>将 RDD 里的元素进行去重操作 内部实现相当于分区内，以及全量分别做了去重</td>
<td>rdd1.distinct()</td>
<td>(1,2,3)</td>
</tr>
<tr>
<td>union()</td>
<td>生成包含两个 RDD 所有元素的新的 RDD</td>
<td>rdd1.union(rdd2)</td>
<td>{1,2,3,3,3,4,5}</td>
</tr>
<tr>
<td>intersection()</td>
<td>求出两个 RDD 的共同元素</td>
<td>rdd1.intersection(rdd2)</td>
<td>{3}</td>
</tr>
<tr>
<td>subtract()</td>
<td>将原 RDD 里和参数 RDD 里相同的元素去掉 （差集）</td>
<td>rdd1.subtract(rdd2)</td>
<td>{1,2}</td>
</tr>
<tr>
<td>cartesian()</td>
<td>求两个 RDD 的笛卡儿积</td>
<td>rdd1.cartesian(rdd2)</td>
<td>{(1,3),(1,4)……(3,5)}</td>
</tr>
</tbody></table>
<h3 id="1-2-3-Action（行动操作）"><a href="#1-2-3-Action（行动操作）" class="headerlink" title="1.2.3 Action（行动操作）"></a>1.2.3 Action（行动操作）</h3><p>行动操作用于执行计算并按指定的方式输出结果。</p>
<p><strong>行动操作接受 RDD，但是返回非 RDD，即输出一个值或者结果。在 RDD 执行过程中，真正的计算发生在行动操作</strong></p>
<p> <strong>表 2 RDD 行动操作（rdd&#x3D;{1,2,3,3}）</strong></p>
<table>
<thead>
<tr>
<th>函数名</th>
<th>作用</th>
<th>示例</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>collect()</td>
<td>返回 RDD 的所有元素</td>
<td>rdd.collect()</td>
<td>{1,2,3,3}</td>
</tr>
<tr>
<td>count()</td>
<td>RDD 里元素的个数</td>
<td>rdd.count()</td>
<td>4</td>
</tr>
<tr>
<td>countByValue()</td>
<td>各元素在 RDD 中的出现次数</td>
<td>rdd.countByValue()</td>
<td>{(1,1),(2,1),(3,2})}</td>
</tr>
<tr>
<td>take(num)</td>
<td>从 RDD 中返回 num 个元素</td>
<td>rdd.take(2)</td>
<td>{1,2}</td>
</tr>
<tr>
<td>top(num)</td>
<td>从 RDD 中，按照默认（降序）或者指定的排序返回最前面的 num 个元素</td>
<td>rdd.top(2)</td>
<td>{3,3}</td>
</tr>
<tr>
<td>reduce()</td>
<td>并行整合所有 RDD 数据，如求和操作</td>
<td>rdd.reduce((x,y)&#x3D;&gt;x+y)</td>
<td>9</td>
</tr>
<tr>
<td>fold(zero)(func)</td>
<td>和 reduce() 功能一样，但需要提供初始值</td>
<td>rdd.fold(0)((x,y)&#x3D;&gt;x+y)</td>
<td>9</td>
</tr>
<tr>
<td>foreach(func)</td>
<td>对 RDD 的每个元素都使用特定函数</td>
<td>rdd1.foreach(x&#x3D;&gt;printIn(x))</td>
<td>打印每一个元素</td>
</tr>
<tr>
<td>saveAsTextFile(path)</td>
<td>将数据集的元素，以文本的形式保存到文件系统中</td>
<td>rdd1.saveAsTextFile(file:&#x2F;&#x2F;home&#x2F;test)</td>
<td></td>
</tr>
<tr>
<td>saveAsSequenceFile(path)</td>
<td>将数据集的元素，以顺序文件格式保存到指 定的目录下</td>
<td>saveAsSequenceFile(hdfs:&#x2F;&#x2F;home&#x2F;test)</td>
<td></td>
</tr>
</tbody></table>
<p><strong>aggregateByKey</strong></p>
<p>aggregateByKey(1)(2,3)</p>
<p>参数1：为初始值</p>
<p>参数2：操作1</p>
<p>参数3：操作2</p>
<p>对RDD中相同的Key值进行聚合操作，在聚合过程中使用了一个中立的初始值。返回值的类型不需要和RDD中value的类型一致。</p>
<p>首先根据分区，相同key的值，基于参数1，操作1，进行合并。</p>
<p>然后各分区结果，相同的key，基于操作2进行合并。</p>
<p>最后结果是key，key对应的结果。</p>
<p><strong>aggregate() 函数 : agregate(zero)(seqOp,combOp)</strong></p>
<p>aggregate() 函数的返回类型不需要和 RDD 中的元素类型一致，所以<strong>在使用时，需要提供所期待的返回类型的初始值</strong>，然后通过一个函数把 RDD 中的元素累加起来放入累加器。</p>
<hr>
<ul>
<li>首先使用 <strong>seqOp</strong> 操作聚合各分区中的元素</li>
<li>然后再使用 <strong>combOp</strong> 操作把所有分区的聚合结果再次聚合</li>
<li>两个操作的初始值都是 zero。</li>
</ul>
<p><strong>seqOp 的操作是遍历分区中的所有元素 T，第一个 T 跟 zero 做操作，结果再作为与第二个 T 做操作的 zero，直到遍历完整个分区。</strong></p>
<p><strong>combOp 操作是把各分区聚合的结果再聚合。aggregate() 函数会返回一个跟 RDD 不同类型的值。</strong></p>
<p>因此，需要 seqOp 操作来把分区中的元素 T 合并成一个 U，以及 combOp 操作把所有 U 聚合。</p>
<p>举个例子：（一进二出，进的值是value, acc._1和acc._2指的是初始元组（0，0）中的第一，二个元素）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val rdd = List (1,2,3,4) </span><br><span class="line">val input = sc.parallelize(rdd) </span><br><span class="line"></span><br><span class="line">val result=input.aggregate((0,0))((acc,value)=&gt;(acc._1+value,acc._2+1),(acc1,acc2)=&gt;(acc1._1+acc2._1,acc1._2+acc2._2)) </span><br><span class="line"></span><br><span class="line">--(resultInt,Int) = (10,4)</span><br><span class="line"></span><br><span class="line">val avg = result._1 / result._2</span><br><span class="line">avg:Int = 2.5</span><br></pre></td></tr></table></figure>

<p>程序的详细过程大概如下。</p>
<p>定义一个初始值 (0,0)，即所期待的返回类型的初始值。代码 (acc,value) &#x3D;&gt; (acc._1 + value,acc._2 + 1) 中的 value 是函数定义里面的 T，这里是 List 里面的元素。acc._1 + value，acc._2 + 1 的过程如下。</p>
<p>(0+1,0+1)→(1+2,1+1)→(3+3,2+1)→(6+4,3+1)，结果为(10,4)。</p>
<p>实际的 Spark 执行过程是分布式计算，可能会把 List 分成多个分区，假如是两个：p1(1,2) 和 p2(3,4)。</p>
<p>经过计算，各分区的结果分别为 (3,2) 和 (7,2)。这样，执行 (acc1,acc2) &#x3D;&gt; (acc1._1 + acc2._2,acc1._2 + acc2._2) 的结果就是 (3+7,2+2)，即 (10,4)，然后可计算平均值。<br><strong>acc._1 : 第一个参数 acc._2 ：第二个参数</strong></p>
<h2 id="1-3-Spark-Stage的划分"><a href="#1-3-Spark-Stage的划分" class="headerlink" title="1.3 Spark Stage的划分"></a>1.3 Spark Stage的划分</h2><p>RDD之间有一系列的依赖关系，依赖关系又分为窄依赖和宽依赖。</p>
<p>Spark中的Stage其实就是一组并行的任务，任务是一个个的task 。</p>
<ul>
<li><p><strong>窄依赖</strong></p>
<p>父RDD和子RDD partition之间的关系是一对一的。</p>
<p><strong>不会有shuffle的产生。父RDD</strong>的<strong>一个分区</strong>去到<strong>子RDD的一个分区</strong>。</p>
</li>
<li><p><strong>宽依赖</strong></p>
<p>父RDD与子RDD partition之间的关系是一对多。<strong>会有shuffle的产生。</strong></p>
<p><strong>父RDD的一个分区的数据去到子RDD的不同分区里面。</strong></p>
</li>
<li><p>总结：</p>
<p>窄依赖：可以理解为独生子女</p>
<p>宽依赖：可以理解为超生</p>
</li>
</ul>
<h3 id="1-3-1-Stage的概念"><a href="#1-3-1-Stage的概念" class="headerlink" title="1.3.1 Stage的概念"></a>1.3.1 Stage的概念</h3><p>Spark任务会根据<strong>RDD之间的依赖关系，形成一个DAG有向无环图</strong>。</p>
<p>DAG会提交给DAGScheduler，DAGScheduler会把DAG划分相互依赖的多个stage，<strong>划分stage的依据就是RDD之间的宽窄依赖</strong>。</p>
<p><strong>遇到宽依赖就划分stage</strong>,每个stage包含一个或多个task任务。</p>
<p>将一个stage中的tasks以taskSet的形式提交给<strong>TaskScheduler运行</strong>。 即<strong>stage是由一组并行的task组成。</strong></p>
<h3 id="1-3-2-shuffle-和-stage"><a href="#1-3-2-shuffle-和-stage" class="headerlink" title="1.3.2 shuffle 和 stage"></a>1.3.2 shuffle 和 stage</h3><p><strong>shuffle 是划分 DAG 中 stage 的标识,同时影响 Spark 执行速度的关键步骤</strong>.</p>
<p>窄依赖跟宽依赖的区别是<strong>是否发生 shuffle(洗牌) 操作</strong>.</p>
<p><strong>宽依赖会发生 shuffle 操作.</strong></p>
<p><strong>shuffle 操作是 spark 中最耗时的操作,应尽量避免不必要的 shuffle</strong>.</p>
<ul>
<li>宽依赖主要有两个过程: shuffle write 和 shuffle fetch. 类似 Hadoop 的 Map 和 Reduce 阶段.shuffle write 将 ShuffleMapTask 任务产生的中间结果缓存到内存中, shuffle fetch 获得 ShuffleMapTask 缓存的中间结果进行 ShuffleReduceTask 计算,<strong>这个过程容易造成OutOfMemory</strong>.</li>
</ul>
<p><strong>shuffle 操作的时候可以用 combiner 压缩数据,减少 IO 的消耗</strong></p>
<h2 id="1-4-SparkContext、SparkConf和SparkSession"><a href="#1-4-SparkContext、SparkConf和SparkSession" class="headerlink" title="1.4 SparkContext、SparkConf和SparkSession"></a>1.4 SparkContext、SparkConf和SparkSession</h2><p>Application：用户编写的Spark应用程序，Driver 即运行上述 Application 的 main() 函数并且创建 SparkContext。<br><strong>SparkContext</strong>：整个应用的上下文，控制应用的生命周期。</p>
<p>RDD：不可变的数据集合，可由 SparkContext 创建，是 Spark 的基本计算单元。</p>
<p><strong>SparkSession</strong>是Spark2.0新引入的。</p>
<p>SparkSession内部封装了SparkConf、SparkContext、SQLContext、HiveContext。</p>
<p>因此SparkSession可以用他们所有的api</p>
<h1 id="2-Spark-SQL"><a href="#2-Spark-SQL" class="headerlink" title="2. Spark SQL"></a>2. Spark SQL</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h2><p>Spark SQL是Spark用来<strong>处理结构化数据</strong>的一个模块，</p>
<p>它提供了2个编程抽象：<strong>DataFrame</strong>和<strong>DataSet</strong>，并且作为<strong>分布式SQL查询引擎</strong>的作用。</p>
<h3 id="2-1-1-特点"><a href="#2-1-1-特点" class="headerlink" title="2.1.1 特点"></a>2.1.1 特点</h3><ul>
<li>易整合</li>
<li>统一的数据访问方式</li>
<li>兼容Hive</li>
<li>标准的数据连接</li>
</ul>
<h3 id="2-1-2-DataFrame"><a href="#2-1-2-DataFrame" class="headerlink" title="2.1.2 DataFrame"></a>2.1.2 DataFrame</h3><p>DataFrame也是一个分布式数据容器。</p>
<p>但DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。</p>
<p>同时，与Hive类似，<strong>DataFrame也支持嵌套数据类型</strong>（struct、array和map）。</p>
<p>DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。</p>
<p> 性能上比RDD要高，主要原因：</p>
<p> 优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。</p>
<h3 id="2-1-3-DataSet"><a href="#2-1-3-DataSet" class="headerlink" title="2.1.3 DataSet"></a>2.1.3 DataSet</h3><p>DataSet是</p>
<p> 1)Dataframe API的一个扩展，是Spark最新的数据抽象。</p>
<p> 2)用户友好的API风格，既具有类型安全检查也具有Dataframe的查询优化特性。</p>
<p> 3)Dataset支持编解码器，当需要访问非堆上的数据时可以避免反序列化整个对象，提高了效率。</p>
<p> 4)样例类被用来在Dataset中定义数据的结构信息，<strong>样例类中每个属性的名称直接映射到DataSet中的字段名称</strong>。</p>
<p> 5)Dataframe是Dataset的特列，DataFrame&#x3D;Dataset[Row] ，所以可以通过as方法将Dataframe转换为Dataset。Row是一个类型，跟Car、Person这些的类型一样，所有的表结构信息我都用Row来表示。</p>
<p> 6)DataSet是强类型的。比如可以有Dataset[Car]，Dataset[Person].</p>
<p> 7)DataFrame只是知道字段，但是不知道字段的类型，所以在执行这些操作的时候是没办法在编译的时候检查是否类型失败的，比如你可以对一个String进行减法操作，在执行的时候才报错，而DataSet不仅仅知道字段，而且知道字段类型，所以有更严格的错误检查。就跟JSON对象和类对象之间的类比。</p>
<h2 id="2-2-SparkSQL编程"><a href="#2-2-SparkSQL编程" class="headerlink" title="2.2. SparkSQL编程"></a>2.2. SparkSQL编程</h2><h3 id="2-2-1-SparkSession"><a href="#2-2-1-SparkSession" class="headerlink" title="2.2.1 SparkSession"></a>2.2.1 SparkSession</h3><p>在<strong>老spark的版本</strong>中，SparkSQL提供两种SQL查询起始点：一个叫<strong>SQLContext</strong>，用于Spark自己提供的SQL查询；一个叫<strong>HiveContext</strong>，用于连接Hive的查询。</p>
<p><strong>SparkSession</strong>是Spark最新的SQL查询起始点，实质上<strong>是SQLContext和HiveContext的组合</strong>，所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。<strong>SparkSession内部封装了sparkContext</strong>，所以计算实际上是由sparkContext完成的。</p>
<h3 id="2-2-2-DataFrame（DataSet基本一致）"><a href="#2-2-2-DataFrame（DataSet基本一致）" class="headerlink" title="2.2.2 DataFrame（DataSet基本一致）"></a>2.2.2 DataFrame（DataSet基本一致）</h3><h4 id="2-2-2-1-创建"><a href="#2-2-2-1-创建" class="headerlink" title="2.2.2.1 创建"></a>2.2.2.1 创建</h4><p>在Spark SQL中SparkSession是创建DataFrame和执行SQL的入口，</p>
<p>创建DataFrame有三种方式：</p>
<ul>
<li>通过Spark的数据源进行创建</li>
<li>从一个存在的RDD进行转换</li>
<li>从Hive Table进行查询返回</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 从Spark数据源进行创建</span><br><span class="line">1)查看Spark数据源进行创建的文件格式	</span><br><span class="line">	spark.read.	</span><br><span class="line">	csv   format   jdbc   json   load   option   options   orc	parquet   </span><br><span class="line">	schema   table   text   textFile</span><br><span class="line">	</span><br><span class="line">2)读取json文件创建DataFrame	</span><br><span class="line">	val df=spark.read.json(&quot;/opt/module/spark/.../people.json&quot;)</span><br><span class="line">	</span><br><span class="line">3）展示结果	df.show</span><br><span class="line"></span><br><span class="line">2. 从RDD进行转换</span><br><span class="line">注意：如果需要RDD与DF或者DS之间操作，那么都需要引入 import spark.implicits._  </span><br><span class="line">【spark不是包名，而是sparkSession对象的名称】</span><br><span class="line"></span><br><span class="line">import spark.implicits._</span><br><span class="line">val peopleRDD = sc.textFile(&quot;examples/src/main/resources/people.txt&quot;)</span><br><span class="line"></span><br><span class="line">1)手动转换</span><br><span class="line">peopleRDD.map&#123;x=&gt;    </span><br><span class="line">	val para = x.split(&quot;,&quot;);			  				 		、、、、、</span><br><span class="line">	(para(0),para(1).trim.toInt)	</span><br><span class="line">	&#125;.toDF(&quot;name&quot;,&quot;age&quot;)</span><br><span class="line">	</span><br><span class="line">2）通过反射确定（需要用到样例类）	</span><br><span class="line">	（1）创建一个样例类	</span><br><span class="line">		case class People(name:String, age:Int)	</span><br><span class="line">	（2）根据样例类将RDD转换为DataFrame	</span><br><span class="line">		peopleRDD.map&#123; x =&gt; 	</span><br><span class="line">			val para = x.split(&quot;,&quot;);	</span><br><span class="line">			People(para(0),para(1).trim.toInt)	</span><br><span class="line">		&#125;.toDF</span><br><span class="line">		</span><br><span class="line">3）通过编程的方式（--了解--）	</span><br><span class="line">	（1）导入所需的类型	</span><br><span class="line">		import org.apache.spark.sql.types._	</span><br><span class="line">	（2）创建Schema	</span><br><span class="line">		val structType: StructType = </span><br><span class="line">		StructType(StructField(&quot;name&quot;, StringType) </span><br><span class="line">			:: StructField(&quot;age&quot;, IntegerType) :: Nil)	</span><br><span class="line">			</span><br><span class="line">	（3）导入所需的类型	</span><br><span class="line">		import org.apache.spark.sql.Row	</span><br><span class="line">		</span><br><span class="line">	（4）根据给定的类型创建二元组RDD	</span><br><span class="line">		val data = peopleRDD.map&#123; x =&gt; 	</span><br><span class="line">			val para = x.split(&quot;,&quot;);	</span><br><span class="line">			Row(para(0),para(1).trim.toInt)</span><br><span class="line">		&#125;	</span><br><span class="line">		</span><br><span class="line">	（5）根据数据及给定的schema创建DataFrame	</span><br><span class="line">		val dataFrame = spark.createDataFrame(data, structType)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 从Hive Table进行查询返回</span><br></pre></td></tr></table></figure>

<h4 id="2-2-2-2-SQL风格语法"><a href="#2-2-2-2-SQL风格语法" class="headerlink" title="2.2.2.2 SQL风格语法"></a>2.2.2.2 SQL风格语法</h4><ol>
<li><p>创建DF</p>
<p>spark.read.json(“”)</p>
</li>
<li><p>对DataFrame创建一个临时表</p>
<p>df.createOrReplaceTempView(“people”)</p>
</li>
<li><p>通过SQL语句实现查询全表</p>
<p>val sqlDF &#x3D; spark.sql(“SELECT * FROM people”)</p>
</li>
<li><p>结果展示</p>
<p>sqlDF.show</p>
</li>
</ol>
<p>注意：临时表是Session范围内的，Session退出后，表就失效了。</p>
<p>如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，</p>
<p>如：global_temp.people</p>
<ol>
<li><p>对于DataFrame创建一个全局表</p>
<p>df.createGlobalTempView(“people”)</p>
</li>
<li><p>通过SQL语句实现查询全表</p>
<p>spark.sql(“SELECT * FROM global_temp.people”).show()</p>
<p>spark.newSession().sql(“SELECT * FROM global_temp.people”).show()</p>
</li>
</ol>
<h3 id="2-2-3-DataFrame与DataSet的互操作"><a href="#2-2-3-DataFrame与DataSet的互操作" class="headerlink" title="2.2.3 DataFrame与DataSet的互操作"></a>2.2.3 DataFrame与DataSet的互操作</h3><p>在使用一些特殊的操作时，一定要加上 import spark.implicits._</p>
<p>不然toDF、toDS无法使用。</p>
<ol>
<li><p>DataFrame转换为DataSe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）创建一个DateFrame</span><br><span class="line">val df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)</span><br><span class="line"></span><br><span class="line">2）创建一个样例类</span><br><span class="line">case class Person(name: String, age: Long)</span><br><span class="line"></span><br><span class="line">3）将DateFrame转化为DataSet</span><br><span class="line">df.as[Person]</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataSet转换为DataFrame</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）创建一个样例类</span><br><span class="line">case class Person(name: String, age: Long)</span><br><span class="line"></span><br><span class="line">2）创建DataSetval ds = Seq(Person(&quot;Andy&quot;, 32)).toDS()</span><br><span class="line"></span><br><span class="line">3）将DataSet转化为DataFrame</span><br><span class="line">val df = ds.toDF</span><br><span class="line"></span><br><span class="line">4)展示df.show</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-4-RDD、DataFrame、DataSet"><a href="#2-2-4-RDD、DataFrame、DataSet" class="headerlink" title="2.2.4 RDD、DataFrame、DataSet"></a>2.2.4 RDD、DataFrame、DataSet</h3><p>在SparkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。</p>
<p>他们和RDD有什么区别呢？首先从版本的产生上来看：</p>
<p> RDD (Spark1.0) —&gt; Dataframe(Spark1.3) —&gt;Dataset(Spark1.6)</p>
<p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。</p>
<p>在后期的Spark版本中，DataSet会逐步取代RDD和DataFrame成为唯一的API接口。</p>
<h1 id="3-Spark调参"><a href="#3-Spark调参" class="headerlink" title="3. Spark调参"></a>3. Spark调参</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">export LANG=en_US.UTF-8</span><br><span class="line"></span><br><span class="line">export HADOOP_CONF_DIR=/etc/hadoop/conf</span><br><span class="line"></span><br><span class="line">date=$1</span><br><span class="line"></span><br><span class="line">WORK_HOME=/home/hypersuser/insight/insight-1.0.0/jobs</span><br><span class="line"></span><br><span class="line">TASK_CLASSPATH=</span><br><span class="line">for i in $&#123;WORK_HOME&#125;/taskLib/*.jar ; do   </span><br><span class="line">	if [ ! -n &quot;$TASK_CLASSPATH&quot; ]; then      </span><br><span class="line">		TASK_CLASSPATH=$i   </span><br><span class="line">	else      </span><br><span class="line">		TASK_CLASSPATH=$TASK_CLASSPATH,$i</span><br><span class="line">	fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">num_executors=16</span><br><span class="line">executor_memory=16G</span><br><span class="line">driver_memory=2G</span><br><span class="line">executor_cores=1</span><br><span class="line">partition_number=256</span><br><span class="line">job_queue=`cat /home/hypersuser/insight/insight-1.0.0/jobs/conf/queue/daily_queue`</span><br><span class="line"></span><br><span class="line">spark2-submit --driver-class-path $&#123;WORK_HOME&#125;/conf:$&#123;WORK_HOME&#125;/lib/* \</span><br><span class="line">--jars &quot;$TASK_CLASSPATH&quot;,$WORK_HOME/conf/hbase-site.xml \</span><br><span class="line">--conf spark.port.maxRetries=100 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=true \</span><br><span class="line">--master yarn --deploy-mode client \</span><br><span class="line">--queue $&#123;job_queue&#125; \</span><br><span class="line">--num-executors $num_executors </span><br><span class="line">--executor-memory $executor_memory \</span><br><span class="line">--driver-memory $driver_memory </span><br><span class="line">--executor-cores $executor_cores \</span><br><span class="line">--class com.hypers.insight.tools.oreal.offlineplus.CdpLabelKIEOfflinePlus \</span><br><span class="line">$&#123;WORK_HOME&#125;/jobsLib/orealOffline/insight-orealoffline-1.0.0.jar $date</span><br></pre></td></tr></table></figure>

<h2 id="3-1-关于执行脚本参数"><a href="#3-1-关于执行脚本参数" class="headerlink" title="3.1 关于执行脚本参数"></a>3.1 关于执行脚本参数</h2><ul>
<li><p>涉及运行的参数</p>
<p>num_executors, executor_memory, driver_memory, executor_cores, partition_number</p>
<p>num_executors 启动spark任务分配多少个Executor</p>
<p>executor_memory 每个Executor的内存大小（spark.dynamicAllocation.enabled&#x3D;true可以自适应？）</p>
<p>driver_memory Driver的内存大小，调度器的内存，可适量，一般没必要太大。</p>
<p>executor_cores 每个Executor的内core的数量。</p>
<p>partition_number 分区数量，大了以后可以提高并发数</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot从入门到精通</title>
    <url>/2019/12/10/Spring/SpringBoot%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/</url>
    <content><![CDATA[<h1 id="SpringBoot-2-X"><a href="#SpringBoot-2-X" class="headerlink" title="SpringBoot 2.X"></a>SpringBoot 2.X</h1><h2 id="1-第一部分"><a href="#1-第一部分" class="headerlink" title="1. 第一部分"></a>1. 第一部分</h2><h3 id="1-SpringBoot2-x依赖环境和版本新特性说明"><a href="#1-SpringBoot2-x依赖环境和版本新特性说明" class="headerlink" title="1. SpringBoot2.x依赖环境和版本新特性说明"></a>1. SpringBoot2.x依赖环境和版本新特性说明</h3><p>1、依赖版本jdk8以上, Springboot2.x用JDK8, 因为底层是 Spring framework5<br>2、安装maven最新版本，maven3.2以上版本，下载地址 ：<a href="https://maven.apache.org/download.cgi">https://maven.apache.org/download.cgi</a><br>3、建议IDEA<br>4、新特性<br>5、翻译工具：<a href="https://translate.google.cn/">https://translate.google.cn/</a><br>6、springbootGitHub地址：<a href="https://github.com/spring-projects/spring-boot">https://github.com/spring-projects/spring-boot</a><br>7、springboot官方文档：<a href="https://spring.io/guides/gs/spring-boot/">https://spring.io/guides/gs/spring-boot/</a></p>
<h3 id="2-快速创建SpringBoot2-x应用之手工创建web应用"><a href="#2-快速创建SpringBoot2-x应用之手工创建web应用" class="headerlink" title="2. 快速创建SpringBoot2.x应用之手工创建web应用"></a>2. 快速创建SpringBoot2.x应用之手工创建web应用</h3><p>文档：<a href="https://spring.io/guides/gs/rest-service/">https://spring.io/guides/gs/rest-service/</a></p>
<ol>
<li><p>使用idea 创建maven工程</p>
</li>
<li><p>使用构建工具自动生成项目基本架构：<a href="http://start.spring.io/">http://start.spring.io/</a></p>
</li>
</ol>
<h2 id="2-第二部分-SpringBoot接口Http协议开发实战"><a href="#2-第二部分-SpringBoot接口Http协议开发实战" class="headerlink" title="2. 第二部分-SpringBoot接口Http协议开发实战"></a>2. 第二部分-SpringBoot接口Http协议开发实战</h2><h3 id="1-SpringBoot2-xHTTP请求配置讲解"><a href="#1-SpringBoot2-xHTTP请求配置讲解" class="headerlink" title="1. SpringBoot2.xHTTP请求配置讲解"></a>1. SpringBoot2.xHTTP请求配置讲解</h3><ol>
<li>@RestController and @RequestMapping 是springMVC的注解，不是springboot特有的	</li>
<li>@RestController &#x3D; @Controller+@ResponseBody	</li>
<li>@SpringBootApplication &#x3D; @Configuration+@EnableAutoConfiguration+@ComponentScan<br>    localhost:8080</li>
</ol>
<h3 id="2-PostMan接口调试工具"><a href="#2-PostMan接口调试工具" class="headerlink" title="2. PostMan接口调试工具"></a>2. PostMan接口调试工具</h3><p>具体使用自行google</p>
<h3 id="3-SpringBoot基础HTTP接口请求实战"><a href="#3-SpringBoot基础HTTP接口请求实战" class="headerlink" title="3. SpringBoot基础HTTP接口请求实战"></a>3. SpringBoot基础HTTP接口请求实战</h3><h4 id="1-GET请求"><a href="#1-GET请求" class="headerlink" title="1. GET请求"></a>1. GET请求</h4><pre><code>单一参数@RequestMapping(path = &quot;/&#123;id&#125;&quot;, method = RequestMethod.GET)
1) public String getUser(@PathVariable String id ) &#123;&#125;

2）@RequestMapping(path = &quot;/&#123;depid&#125;/&#123;userid&#125;&quot;, method = RequestMethod.GET) 可以同时指定多个提交方法
getUser(@PathVariable(&quot;depid&quot;) String departmentID,@PathVariable(&quot;userid&quot;) String userid)

3）一个顶俩
@GetMapping = @RequestMapping(method = RequestMethod.GET)
@PostMapping = @RequestMapping(method = RequestMethod.POST)
@PutMapping = @RequestMapping(method = RequestMethod.PUT)
@DeleteMapping = @RequestMapping(method = RequestMethod.DELETE)

4）@RequestParam(value = &quot;name&quot;, required = true)
    可以设置默认值，比如分页 

4)@RequestBody 请求体映射实体类
    需要指定http头为 content-type为application/json charset=utf-8

5）@RequestHeader 请求头，比如鉴权
    @RequestHeader(&quot;access_token&quot;) String accessToken

6）HttpServletRequest request自动注入获取参数
</code></pre>
<h4 id="2-POST-PUT-DELETE请求"><a href="#2-POST-PUT-DELETE请求" class="headerlink" title="2. POST,PUT,DELETE请求"></a>2. POST,PUT,DELETE请求</h4><p>略</p>
<h4 id="3-常用json框架介绍和Jackson返回结果处理"><a href="#3-常用json框架介绍和Jackson返回结果处理" class="headerlink" title="3. 常用json框架介绍和Jackson返回结果处理"></a>3. 常用json框架介绍和Jackson返回结果处理</h4><p>1、常用框架 阿里 fastjson,谷歌gson等</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">JavaBean序列化为Json，性能：Jackson &gt; FastJson &gt; Gson &gt; Json-lib 同个结构</span><br><span class="line">Jackson、FastJson、Gson类库各有优点，各有自己的专长</span><br><span class="line">空间换时间，时间换空间</span><br></pre></td></tr></table></figure>

<p>2、jackson处理相关自动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">指定字段不返回：@JsonIgnore</span><br><span class="line">指定日期格式：@JsonFormat(pattern=&quot;yyyy-MM-dd hh:mm:ss&quot;,locale=&quot;zh&quot;,timezone=&quot;GMT+8&quot;)</span><br><span class="line">空字段不返回：@JsonInclude(Include.NON_NUll)</span><br><span class="line">指定别名：@JsonProperty</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-SpringBoot2-x目录文件结构讲解"><a href="#4-SpringBoot2-x目录文件结构讲解" class="headerlink" title="4. SpringBoot2.x目录文件结构讲解"></a>4. SpringBoot2.x目录文件结构讲解</h4><p> 1、目录讲解</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">src/main/java：存放代码</span><br><span class="line">	 src/main/resources</span><br><span class="line">		static: 存放静态文件，比如 css、js、image, （访问方式 http://localhost:8080/js/main.js）</span><br><span class="line">		templates:存放静态页面jsp,html,tpl</span><br><span class="line">		config:存放配置文件,application.properties</span><br><span class="line">		resources:</span><br></pre></td></tr></table></figure>

<p> 2、引入依赖 Thymeleaf</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">	   &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line">注意：如果不引人这个依赖包，html文件应该放在默认加载文件夹里面，比如resources、比如resources/static、比如resources/public这个几个文件夹，才可以访问</span><br></pre></td></tr></table></figure>

<p> 3、同个文件的加载顺序,静态资源文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Spring Boot 默认会挨个从META/resources &gt; resources &gt; static &gt; public  里面找是否存在相应的资源，如果有则直接返回。</span><br></pre></td></tr></table></figure>

<p> 4、默认配置	<br>    1）官网地址：<a href="https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-static-content">https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-static-content</a></p>
<pre><code>2）spring.resources.static-locations = classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ 
</code></pre>
<p> 5、静态资源文件存储在CDN</p>
<h4 id="4-文件上传实战"><a href="#4-文件上传实战" class="headerlink" title="4. 文件上传实战"></a>4. 文件上传实战</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1）静态页面直接访问：localhost:8080/index.html</span><br><span class="line">	注意点：</span><br><span class="line">		如果想要直接访问html页面，则需要把html放在springboot默认加载的文件夹下面</span><br><span class="line">2）MultipartFile 对象的transferTo方法，用于文件保存（效率和操作比原先用FileOutStream方便和高效）</span><br><span class="line"></span><br><span class="line">访问路径 http://localhost:8080/images/20220531000000.jpeg</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-jar包方式运行web项目的文件上传和访问处理"><a href="#5-jar包方式运行web项目的文件上传和访问处理" class="headerlink" title="5. jar包方式运行web项目的文件上传和访问处理"></a>5. jar包方式运行web项目的文件上传和访问处理</h4><p>1、文件大小配置，启动类里面配置(springboot main class)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Bean  </span><br><span class="line">public MultipartConfigElement multipartConfigElement() &#123;  </span><br><span class="line">	MultipartConfigFactory factory = new MultipartConfigFactory();  </span><br><span class="line">	//单个文件最大  </span><br><span class="line">	factory.setMaxFileSize(&quot;10240KB&quot;); //KB,MB  </span><br><span class="line">	/// 设置总上传数据总大小  </span><br><span class="line">	factory.setMaxRequestSize(&quot;1024000KB&quot;);  </span><br><span class="line">	return factory.createMultipartConfig();  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>2、打包成jar包，需要增加maven依赖</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">	&lt;plugins&gt;</span><br><span class="line">		&lt;plugin&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">		&lt;/plugin&gt;</span><br><span class="line">	&lt;/plugins&gt;</span><br><span class="line">&lt;/build&gt;</span><br><span class="line">如果没加相关依赖，执行maven打包，运行后会报错:no main manifest attribute, in XXX.jar</span><br><span class="line"></span><br><span class="line">GUI：反编译工具，作用就是用于把class文件转换成java文件</span><br></pre></td></tr></table></figure>

<p>3、文件上传和访问需要指定磁盘路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">application.properties中增加下面配置</span><br><span class="line">	1) web.images-path=/Users/jack/Desktop</span><br><span class="line">	2) spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/,classpath:/test/,file:$&#123;web.upload-path&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4、文件服务器：fastdfs，阿里云oss，nginx搭建一个简单的文件服务器</p>
<h2 id="3-SpringBoot热部署devtool和配置文件自动注入实战"><a href="#3-SpringBoot热部署devtool和配置文件自动注入实战" class="headerlink" title="3. SpringBoot热部署devtool和配置文件自动注入实战"></a>3. SpringBoot热部署devtool和配置文件自动注入实战</h2><h3 id="1-使用Dev-tool热部署"><a href="#1-使用Dev-tool热部署" class="headerlink" title="1. 使用Dev-tool热部署"></a>1. 使用Dev-tool热部署</h3><p>什么是热部署，使用springboot结合dev-tool工具，快速加载启动应用</p>
<p>官方地址：<a href="https://docs.spring.io/spring-boot/docs/2.7.0/reference/reference/htmlsingle/#using-boot-devtools">https://docs.spring.io/spring-boot/docs/2.7.0/reference/reference/htmlsingle/#using-boot-devtools</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">核心依赖包：</span><br><span class="line">	&lt;dependency&gt;  </span><br><span class="line">		 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  </span><br><span class="line">		 &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;  </span><br><span class="line">		 &lt;optional&gt;true&lt;/optional&gt;  </span><br><span class="line">	 &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">添加依赖后，在ide里面重启应用，后续修改后马上可以生效</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">不被热部署的文件</span><br><span class="line">	1、/META-INF/maven, /META-INF/resources, /resources, /static, /public, or /templates</span><br><span class="line">	2、指定文件不进行热部署 spring.devtools.restart.exclude=static/**,public/**</span><br><span class="line">	3、手工触发重启 spring.devtools.restart.trigger-file=trigger.txt</span><br><span class="line">		改代码不重启，通过一个文本去控制</span><br><span class="line"></span><br><span class="line">https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#using-boot-devtools-restart-exclude</span><br><span class="line"></span><br><span class="line">注意点：生产环境不要开启这个功能，如果用java -jar启动，springBoot是不会进行热部署的</span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot2-x配置文件讲解"><a href="#2-SpringBoot2-x配置文件讲解" class="headerlink" title="2. SpringBoot2.x配置文件讲解"></a>2. SpringBoot2.x配置文件讲解</h3><h4 id="1-xml、properties、json、yaml"><a href="#1-xml、properties、json、yaml" class="headerlink" title="1. xml、properties、json、yaml"></a>1. xml、properties、json、yaml</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、常见的配置文件 xx.yml, xx.properties，</span><br><span class="line">	1)YAML（Yet Another Markup Language）</span><br><span class="line">		写 YAML 要比写 XML 快得多(无需关注标签或引号)</span><br><span class="line">		使用空格 Space 缩进表示分层，不同层次之间的缩进可以使用不同的空格数目</span><br><span class="line">		注意：key后面的冒号，后面一定要跟一个空格,树状结构</span><br><span class="line">	application.properties示例</span><br><span class="line">		server.port=8090  </span><br><span class="line">		server.session-timeout=30  </span><br><span class="line">		server.tomcat.max-threads=0  </span><br><span class="line">		server.tomcat.uri-encoding=UTF-8 </span><br><span class="line"></span><br><span class="line">	application.yml示例</span><br><span class="line">		server:  </span><br><span class="line">			port: 8090  </span><br><span class="line">			session-timeout: 30  </span><br><span class="line">			tomcat.max-threads: 0  </span><br><span class="line">			tomcat.uri-encoding: UTF-8 </span><br><span class="line"></span><br><span class="line">2、参考：https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#common-application-properties</span><br><span class="line">如果需要修改，直接复制对应的配置文件，加到application.properties里面</span><br></pre></td></tr></table></figure>

<h3 id="3-SpringBoot注解把配置文件自动映射到属性和实体类实战"><a href="#3-SpringBoot注解把配置文件自动映射到属性和实体类实战" class="headerlink" title="3. SpringBoot注解把配置文件自动映射到属性和实体类实战"></a>3. SpringBoot注解把配置文件自动映射到属性和实体类实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、配置文件加载</span><br><span class="line">	方式一</span><br><span class="line">		1、Controller上面配置</span><br><span class="line">		   @PropertySource(&#123;&quot;classpath:resource.properties&quot;&#125;)</span><br><span class="line">		2、增加属性</span><br><span class="line">			 @Value(&quot;$&#123;test.name&#125;&quot;)</span><br><span class="line">			 private String name;</span><br><span class="line"></span><br><span class="line">	方式二：实体类配置文件</span><br><span class="line">	步骤：</span><br><span class="line">		1、添加 @Component 注解；</span><br><span class="line">		2、使用 @PropertySource(&#123;&quot;classpath:resource.properties&quot;&#125;) 注解 指定配置文件位置；</span><br><span class="line">		3、使用 @ConfigurationProperties 注解，设置相关属性；</span><br><span class="line"></span><br><span class="line">		4、必须 通过注入IOC对象Resource 进来 ， 才能在类中使用获取的配置文件值。</span><br><span class="line">			@Autowired</span><br><span class="line">			private ServerSettings serverSettings;</span><br><span class="line">			</span><br><span class="line">			例子1：</span><br><span class="line">				@Configuration</span><br><span class="line">				@ConfigurationProperties</span><br><span class="line">				@PropertySource(value=&quot;classpath:resource.properties&quot;)</span><br><span class="line">				public class ServerConstant &#123;</span><br><span class="line">					@Value(&quot;$&#123;test.name&#125;&quot;)</span><br><span class="line">					private String name;</span><br><span class="line"></span><br><span class="line">			例子2：此例子配置名直接和字段名匹配</span><br><span class="line">				@Configuration</span><br><span class="line">				@ConfigurationProperties(prefix=&quot;test&quot;)</span><br><span class="line">				@PropertySource(value=&quot;classpath:resource.properties&quot;)</span><br><span class="line">				public class ServerConstant &#123;</span><br><span class="line">					private String name;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		常见问题：</span><br><span class="line">			1、配置文件注入失败，Could not resolve placeholder</span><br><span class="line">				解决：根据springboot启动流程，会有自动扫描包没有扫描到相关注解, </span><br><span class="line">				默认Spring框架实现会从声明@ComponentScan所在的类的package进行扫描，来自动注入，</span><br><span class="line">				因此启动类最好放在根路径下面，或者指定扫描包范围</span><br><span class="line">				spring-boot扫描启动类对应的目录和子目录</span><br><span class="line">			2、注入bean的方式，属性名称和配置文件里面的key一一对应，就用加@Value 这个注解</span><br><span class="line">				如果不一样，就要加@value(&quot;$&#123;XXX&#125;&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="4-Springboot2-0单元测试进阶实战和自定义异常处理"><a href="#4-Springboot2-0单元测试进阶实战和自定义异常处理" class="headerlink" title="4. Springboot2.0单元测试进阶实战和自定义异常处理"></a>4. Springboot2.0单元测试进阶实战和自定义异常处理</h2><h3 id="1-SpringBootTest单元测试实战"><a href="#1-SpringBootTest单元测试实战" class="headerlink" title="1. @SpringBootTest单元测试实战"></a>1. @SpringBootTest单元测试实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、引入相关依赖</span><br><span class="line">	 &lt;!--springboot程序测试依赖，如果是自动创建项目默认添加--&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">			&lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、使用</span><br><span class="line">	@RunWith(SpringRunner.class)  //底层用junit  SpringJUnit4ClassRunner  类注解</span><br><span class="line">	@SpringBootTest(classes=&#123;XdclassApplication.class&#125;)//启动整个springboot工程</span><br><span class="line">	public class SpringBootTests &#123; &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3、SpringBoot测试进阶高级篇之MockMvc讲解</span><br><span class="line">	简介:讲解MockMvc类的使用和模拟Http请求实战</span><br><span class="line"></span><br><span class="line">		1、增加类注解 @AutoConfigureMockMvc</span><br><span class="line">					@SpringBootTest(classes=&#123;XdclassApplication.class&#125;)</span><br><span class="line">		2、 成员变量</span><br><span class="line">			@Autowired</span><br><span class="line">			private MockMvc mockMvc;</span><br><span class="line">		3、相关API</span><br><span class="line">			perform：执行一个RequestBuilder请求</span><br><span class="line">			andExpect：添加ResultMatcher-&gt;MockMvcResultMatchers验证规则</span><br><span class="line">			andReturn：最后返回相应的MvcResult-&gt;Response</span><br><span class="line">			例子：</span><br><span class="line">			MvcResult mvcResult =  mockMvc.perform(MockMvcRequestBuilders.get(&quot;/test/home&quot;) ).andExpect(MockMvcResultMatchers.status().isOk() ).andReturn();</span><br><span class="line">			int status = mvcResult.getResponse().getStatus();</span><br><span class="line">			System.out.println(status);</span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot2-x个性化启动banner设置和debug日志"><a href="#2-SpringBoot2-x个性化启动banner设置和debug日志" class="headerlink" title="2. SpringBoot2.x个性化启动banner设置和debug日志"></a>2. SpringBoot2.x个性化启动banner设置和debug日志</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、启动获取更多日志信息 java -jar xxx.jar --debug</span><br><span class="line"></span><br><span class="line">2、修改启动的banner信息</span><br><span class="line">	1）在类路径下增加一个banner.txt，里面是启动要输出的信息</span><br><span class="line">	2）在applicatoin.properties增加banner文件的路径地址 </span><br><span class="line">		spring.banner.location=banner.txt</span><br><span class="line"></span><br><span class="line">	3）官网地址 https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#features.spring-application.banner</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-SpringBoot2-x配置全局异常实战"><a href="#3-SpringBoot2-x配置全局异常实战" class="headerlink" title="3. SpringBoot2.x配置全局异常实战"></a>3. SpringBoot2.x配置全局异常实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、默认异常测试  int i = 1/0，不友好</span><br><span class="line"></span><br><span class="line">2、异常注解介绍</span><br><span class="line">	@ControllerAdvice 如果是返回json数据 则用 RestControllerAdvice,就可以不加 @ResponseBody</span><br><span class="line">	</span><br><span class="line">	//捕获全局异常,处理所有不可知的异常</span><br><span class="line">	@ExceptionHandler(value=Exception.class)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//@ControllerAdvice</span><br><span class="line">@RestControllerAdvice</span><br><span class="line">public class CustomExtHandler &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(CustomExtHandler.class);</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">	//捕获全局异常,处理所有不可知的异常</span><br><span class="line">	//@ResponseBody</span><br><span class="line">	@ExceptionHandler(value=Exception.class)</span><br><span class="line">    Object handleException(Exception e,HttpServletRequest request)&#123;</span><br><span class="line">		logger.error(&quot;url &#123;&#125;, msg &#123;&#125;&quot;,request.getRequestURL(), e.getMessage());</span><br><span class="line">		Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">	        map.put(&quot;code&quot;, 100);</span><br><span class="line">	        map.put(&quot;msg&quot;, e.getMessage());</span><br><span class="line">	        map.put(&quot;url&quot;, request.getRequestURL());</span><br><span class="line">	        return map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-SpringBoot2-x配置全局异常返回自定义页面"><a href="#4-SpringBoot2-x配置全局异常返回自定义页面" class="headerlink" title="4. SpringBoot2.x配置全局异常返回自定义页面"></a>4. SpringBoot2.x配置全局异常返回自定义页面</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、返回自定义异常界面，需要引入thymeleaf依赖</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">	   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">	   &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、resource目录下新建templates,并新建error.html   CustomExtHandler类使用以下方式</span><br><span class="line">	@ExceptionHandler(value=MyException.class)</span><br><span class="line">    Object handleMyException(MyException e,HttpServletRequest request)&#123;</span><br><span class="line">        ModelAndView modelAndView = new ModelAndView();</span><br><span class="line">        modelAndView.setViewName(&quot;error.html&quot;);</span><br><span class="line">        modelAndView.addObject(&quot;msg&quot;, e.getMessage());</span><br><span class="line">        return modelAndView;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#web.servlet.spring-mvc.error-handling</span><br></pre></td></tr></table></figure>



<h2 id="5-SpringBoot部署war项目到tomcat"><a href="#5-SpringBoot部署war项目到tomcat" class="headerlink" title="5. SpringBoot部署war项目到tomcat"></a>5. SpringBoot部署war项目到tomcat</h2><h3 id="1-SpringBoot启动方式讲解和部署war项目到tomcat"><a href="#1-SpringBoot启动方式讲解和部署war项目到tomcat" class="headerlink" title="1. SpringBoot启动方式讲解和部署war项目到tomcat"></a>1. SpringBoot启动方式讲解和部署war项目到tomcat</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、ide启动</span><br><span class="line">2、jar包方式启动</span><br><span class="line">			maven插件:</span><br><span class="line">			&lt;build&gt;</span><br><span class="line">			&lt;plugins&gt;</span><br><span class="line">				&lt;plugin&gt;</span><br><span class="line">					&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">					&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">				&lt;/plugin&gt;</span><br><span class="line">			&lt;/plugins&gt;</span><br><span class="line">			&lt;/build&gt;</span><br><span class="line">			</span><br><span class="line">			如果没有加，则执行jar包 ，报错如下</span><br><span class="line">				java -jar spring-boot-demo-0.0.1-SNAPSHOT.jar</span><br><span class="line">				no main manifest attribute, in spring-boot-demo-0.0.1-SNAPSHOT.jar</span><br><span class="line">			如果有安装maven 用 mvn spring-boot:run</span><br><span class="line">	项目结构</span><br><span class="line">		example.jar</span><br><span class="line">				 |</span><br><span class="line">				 +-META-INF</span><br><span class="line">				 |  +-MANIFEST.MF</span><br><span class="line">				 +-org</span><br><span class="line">				 |  +-springframework</span><br><span class="line">				 |     +-boot</span><br><span class="line">				 |        +-loader</span><br><span class="line">				 |           +-&lt;spring boot loader classes&gt;</span><br><span class="line">				 +-BOOT-INF</span><br><span class="line">					+-classes</span><br><span class="line">					|  +-mycompany</span><br><span class="line">					|     +-project</span><br><span class="line">					|        +-YourClasses.class</span><br><span class="line">					+-lib</span><br><span class="line">					   +-dependency1.jar</span><br><span class="line">					   +-dependency2.jar</span><br><span class="line"></span><br><span class="line">官方文档：https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#appendix.executable-jar.nested-jars.jar-structure</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3、war包方式启动</span><br><span class="line">	1)在pom.xml中将打包形式 jar 修改为war  &lt;packaging&gt;war&lt;/packaging&gt;</span><br><span class="line"></span><br><span class="line">	构建项目名称 &lt;finalName&gt;xdclass_springboot&lt;/finalName&gt;</span><br><span class="line"></span><br><span class="line">	2)tocmat下载 https://tomcat.apache.org/download-90.cgi</span><br><span class="line">	</span><br><span class="line">	3)修改启动类</span><br><span class="line">		public class XdclassApplication extends SpringBootServletInitializer &#123;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123;</span><br><span class="line">				return application.sources(XdclassApplication.class);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			public static void main(String[] args) throws Exception &#123;</span><br><span class="line">				SpringApplication.run(XdclassApplication.class, args);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	4)打包项目，启动tomcat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">4、启动容器介绍(Tomcat vs. Jetty vs. Undertow) 和 第三方测试数据讲解</span><br><span class="line"></span><br><span class="line">使用Jmter测试工具测试性能，QPS,TPS，RT</span><br><span class="line"></span><br><span class="line">https://examples.javacodegeeks.com/enterprise-java/spring/tomcat-vs-jetty-vs-undertow-comparison-of-spring-boot-embedded-servlet-containers/</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="6-SpringBoot拦截器实战和-Servlet3-0自定义Filter、Listener"><a href="#6-SpringBoot拦截器实战和-Servlet3-0自定义Filter、Listener" class="headerlink" title="6. SpringBoot拦截器实战和 Servlet3.0自定义Filter、Listener"></a>6. SpringBoot拦截器实战和 Servlet3.0自定义Filter、Listener</h2><h3 id="1-深入SpringBoot2-x过滤器Filter和使用Servlet3-0配置自定义Filter实战-核心知识"><a href="#1-深入SpringBoot2-x过滤器Filter和使用Servlet3-0配置自定义Filter实战-核心知识" class="headerlink" title="1. 深入SpringBoot2.x过滤器Filter和使用Servlet3.0配置自定义Filter实战(核心知识)"></a>1. 深入SpringBoot2.x过滤器Filter和使用Servlet3.0配置自定义Filter实战(核心知识)</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">filter简单理解：人---&gt;检票员（filter）---&gt; 景点</span><br><span class="line"></span><br><span class="line">1、SpringBoot启动默认加载的Filter </span><br><span class="line">	characterEncodingFilter</span><br><span class="line">	hiddenHttpMethodFilter</span><br><span class="line">	httpPutFormContentFilter</span><br><span class="line">	requestContextFilter</span><br><span class="line">		</span><br><span class="line">2、Filter优先级</span><br><span class="line"></span><br><span class="line">	Ordered.HIGHEST_PRECEDENCE</span><br><span class="line">	Ordered.LOWEST_PRECEDENCE</span><br><span class="line"></span><br><span class="line">	低位值意味着更高的优先级 Higher values are interpreted as lower priority</span><br><span class="line">	自定义Filter，避免和默认的Filter优先级一样，不然会冲突</span><br><span class="line"></span><br><span class="line">	注册Filter的bean FilterRegistrationBean</span><br><span class="line">	同模块里面有相关默认Filter</span><br><span class="line">		web-&gt;servlet-&gt;filter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3、自定义Filter</span><br><span class="line">	1）使用Servlet3.0的注解进行配置</span><br><span class="line">	2）启动类里面增加 @ServletComponentScan，进行扫描</span><br><span class="line">	3）新建一个Filter类，implements Filter，并实现对应的接口</span><br><span class="line">	4) @WebFilter 标记一个类为filter，被spring进行扫描 </span><br><span class="line">		urlPatterns：拦截规则，支持正则</span><br><span class="line"></span><br><span class="line">	6）控制chain.doFilter的方法的调用，来实现是否放行</span><br><span class="line">	   不放行，web应用resp.sendRedirect(&quot;/index.html&quot;);</span><br><span class="line">		场景：权限控制、用户登录(非前端后端分离场景)等</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">官网地址：https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#boot-features-embedded-container-servlets-filters-listeners</span><br></pre></td></tr></table></figure>



<h3 id="2-Servlet3-0的注解自定义原生Servlet实战"><a href="#2-Servlet3-0的注解自定义原生Servlet实战" class="headerlink" title="2. Servlet3.0的注解自定义原生Servlet实战"></a>2. Servlet3.0的注解自定义原生Servlet实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、自定义原生Servlet</span><br><span class="line"></span><br><span class="line">	@WebServlet(name = &quot;userServlet&quot;,urlPatterns = &quot;/test/customs&quot;)</span><br><span class="line">	public class UserServlet extends HttpServlet&#123;</span><br><span class="line"></span><br><span class="line">		 @Override</span><br><span class="line">		 public void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;</span><br><span class="line">			 resp.getWriter().print(&quot;custom sevlet&quot;);</span><br><span class="line">			 resp.getWriter().flush();</span><br><span class="line">			 resp.getWriter().close();</span><br><span class="line">		 &#125;</span><br><span class="line"></span><br><span class="line">		 @Override</span><br><span class="line">		 protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;</span><br><span class="line">			 this.doGet(req, resp);</span><br><span class="line">		 &#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-Servlet3-0的注解自定义原生Listener监听器实战"><a href="#3-Servlet3-0的注解自定义原生Listener监听器实战" class="headerlink" title="3. Servlet3.0的注解自定义原生Listener监听器实战"></a>3. Servlet3.0的注解自定义原生Listener监听器实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、自定义Listener(常用的监听器 servletContextListener、httpSessionListener、servletRequestListener)</span><br><span class="line">			@WebListener</span><br><span class="line">			public class RequestListener implements ServletRequestListener &#123;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void requestDestroyed(ServletRequestEvent sre) &#123;</span><br><span class="line">				// TODO Auto-generated method stub</span><br><span class="line">				System.out.println(&quot;======requestDestroyed========&quot;);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void requestInitialized(ServletRequestEvent sre) &#123;</span><br><span class="line">				System.out.println(&quot;======requestInitialized========&quot;);</span><br><span class="line">				</span><br><span class="line">			&#125;</span><br></pre></td></tr></table></figure>



<h3 id="4-SpringBoot2-X自定义拦截器实战及新旧配置对比"><a href="#4-SpringBoot2-X自定义拦截器实战及新旧配置对比" class="headerlink" title="4. SpringBoot2.X自定义拦截器实战及新旧配置对比"></a>4. SpringBoot2.X自定义拦截器实战及新旧配置对比</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、@Configuration</span><br><span class="line">	继承WebMvcConfigurationAdapter(SpringBoot2.X之前旧版本)</span><br><span class="line"></span><br><span class="line">	SpringBoot2.X 新版本配置拦截器 implements WebMvcConfigurer</span><br><span class="line"></span><br><span class="line">2、自定义拦截器 HandlerInterceptor</span><br><span class="line">	preHandle：调用Controller某个方法之前</span><br><span class="line">	postHandle：Controller之后调用，视图渲染之前，如果控制器Controller出现了异常，则不会执行此方法</span><br><span class="line">	afterCompletion：不管有没有异常，这个afterCompletion都会被调用，用于资源清理</span><br><span class="line"></span><br><span class="line">3、按照注册顺序进行拦截，先注册，再被拦截</span><br><span class="line"></span><br><span class="line">拦截器不生效常见问题：</span><br><span class="line">	1）是否有加@Configuration</span><br><span class="line">	2）拦截路径是否有问题 **  和 * </span><br><span class="line">	3）拦截器最后路径一定要 “/**”， 如果是目录的话则是 /*/</span><br><span class="line"></span><br><span class="line">Filter</span><br><span class="line">	是基于函数回调 doFilter()，而Interceptor则是基于AOP思想</span><br><span class="line">	Filter在只在Servlet前后起作用，而Interceptor够深入到方法前后、异常抛出前后等</span><br><span class="line"></span><br><span class="line">	依赖于Servlet容器即web应用中，而Interceptor不依赖于Servlet容器所以可以运行在多种环境。</span><br><span class="line"></span><br><span class="line">	在接口调用的生命周期里，Interceptor可以被多次调用，而Filter只能在容器初始化时调用一次。</span><br><span class="line">	</span><br><span class="line">	Filter和Interceptor的执行顺序</span><br><span class="line">	</span><br><span class="line">	过滤前-&gt;拦截前-&gt;action执行-&gt;拦截后-&gt;过滤后</span><br></pre></td></tr></table></figure>



<h2 id="7-SpringBoot常用Starter介绍和整合模板引擎Freemaker、thymeleaf"><a href="#7-SpringBoot常用Starter介绍和整合模板引擎Freemaker、thymeleaf" class="headerlink" title="7. SpringBoot常用Starter介绍和整合模板引擎Freemaker、thymeleaf"></a>7. SpringBoot常用Starter介绍和整合模板引擎Freemaker、thymeleaf</h2><h3 id="1-SpringBoot-Starter"><a href="#1-SpringBoot-Starter" class="headerlink" title="1. SpringBoot Starter"></a>1. SpringBoot Starter</h3><p>官网地址：<a href="https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#using-boot-starter">https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#using-boot-starter</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、starter主要简化依赖用的</span><br><span class="line">	spring-boot-starter-web	-&gt;里面包含多种依赖</span><br><span class="line"></span><br><span class="line">2、几个常用的starter</span><br><span class="line">	spring-boot-starter-activemq</span><br><span class="line">	spring-boot-starter-aop</span><br><span class="line">	spring-boot-starter-data-redis</span><br><span class="line">	spring-boot-starter-freemarker</span><br><span class="line">	spring-boot-starter-thymeleaf</span><br><span class="line">	spring-boot-starter-webflux</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot2-x常见模板引擎讲解和官方推荐使用"><a href="#2-SpringBoot2-x常见模板引擎讲解和官方推荐使用" class="headerlink" title="2. SpringBoot2.x常见模板引擎讲解和官方推荐使用"></a>2. SpringBoot2.x常见模板引擎讲解和官方推荐使用</h3><h4 id="1-JSP（后端渲染，消耗性能）"><a href="#1-JSP（后端渲染，消耗性能）" class="headerlink" title="1. JSP（后端渲染，消耗性能）"></a>1. JSP（后端渲染，消耗性能）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Java Server Pages 动态网页技术,由应用服务器中的JSP引擎来编译和执行，再将生成的整个页面返回给客户端</span><br><span class="line"></span><br><span class="line">可以写java代码</span><br><span class="line"></span><br><span class="line">持表达式语言（el、jstl）</span><br><span class="line"></span><br><span class="line">内建函数</span><br><span class="line"></span><br><span class="line">JSP-&gt;Servlet(占用JVM内存)permSize</span><br><span class="line"></span><br><span class="line">javaweb官方推荐</span><br><span class="line">springboot不推荐 </span><br><span class="line">https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#boot-features-jsp-limitations</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="2-Freemarker"><a href="#2-Freemarker" class="headerlink" title="2. Freemarker"></a>2. Freemarker</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FreeMarker Template Language（FTL）  文件一般保存为 xxx.ftl</span><br><span class="line"></span><br><span class="line">严格依赖MVC模式，不依赖Servlet容器（不占用JVM内存）</span><br><span class="line"></span><br><span class="line">内建函数</span><br></pre></td></tr></table></figure>



<h4 id="3-Thymeleaf-主推"><a href="#3-Thymeleaf-主推" class="headerlink" title="3. Thymeleaf (主推)"></a>3. Thymeleaf (主推)</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">轻量级的模板引擎（负责逻辑业务的不推荐，解析DOM或者XML会占用多的内存）</span><br><span class="line">可以直接在浏览器中打开且正确显示模板页面</span><br><span class="line"></span><br><span class="line">直接是html结尾，直接编辑</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-SpringBoot2-x整合模板引擎freemarker实战"><a href="#3-SpringBoot2-x整合模板引擎freemarker实战" class="headerlink" title="3. SpringBoot2.x整合模板引擎freemarker实战"></a>3. SpringBoot2.x整合模板引擎freemarker实战</h3><h4 id="1-Freemarker相关maven依赖"><a href="#1-Freemarker相关maven依赖" class="headerlink" title="1. Freemarker相关maven依赖"></a>1. Freemarker相关maven依赖</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- 引入freemarker模板引擎的依赖 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-Freemarker基础配置"><a href="#2-Freemarker基础配置" class="headerlink" title="2. Freemarker基础配置"></a>2. Freemarker基础配置</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 是否开启thymeleaf缓存,本地为false，生产建议为true</span><br><span class="line">spring.freemarker.cache=false</span><br><span class="line"></span><br><span class="line">spring.freemarker.charset=UTF-8</span><br><span class="line">spring.freemarker.allow-request-override=false</span><br><span class="line">spring.freemarker.check-template-location=true</span><br><span class="line"></span><br><span class="line">#类型</span><br><span class="line">spring.freemarker.content-type=text/html</span><br><span class="line"></span><br><span class="line">spring.freemarker.expose-request-attributes=true</span><br><span class="line">spring.freemarker.expose-session-attributes=true</span><br><span class="line"></span><br><span class="line">#文件后缀</span><br><span class="line">spring.freemarker.suffix=.ftl</span><br><span class="line">#路径</span><br><span class="line">spring.freemarker.template-loader-path=classpath:/templates/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-建立文件夹"><a href="#3-建立文件夹" class="headerlink" title="3. 建立文件夹"></a>3. 建立文件夹</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1)src/main/resources/templates/fm/user/</span><br><span class="line"></span><br><span class="line">2)建立一个index.ftl</span><br><span class="line"></span><br><span class="line">3)user文件夹下面建立一个user.html</span><br></pre></td></tr></table></figure>

<h3 id="4-SpringBoot2-x整合模板引擎thymeleaf实战"><a href="#4-SpringBoot2-x整合模板引擎thymeleaf实战" class="headerlink" title="4. SpringBoot2.x整合模板引擎thymeleaf实战"></a>4. SpringBoot2.x整合模板引擎thymeleaf实战</h3><p>官网地址：<a href="https://www.thymeleaf.org/doc/articles/thymeleaf3migration.html">https://www.thymeleaf.org/doc/articles/thymeleaf3migration.html</a></p>
<h4 id="1-thymeleaf相关maven依赖"><a href="#1-thymeleaf相关maven依赖" class="headerlink" title="1. thymeleaf相关maven依赖"></a>1. thymeleaf相关maven依赖</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-thymeleaf基础配置"><a href="#2-thymeleaf基础配置" class="headerlink" title="2. thymeleaf基础配置"></a>2. thymeleaf基础配置</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#开发时关闭缓存,不然没法看到实时页面</span><br><span class="line">spring.thymeleaf.cache=false</span><br><span class="line">spring.thymeleaf.mode=HTML5</span><br><span class="line"></span><br><span class="line">#前缀</span><br><span class="line">spring.thymeleaf.prefix=classpath:/templates/</span><br><span class="line"></span><br><span class="line">#编码</span><br><span class="line">spring.thymeleaf.encoding=UTF-8</span><br><span class="line"></span><br><span class="line">#类型</span><br><span class="line">spring.thymeleaf.content-type=text/html</span><br><span class="line"></span><br><span class="line">#名称的后缀</span><br><span class="line">spring.thymeleaf.suffix=.html</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-建立文件夹-1"><a href="#3-建立文件夹-1" class="headerlink" title="3. 建立文件夹"></a>3. 建立文件夹</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1)src/main/resources/templates/tl/</span><br><span class="line"></span><br><span class="line">2)建立一个index.html</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-简单测试代码编写和访问"><a href="#4-简单测试代码编写和访问" class="headerlink" title="4. 简单测试代码编写和访问"></a>4. 简单测试代码编写和访问</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意：$表达式只能写在th标签内部</span><br><span class="line">快速入门：https://www.thymeleaf.org/doc/articles/standarddialect5minutes.html</span><br></pre></td></tr></table></figure>



<h2 id="8-数据库操作之整合Mybaties和事务"><a href="#8-数据库操作之整合Mybaties和事务" class="headerlink" title="8. 数据库操作之整合Mybaties和事务"></a>8. 数据库操作之整合Mybaties和事务</h2><h3 id="1-SpringBoot2-x持久化数据方式"><a href="#1-SpringBoot2-x持久化数据方式" class="headerlink" title="1. SpringBoot2.x持久化数据方式"></a>1. SpringBoot2.x持久化数据方式</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、原始java访问数据库</span><br><span class="line">	开发流程麻烦</span><br><span class="line">	1、注册驱动/加载驱动</span><br><span class="line">		Class.forName(&quot;com.mysql.jdbc.Driver&quot;)</span><br><span class="line">	2、建立连接</span><br><span class="line">		Connection con = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/dbname&quot;,&quot;root&quot;,&quot;root&quot;);</span><br><span class="line">	3、创建Statement</span><br><span class="line"></span><br><span class="line">	4、执行SQL语句</span><br><span class="line"></span><br><span class="line">	5、处理结果集</span><br><span class="line"></span><br><span class="line">	6、关闭连接，释放资源</span><br><span class="line"></span><br><span class="line">2、apache dbutils框架</span><br><span class="line">	比上一步简单点</span><br><span class="line">	官网:https://commons.apache.org/proper/commons-dbutils/</span><br><span class="line">3、jpa框架</span><br><span class="line">	spring-data-jpa</span><br><span class="line">	jpa在复杂查询的时候性能不是很好</span><br><span class="line"></span><br><span class="line">4、Hiberante   解释：ORM：对象关系映射Object Relational Mapping</span><br><span class="line">	企业大都喜欢使用hibernate</span><br><span class="line"></span><br><span class="line">5、Mybatis框架   </span><br><span class="line">	互联网行业通常使用mybatis</span><br><span class="line">	不提供对象和关系模型的直接映射,半ORM</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot2-x整合Mybatis3-x注解实战"><a href="#2-SpringBoot2-x整合Mybatis3-x注解实战" class="headerlink" title="2. SpringBoot2.x整合Mybatis3.x注解实战"></a>2. SpringBoot2.x整合Mybatis3.x注解实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、使用starter, maven仓库地址：http://mvnrepository.com/artifact/org.mybatis.spring.boot/mybatis-spring-boot-starter</span><br><span class="line"></span><br><span class="line">2、加入依赖(可以用 http://start.spring.io/ 下载)</span><br><span class="line">			</span><br><span class="line">	&lt;!-- 引入starter--&gt;</span><br><span class="line">			&lt;dependency&gt;</span><br><span class="line">				&lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">				&lt;version&gt;1.3.2&lt;/version&gt;</span><br><span class="line">				&lt;scope&gt;runtime&lt;/scope&gt;			    </span><br><span class="line">			&lt;/dependency&gt;</span><br><span class="line">			</span><br><span class="line">	&lt;!-- MySQL的JDBC驱动包	--&gt;	</span><br><span class="line">			&lt;dependency&gt;</span><br><span class="line">				&lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">				&lt;scope&gt;runtime&lt;/scope&gt;</span><br><span class="line">			&lt;/dependency&gt; </span><br><span class="line">	&lt;!-- 引入第三方数据源 --&gt;		</span><br><span class="line">			&lt;dependency&gt;</span><br><span class="line">				&lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;druid&lt;/artifactId&gt;</span><br><span class="line">				&lt;version&gt;1.1.6&lt;/version&gt;</span><br><span class="line">			&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">3、加入配置文件</span><br><span class="line">	#mybatis.type-aliases-package=net.xdclass.base_project.domain</span><br><span class="line">	#可以自动识别</span><br><span class="line">	#spring.datasource.driver-class-name =com.mysql.jdbc.Driver</span><br><span class="line"></span><br><span class="line">	spring.datasource.url=jdbc:mysql://localhost:3306/movie?useUnicode=true&amp;characterEncoding=utf-8</span><br><span class="line">	spring.datasource.username =root</span><br><span class="line">	spring.datasource.password =password</span><br><span class="line">	#如果不使用默认的数据源 （com.zaxxer.hikari.HikariDataSource）</span><br><span class="line">	spring.datasource.type =com.alibaba.druid.pool.DruidDataSource</span><br><span class="line"></span><br><span class="line">加载配置，注入到sqlSessionFactory等都是springBoot帮我们完成</span><br><span class="line"></span><br><span class="line">4、启动类增加mapper扫描</span><br><span class="line">	@MapperScan(&quot;net.xdclass.base_project.mapper&quot;)</span><br><span class="line"></span><br><span class="line">	 技巧：保存对象，获取数据库自增id </span><br><span class="line">	 @Options(useGeneratedKeys=true, keyProperty=&quot;id&quot;, keyColumn=&quot;id&quot;)</span><br><span class="line"></span><br><span class="line">4、开发mapper</span><br><span class="line">	参考语法 http://www.mybatis.org/mybatis-3/zh/java-api.html</span><br><span class="line"></span><br><span class="line">5、sql脚本</span><br><span class="line">	CREATE TABLE `user` (</span><br><span class="line">	  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">	  `name` varchar(128) DEFAULT NULL COMMENT &#x27;名称&#x27;,</span><br><span class="line">	  `phone` varchar(16) DEFAULT NULL COMMENT &#x27;用户手机号&#x27;,</span><br><span class="line">	  `create_time` datetime DEFAULT NULL COMMENT &#x27;创建时间&#x27;,</span><br><span class="line">	  `age` int(4) DEFAULT NULL COMMENT &#x27;年龄&#x27;,</span><br><span class="line">	  PRIMARY KEY (`id`)</span><br><span class="line">	) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=utf8;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">相关资料：</span><br><span class="line">http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/#Configuration</span><br><span class="line"></span><br><span class="line">https://github.com/mybatis/spring-boot-starter/tree/master/mybatis-spring-boot-samples</span><br><span class="line"></span><br><span class="line">整合问题集合：</span><br><span class="line">	https://my.oschina.net/hxflar1314520/blog/1800035</span><br><span class="line">	https://blog.csdn.net/tingxuetage/article/details/80179772</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-SpringBoot2-x整合Mybatis3-x增删改查实操和控制台打印SQL语句"><a href="#3-SpringBoot2-x整合Mybatis3-x增删改查实操和控制台打印SQL语句" class="headerlink" title="3. SpringBoot2.x整合Mybatis3.x增删改查实操和控制台打印SQL语句"></a>3. SpringBoot2.x整合Mybatis3.x增删改查实操和控制台打印SQL语句</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、控制台打印sql语句		</span><br><span class="line">	#增加打印sql语句，一般用于本地开发测试</span><br><span class="line">	mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl</span><br><span class="line"></span><br><span class="line">2、增加mapper代码		</span><br><span class="line">	@Select(&quot;SELECT * FROM user&quot;)</span><br><span class="line">	@Results(&#123;</span><br><span class="line">		@Result(column = &quot;create_time&quot;,property = &quot;createTime&quot;)  //javaType = java.util.Date.class        </span><br><span class="line">	&#125;)</span><br><span class="line">	List&lt;User&gt; getAll();</span><br><span class="line">  </span><br><span class="line">	@Select(&quot;SELECT * FROM user WHERE id = #&#123;id&#125;&quot;)</span><br><span class="line">	@Results(&#123;</span><br><span class="line">		 @Result(column = &quot;create_time&quot;,property = &quot;createTime&quot;)</span><br><span class="line">	&#125;)</span><br><span class="line">	User findById(Long id);</span><br><span class="line"></span><br><span class="line">	@Update(&quot;UPDATE user SET name=#&#123;name&#125; WHERE id =#&#123;id&#125;&quot;)</span><br><span class="line">	void update(User user);</span><br><span class="line"></span><br><span class="line">	@Delete(&quot;DELETE FROM user WHERE id =#&#123;userId&#125;&quot;)</span><br><span class="line">	void delete(Long userId);</span><br><span class="line"> </span><br><span class="line"> 3、增加API</span><br><span class="line"></span><br><span class="line">	@GetMapping(&quot;find_all&quot;)</span><br><span class="line">	public Object findAll()&#123;</span><br><span class="line">	   return JsonData.buildSuccess(userMapper.getAll());</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	@GetMapping(&quot;find_by_Id&quot;)</span><br><span class="line">	public Object findById(long id)&#123;</span><br><span class="line">	   return JsonData.buildSuccess(userMapper.findById(id));</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	@GetMapping(&quot;del_by_id&quot;)</span><br><span class="line">	public Object delById(long id)&#123;</span><br><span class="line">	userMapper.delete(id);</span><br><span class="line">	   return JsonData.buildSuccess();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	@GetMapping(&quot;update&quot;)</span><br><span class="line">	public Object update(String name,int id)&#123;</span><br><span class="line">		User user = new User();</span><br><span class="line">		user.setName(name);</span><br><span class="line">		user.setId(id);</span><br><span class="line">		userMapper.update(user);</span><br><span class="line">		return JsonData.buildSuccess();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-事务介绍和常见的隔离级别，传播行为"><a href="#4-事务介绍和常见的隔离级别，传播行为" class="headerlink" title="4. 事务介绍和常见的隔离级别，传播行为"></a>4. 事务介绍和常见的隔离级别，传播行为</h3><h4 id="1-介绍什么是事务，单机事务，分布式事务处理等"><a href="#1-介绍什么是事务，单机事务，分布式事务处理等" class="headerlink" title="1. 介绍什么是事务，单机事务，分布式事务处理等"></a>1. 介绍什么是事务，单机事务，分布式事务处理等</h4><p>略</p>
<h4 id="2-隔离级别"><a href="#2-隔离级别" class="headerlink" title="2. 隔离级别"></a>2. 隔离级别</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Serializable： 最严格，串行处理，消耗资源大</span><br><span class="line">Repeatable Read：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据</span><br><span class="line">Read Committed：大多数主流数据库的默认事务等级</span><br><span class="line">Read Uncommitted：保证了读取过程中不会读取到非法数据。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-常见的传播行为"><a href="#3-常见的传播行为" class="headerlink" title="3. 常见的传播行为"></a>3. 常见的传播行为</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PROPAGATION_REQUIRED--支持当前事务，如果当前没有事务，就新建一个事务,最常见的选择。</span><br><span class="line"></span><br><span class="line">PROPAGATION_SUPPORTS--支持当前事务，如果当前没有事务，就以非事务方式执行。</span><br><span class="line"></span><br><span class="line">PROPAGATION_MANDATORY--支持当前事务，如果当前没有事务，就抛出异常。</span><br><span class="line"></span><br><span class="line">PROPAGATION_REQUIRES_NEW--新建事务，如果当前存在事务，把当前事务挂起, 两个事务之间没有关系，一个异常，一个提交，不会同时回滚</span><br><span class="line"></span><br><span class="line">PROPAGATION_NOT_SUPPORTED--以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</span><br><span class="line"></span><br><span class="line">PROPAGATION_NEVER--以非事务方式执行，如果当前存在事务，则抛出异常</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="5-SpringBoot整合mybatis之事务处理"><a href="#5-SpringBoot整合mybatis之事务处理" class="headerlink" title="5. SpringBoot整合mybatis之事务处理"></a>5. SpringBoot整合mybatis之事务处理</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、service逻辑引入事务 @Transantional(propagation=Propagation.REQUIRED)</span><br><span class="line"></span><br><span class="line">2、service代码</span><br><span class="line">	@Override</span><br><span class="line">	@Transactional</span><br><span class="line">	public int addAccount() &#123;</span><br><span class="line">		User user = new User();</span><br><span class="line">		user.setAge(9);</span><br><span class="line">		user.setCreateTime(new Date());</span><br><span class="line">		user.setName(&quot;事务测试&quot;);</span><br><span class="line">		user.setPhone(&quot;000121212&quot;);</span><br><span class="line">		</span><br><span class="line">		userMapper.insert(user);</span><br><span class="line">		int a = 1/0;</span><br><span class="line"></span><br><span class="line">		return user.getId();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



<h2 id="9-SpringBoot2-x整合Redis"><a href="#9-SpringBoot2-x整合Redis" class="headerlink" title="9. SpringBoot2.x整合Redis"></a>9. SpringBoot2.x整合Redis</h2><h3 id="1-分布式缓存Redis介绍"><a href="#1-分布式缓存Redis介绍" class="headerlink" title="1. 分布式缓存Redis介绍"></a>1. 分布式缓存Redis介绍</h3><p>为什么要用缓存, 什么是Redis?</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、redis官网 https://redis.io/download</span><br><span class="line"></span><br><span class="line">2、新手入门redis在线测试工具：http://try.redis.io/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-源码编译安装Redis4-x"><a href="#2-源码编译安装Redis4-x" class="headerlink" title="2. 源码编译安装Redis4.x"></a>2. 源码编译安装Redis4.x</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、快速安装  https://redis.io/download#installation</span><br><span class="line">		wget http://download.redis.io/releases/redis-4.0.9.tar.gz</span><br><span class="line">		tar xzf redis-4.0.9.tar.gz</span><br><span class="line">		cd redis-4.0.9</span><br><span class="line">		make</span><br><span class="line"></span><br><span class="line">		启动服务端：src/redis-server</span><br><span class="line">		启动客户端：src/redis-cli</span><br><span class="line"></span><br><span class="line">2、默认是本地访问的，需要开放外网访问</span><br><span class="line">	1）打开redis.conf文件在NETWORK部分修改</span><br><span class="line">	   注释掉bind 127.0.0.1可以使所有的ip访问redis</span><br><span class="line">	   修改 protected-mode，值改为no</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-SpringBoot2-x整合redis实战"><a href="#3-SpringBoot2-x整合redis实战" class="headerlink" title="3. SpringBoot2.x整合redis实战"></a>3. SpringBoot2.x整合redis实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、官网：https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#boot-features-redis</span><br><span class="line">	集群文档：https://docs.spring.io/spring-data/data-redis/docs/current/reference/html/#cluster</span><br><span class="line"></span><br><span class="line">2、springboot整合redis相关依赖引入</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">3、相关配置文件配置</span><br><span class="line">	#=========redis基础配置=========</span><br><span class="line">	spring.redis.database=0</span><br><span class="line">	spring.redis.host=127.0.0.1</span><br><span class="line">	spring.redis.port=6390</span><br><span class="line">	# 连接超时时间 单位 ms（毫秒）</span><br><span class="line">	spring.redis.timeout=3000</span><br><span class="line"></span><br><span class="line">	#=========redis线程池设置=========</span><br><span class="line">	# 连接池中的最大空闲连接，默认值也是8。</span><br><span class="line">	spring.redis.pool.max-idle=200</span><br><span class="line"></span><br><span class="line">	#连接池中的最小空闲连接，默认值也是0。</span><br><span class="line">	spring.redis.pool.min-idle=200</span><br><span class="line">	</span><br><span class="line">	# 如果赋值为-1，则表示不限制；pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。</span><br><span class="line">	spring.redis.pool.max-active=2000</span><br><span class="line"></span><br><span class="line">	# 等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时</span><br><span class="line">	spring.redis.pool.max-wait=1000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">4、常见redistemplate种类讲解和缓存实操(使用自动注入)</span><br><span class="line"></span><br><span class="line">	1、注入模板</span><br><span class="line">	@Autowired</span><br><span class="line">	private StirngRedisTemplate strTplRedis</span><br><span class="line"></span><br><span class="line">	2、类型String，List,Hash,Set,ZSet</span><br><span class="line">	对应的方法分别是opsForValue()、opsForList()、opsForHash()、opsForSet()、opsForZSet()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-Redis工具类封装讲解和实战"><a href="#4-Redis工具类封装讲解和实战" class="headerlink" title="4. Redis工具类封装讲解和实战"></a>4. Redis工具类封装讲解和实战</h3><p>高效开发方式 Redis工具类封装讲解和实战</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、常用客户端 https://redisdesktop.com/download</span><br><span class="line"></span><br><span class="line">2、封装redis工具类并操作</span><br></pre></td></tr></table></figure>



<h2 id="10-SpringBoot整合定时任务和异步任务处理"><a href="#10-SpringBoot整合定时任务和异步任务处理" class="headerlink" title="10. SpringBoot整合定时任务和异步任务处理"></a>10. SpringBoot整合定时任务和异步任务处理</h2><h3 id="1-SpringBoot定时任务schedule"><a href="#1-SpringBoot定时任务schedule" class="headerlink" title="1. SpringBoot定时任务schedule"></a>1. SpringBoot定时任务schedule</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、常见定时任务 Java自带的java.util.Timer类</span><br><span class="line">	timer:配置比较麻烦，时间延后问题</span><br><span class="line">	timertask:不推荐</span><br><span class="line"></span><br><span class="line">2、Quartz框架</span><br><span class="line">	配置更简单</span><br><span class="line">	xml或者注解</span><br><span class="line"></span><br><span class="line">3、SpringBoot使用注解方式开启定时任务</span><br><span class="line">	1）启动类里面 @EnableScheduling开启定时任务，自动扫描</span><br><span class="line">	2）定时任务业务类 加注解 @Component被容器扫描</span><br><span class="line">	3）定时执行的方法加上注解 @Scheduled(fixedRate=2000) 定期执行一次</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot常用定时任务配置实战"><a href="#2-SpringBoot常用定时任务配置实战" class="headerlink" title="2. SpringBoot常用定时任务配置实战"></a>2. SpringBoot常用定时任务配置实战</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、cron 定时任务表达式 @Scheduled(cron=&quot;*/1 * * * * *&quot;) 表示每秒</span><br><span class="line">	1）crontab 工具  https://tool.lu/crontab/</span><br><span class="line">	</span><br><span class="line">2、fixedRate: 定时多久执行一次（上一次开始执行时间点后xx秒再次执行；）</span><br><span class="line"></span><br><span class="line">3、fixedDelay: 上一次执行结束时间点后xx秒再次执行</span><br><span class="line"></span><br><span class="line">4、fixedDelayString:  字符串形式，可以通过配置文件指定</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-SpringBoot2-x异步任务实战"><a href="#3-SpringBoot2-x异步任务实战" class="headerlink" title="3. SpringBoot2.x异步任务实战"></a>3. SpringBoot2.x异步任务实战</h3><p>什么是异步任务，如何使用SpringBoot2.x开发异步任务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、什么是异步任务和使用场景：适用于处理log、发送邮件、短信……等</span><br><span class="line">	下单接口-&gt;查库存 100</span><br><span class="line">			余额校验 150</span><br><span class="line">			风控用户100</span><br><span class="line">			....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、启动类里面使用@EnableAsync注解开启功能，自动扫描</span><br><span class="line"></span><br><span class="line">3、定义异步任务类并使用@Component标记组件被容器扫描,异步方法加上@Async</span><br><span class="line">	注意点：</span><br><span class="line">		1）要把异步任务封装到类里面，不能直接写到Controller</span><br><span class="line">		2）增加Future&lt;String&gt; 返回结果 AsyncResult&lt;String&gt;(&quot;task执行完成&quot;);  </span><br><span class="line">		3）如果需要拿到结果 需要判断全部的 task.isDone()</span><br><span class="line">4、通过注入方式，注入到controller里面，如果测试前后区别则改为同步则把Async注释掉</span><br></pre></td></tr></table></figure>



<h2 id="11-Logback日志框架介绍和SpringBoot整合"><a href="#11-Logback日志框架介绍和SpringBoot整合" class="headerlink" title="11. Logback日志框架介绍和SpringBoot整合"></a>11. Logback日志框架介绍和SpringBoot整合</h2><h3 id="1-新日志框架LogBack介绍"><a href="#1-新日志框架LogBack介绍" class="headerlink" title="1. 新日志框架LogBack介绍"></a>1. 新日志框架LogBack介绍</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.常用处理java的日志组件 slf4j,log4j,logback,common-logging 等</span><br><span class="line"></span><br><span class="line">2、logback介绍：基于Log4j基础上大量改良，不能单独使用，推荐配合日志框架SLF4J来使用</span><br><span class="line">	logback当前分成三个模块：logback-core,logback-classic和logback-access;</span><br><span class="line">	logback-core是其它两个模块的基础模块</span><br><span class="line"></span><br><span class="line">3、Logback的核心对象：</span><br><span class="line">	Logger：日志记录器</span><br><span class="line">	Appender：指定日志输出的目的地，目的地可以是控制台，文件</span><br><span class="line">	Layout：日志布局 格式化日志信息的输出</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">4、日志级别：DEBUG &lt; INFO &lt; WARN &lt; ERROR</span><br><span class="line"></span><br><span class="line">	===========log4j示例===========		</span><br><span class="line">	 ### 设置###</span><br><span class="line">	log4j.rootLogger = debug,stdout,D,E</span><br><span class="line"></span><br><span class="line">	### 输出信息到控制抬 ###</span><br><span class="line">	log4j.appender.stdout = org.apache.log4j.ConsoleAppender</span><br><span class="line">	log4j.appender.stdout.Target = System.out</span><br><span class="line">	log4j.appender.stdout.layout = org.apache.log4j.PatternLayout</span><br><span class="line">	log4j.appender.stdout.layout.ConversionPattern = [%-5p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n</span><br><span class="line"></span><br><span class="line">	### 输出DEBUG 级别以上的日志到=D://logs/log.log ###</span><br><span class="line">	log4j.appender.D = org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">	log4j.appender.D.File = D://logs/log.log</span><br><span class="line">	log4j.appender.D.Append = true</span><br><span class="line">	log4j.appender.D.Threshold = DEBUG </span><br><span class="line">	log4j.appender.D.layout = org.apache.log4j.PatternLayout</span><br><span class="line">	log4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125;  [ %t:%r ] - [ %p ]  %m%n</span><br><span class="line"></span><br><span class="line">	### 输出ERROR 级别以上的日志到=D://logs/error.log ###</span><br><span class="line">	log4j.appender.E = org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">	log4j.appender.E.File =E://logs/error.log </span><br><span class="line">	log4j.appender.E.Append = true</span><br><span class="line">	log4j.appender.E.Threshold = ERROR </span><br><span class="line">	log4j.appender.E.layout = org.apache.log4j.PatternLayout</span><br><span class="line">	log4j.appender.E.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125;  [ %t:%r ] - [ %p ]  %m%n </span><br><span class="line"></span><br><span class="line">	===========logback============</span><br><span class="line"></span><br><span class="line">4、Log4j日志转换为logback在线工具（支持log4j.properties转换为logback.xml,不支持 log4j.xml转换为logback.xml）</span><br><span class="line"> https://logback.qos.ch/translator/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-SpringBoot2-x日志讲解和自定义Logback配置"><a href="#2-SpringBoot2-x日志讲解和自定义Logback配置" class="headerlink" title="2. SpringBoot2.x日志讲解和自定义Logback配置"></a>2. SpringBoot2.x日志讲解和自定义Logback配置</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、官网介绍：https://docs.spring.io/spring-boot/docs/2.7.0/reference/htmlsingle/#boot-features-logging</span><br><span class="line"></span><br><span class="line">   各个组件案例：https://logback.qos.ch/manual/index.html</span><br><span class="line"></span><br><span class="line">2、分析SpringBoot启动日志</span><br><span class="line">	1）默认情况下，Spring Boot将日志输出到控制台</span><br><span class="line"></span><br><span class="line">3、整合Logback实战</span><br><span class="line">	1）创建 日志文件logback-spring.xml，官方推荐 -spring.xml结尾</span><br><span class="line">		默认加载加载配置顺序 logback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy</span><br><span class="line">	</span><br><span class="line">	注释：</span><br><span class="line">		&lt;configuration&gt; 子节点</span><br><span class="line">		&lt;appender&gt;&lt;/appender&gt;   					</span><br><span class="line">		&lt;logger&gt;&lt;/logger&gt;</span><br><span class="line">		&lt;root&gt;&lt;/root&gt;(要加在最后)		</span><br></pre></td></tr></table></figure>



<h2 id="12-搜索框架ElasticSearch介绍和整合SpringBoot"><a href="#12-搜索框架ElasticSearch介绍和整合SpringBoot" class="headerlink" title="12. 搜索框架ElasticSearch介绍和整合SpringBoot"></a>12. 搜索框架ElasticSearch介绍和整合SpringBoot</h2><h2 id="13-消息队列介绍和SpringBoot2-x整合RockketMQ、ActiveMQ"><a href="#13-消息队列介绍和SpringBoot2-x整合RockketMQ、ActiveMQ" class="headerlink" title="13. 消息队列介绍和SpringBoot2.x整合RockketMQ、ActiveMQ"></a>13. 消息队列介绍和SpringBoot2.x整合RockketMQ、ActiveMQ</h2>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java框架</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring笔记</title>
    <url>/2018/01/10/Spring/Spring%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h1><ul>
<li><p>Spring 是一个开源框架.</p>
</li>
<li><p>使用Spring可以简单的实现 JavaBean.Spring IOC 容器可以管理 Bean 的生命周期.</p>
</li>
<li><p>Spring 是一个 IOC(DI)和AOP容器框架.</p>
</li>
<li><p>在开发过程中的轻松解耦，提高项目的开发效率。</p>
</li>
</ul>
<h2 id="spring-特点"><a href="#spring-特点" class="headerlink" title="spring 特点"></a>spring 特点</h2><ol>
<li>轻量级：Spring 是非侵入性的，基于 Spring开发的应用的对象可以不依赖于 Spring<br>的API。</li>
<li>依赖注入(DI — dependency injection、IOC)</li>
<li>–面向切面编程(AOP— aspect oriented programming)</li>
<li>–容器: Spring 是一个容器, 因为它<strong>包含并且管理应用对象的生命周期</strong></li>
<li>框架:Spring 实现了使用简单的组件配置组合成一个复杂的应用。可以使用 XML 和<br>Java注解组合这些对象</li>
<li>一站式：在IOC和AOP的基础上可以整合各种企业应用的开源框架和优秀的第三方类库<br>（实际上Spring自身也提供了展现层的SpringMVC和持久层的 Spring JDBC）</li>
</ol>
<p>在项目中引入Spring可以带来以下好处：</p>
<ol>
<li><p><strong>降低组件之间的耦合</strong>度,实现软件各层之间的解耦。</p>
</li>
<li><p>可以<strong>使用容器提供的众多服务</strong>，如：事务管理服务、消息服务等等。</p>
</li>
<li><p>当我们使用容器管理事务时，开发人员就<strong>不再需要手工控制事务</strong>.也不需处理复杂的事务传播。</p>
</li>
<li><p>容器<strong>提供单例模式支持</strong>，开发人员<strong>不再需要自己编写实现代码</strong>。</p>
</li>
<li><p>容器提供了 <strong>AOP 技术</strong>，利用它很容易实现如<strong>权限拦截、运行期监控</strong>等功能。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java框架</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ</title>
    <url>/2019/12/12/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/</url>
    <content><![CDATA[<h1 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h1><h2 id="1-什么是MQ"><a href="#1-什么是MQ" class="headerlink" title="1. 什么是MQ?"></a>1. 什么是MQ?</h2><ul>
<li>消息队列（Message Queue，简称MQ），本质是个队列，FIFO先入先出，只不过队列中存放的内容是message而已。</li>
<li>其主要用途：不同进程(Process)&#x2F;线程(Thread)之间通信。</li>
</ul>
<p>为什么会产生消息队列？</p>
<ul>
<li>不同进程（process）之间传递消息时，两个进程之间耦合程度过高，改动一个进程，引发必须修改另一个进程。为了隔离这两个进程，在两进程间抽离出一层（一个模块）即消息队列，来传递消息。单独修改某一个进程，不会影响另一个。</li>
<li>不同进程（process）之间传递消息时，为了实现标准化，将消息的格式规范化了。</li>
<li>某一个进程接受的消息太多，一下子无法处理完，并且也有先后顺序，必须对收到的消息进行排队。</li>
</ul>
<h2 id="2-五种队列"><a href="#2-五种队列" class="headerlink" title="2. 五种队列"></a>2. 五种队列</h2><p>分类：</p>
<ul>
<li>简单队列（一对一）。耦合性高。生产者消费者一一对应，需要同时修改。</li>
<li>Work queues。一个生产者，多个消费者共同处理所有的消息。</li>
<li>交换机<ul>
<li>Publish&#x2F;Subscribe。一个生产者，多个消费者分别消费所有的信息。</li>
<li>Routing。相对订阅，多了一个key。分别选择性消费信息。</li>
<li>Topic。消费者，改进key。允许模糊匹配。</li>
</ul>
</li>
</ul>
<h3 id="1-简单队列"><a href="#1-简单队列" class="headerlink" title="1.简单队列"></a>1.简单队列</h3><p>P - 》 queue - 》 C</p>
<p>P：消息的生产者, C：消息的消费者, queue :队列</p>
<p>生产者将消息发送到队列，消费者从队列中获取消息。</p>
<p>简单队列的生产者和消费者关系一对一。<br>但有时我们的需求，需要一个生产者，对应多个消费者，</p>
<p>那就可以采用第二种模式<strong>Work模式</strong>。</p>
<h3 id="2-Work模式（轮训和公平）"><a href="#2-Work模式（轮训和公平）" class="headerlink" title="2. Work模式（轮训和公平）"></a>2. Work模式（轮训和公平）</h3><p>P - 》 queue - 》 C1，C2</p>
<p>一个生产者、2个消费者。</p>
<p>但MQ中一个消息只能被一个消费者获取。即消息要么被C1获取，要么被C2获取。这种模式适用于类似集群，能者多劳。性能好的可以安排多消费，性能低的可以安排低消费。</p>
<p>有两个概念：<strong>轮询分发</strong>（消费者获取到的消息的数量是相同的） ，<strong>公平分发</strong>（按消费者的能力分配消息）</p>
<p>但<strong>如果面对我需要多个消费者都对这一消息进行消费的需求</strong>，这种模式显然就不适用了。</p>
<p>那就可以采用第三种模式，订阅模式。</p>
<h3 id="3-订阅模式"><a href="#3-订阅模式" class="headerlink" title="3. 订阅模式"></a>3. 订阅模式</h3><p>P - 》 X - 》 queue1,queue2 - 》 C1，C2</p>
<ul>
<li>1个生产者，多个消费者</li>
<li>每一个消费者都有自己的一个队列</li>
<li>生产者没有将消息直接发送到队列，而是发送到了交换机X</li>
<li>每个队列都要绑定到交换机</li>
<li>生产者发送的消息，经过交换机，到达队列，实现，一个消息被多个消费者获取的目的</li>
</ul>
<p>注意：一个消费者队列可以有多个消费者实例，只有其中一个消费者实例会消费。</p>
<p>流程：</p>
<ul>
<li><strong>消息的生产者向交换机中发送消息</strong>。注意：消息发送到没有队列绑定的交换机时，消息将丢失，因为，交换机没有存储消息的能力，消息只能存在在队列中。</li>
<li>各个消费者消费信息。</li>
</ul>
<p>同一个消息被多个消费者获取。</p>
<p><strong>这种模式可以满足消费者发布一个消息，多个消费者消费同一信息的需求</strong>。</p>
<p>但C1、C2消费的都是相同的数据，有时我们需要C1和C2消费的信息只有部分差异，比如我们需求：C1消费增加的数据，C2消费编辑、增加和删除的数据。</p>
<p>引入第四种模式，<strong>路由模式</strong>。</p>
<h3 id="4-路由模式"><a href="#4-路由模式" class="headerlink" title="4. 路由模式"></a>4. 路由模式</h3><p>路由模式是在订阅模式基础上的完善，可以<strong>在生产消息的时候，加入Key值</strong>，与key值匹配的消费者消费信息。</p>
<p>但路由模式中，就如三中提到的C1、C2、如果C2对应的类型更多，就需要写很多key值。但其实它只与C1有一点差别。</p>
<p>那就可以考虑第五种模式：通配符模式</p>
<h3 id="5-通配符模式"><a href="#5-通配符模式" class="headerlink" title="5.通配符模式"></a>5.通配符模式</h3><p>通配符模式是在路由模式的升级，他允许key模糊匹配。</p>
<p>其中*代表一个词，#代表一个或多个词。</p>
<p>通过通配符模式我们就可以将C1对应的一个key准确定为item.add。而C2我们就不需要一一写出key值，而是用item.#代替即可。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis入门</title>
    <url>/2019/01/10/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="初识Redis"><a href="#初识Redis" class="headerlink" title="初识Redis"></a>初识Redis</h2><h3 id="nosql介绍"><a href="#nosql介绍" class="headerlink" title="nosql介绍"></a>nosql介绍</h3><p>NoSQL：一类新出现的数据库(not only sql)，特点：</p>
<ul>
<li>不支持SQL语法</li>
<li>存储结构跟传统关系型数据库中的那种关系表完全不同，nosql中存储的数据都是KV形式</li>
<li>NoSQL的世界中没有一种通用的语言，每种nosql数据库都有自己的api和语法，以及擅长的业务场景</li>
<li>NoSQL中的产品种类相当多：<ul>
<li>Mongodb</li>
<li>Redis</li>
<li>Hbase hadoop</li>
</ul>
</li>
<li>NoSQL和SQL数据库的比较：<ul>
<li>适用场景不同：sql数据库适合用于关系特别复杂的数据查询场景，nosql反之</li>
<li>“事务”特性的支持：sql对事务的支持非常完善，而nosql基本不支持事务</li>
<li>两者在不断地取长补短，呈现融合趋势</li>
</ul>
</li>
</ul>
<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。</p>
<p>Redis是 NoSQL技术阵营中的一员，它通过多种键值数据类型来适应不同场景下的存储需求，可以胜任，如缓存、队列系统的不同角色。</p>
<h3 id="Redis特性"><a href="#Redis特性" class="headerlink" title="Redis特性"></a>Redis特性</h3><p>Redis 与其他 key - value 缓存产品有以下三个特点：</p>
<ul>
<li>支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li>
<li>不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li>
<li>支持数据的备份（集群模式），即master-slave模式的数据备份。</li>
</ul>
<h3 id="Redis-优势"><a href="#Redis-优势" class="headerlink" title="Redis 优势"></a>Redis 优势</h3><ul>
<li>性能极高，读写速度极快。</li>
<li>丰富的数据类型。支持Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li>
<li>原子操作 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。</li>
<li>丰富的特性。通知, key 过期等。</li>
</ul>
<h3 id="Redis应用场景"><a href="#Redis应用场景" class="headerlink" title="Redis应用场景"></a>Redis应用场景</h3><ul>
<li>用来做缓存(ehcache&#x2F;memcached)——redis的所有数据是放在内存中的（内存数据库）</li>
<li>在某些特定应用场景下替代传统数据库——比如社交类的应用</li>
<li>在一些大型系统中，巧妙地实现一些特定的功能：session共享、购物车</li>
</ul>
<h2 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h2><h3 id="方法1：源码编译"><a href="#方法1：源码编译" class="headerlink" title="方法1：源码编译"></a>方法1：源码编译</h3><ol>
<li><p>下载</p>
<p>wget <a href="http://download.redis.io/releases/redis-3.2.8.tar.gz">http://download.redis.io/releases/redis-3.2.8.tar.gz</a></p>
</li>
<li><p>解压</p>
<p>tar -zxvf redis-3.2.8.tar.gz</p>
</li>
<li><p>复制，放到opt&#x2F;⽬录下</p>
<p>sudo mv .&#x2F;redis-3.2.8 &#x2F;opt&#x2F;redis&#x2F;</p>
</li>
<li><p>进⼊redis⽬录</p>
<p>cd &#x2F;opt&#x2F;redis&#x2F;</p>
</li>
<li><p>生成</p>
<p>sudo make</p>
</li>
<li><p>测试—时间会较⻓</p>
<p>sudo make test</p>
</li>
<li><p>安装, 将redis的命令安装到&#x2F;usr&#x2F;local&#x2F;redis&#x2F;⽬录</p>
<p>sudo make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis</p>
</li>
<li><p>安装完成, 进入目录&#x2F;usr&#x2F;local&#x2F;redis中查看</p>
<blockquote>
<p>cd &#x2F;usr&#x2F;local&#x2F;redis</p>
</blockquote>
<blockquote>
<p>ll</p>
</blockquote>
<ul>
<li>redis-server redis服务器</li>
<li>redis-cli redis命令行客户端</li>
<li>redis-benchmark redis性能测试工具</li>
<li>redis-check-aof AOF文件修复工具</li>
<li>redis-check-rdb RDB文件检索工具</li>
</ul>
</li>
<li><p>配置⽂件，移动到&#x2F;etc&#x2F;⽬录下</p>
<p>sudo cp &#x2F;opt&#x2F;redis&#x2F;redis.conf &#x2F;etc&#x2F;redis&#x2F;</p>
</li>
</ol>
<h3 id="apt安装"><a href="#apt安装" class="headerlink" title="apt安装"></a>apt安装</h3><ol>
<li>sudo apt-get update</li>
<li>sudo apt-get install redis-server</li>
<li>service redis status –查看redis服务的状态为running，说明安装完成系统自动启动了服务</li>
</ol>
<h3 id="配置redis"><a href="#配置redis" class="headerlink" title="配置redis"></a>配置redis</h3><ul>
<li><p>cd &#x2F;etc&#x2F;redis&#x2F;redis.conf</p>
<p>开启远程连接：注释掉 127.0.0.1 #bind 127.0.0.1</p>
<p>设置密码 : 添加 requirepass 123456（密码设置为123456）</p>
</li>
<li><p>重启redis服务</p>
<p>停止&#x2F;启动&#x2F;重启redis</p>
<blockquote>
<p>&#x2F;etc&#x2F;init.d&#x2F;redis-server stop</p>
</blockquote>
<blockquote>
<p>&#x2F;etc&#x2F;init.d&#x2F;redis-server start</p>
</blockquote>
<blockquote>
<p>&#x2F;etc&#x2F;init.d&#x2F;redis-server restart</p>
</blockquote>
</li>
<li><p>核心配置选项</p>
<ul>
<li><p>绑定ip：如果需要远程访问，可将此⾏注释，或绑定⼀个真实ip</p>
<blockquote>
<p>bind 127.0.0.1</p>
</blockquote>
</li>
<li><p>端⼝，默认为6379</p>
<blockquote>
<p>port 6379</p>
</blockquote>
</li>
<li><p>是否以守护进程运⾏</p>
<ul>
<li>如果以守护进程运⾏，则不会在命令⾏阻塞，类似于服务</li>
<li>如果以⾮守护进程运⾏，则当前终端被阻塞</li>
<li>设置为yes表示守护进程，设置为no表示⾮守护进程</li>
<li>推荐设置为yes</li>
</ul>
<blockquote>
<p>daemonize yes</p>
</blockquote>
</li>
<li><p>数据⽂件</p>
<blockquote>
<p>dbfilename dump.rdb</p>
</blockquote>
</li>
<li><p>数据⽂件存储路径</p>
<blockquote>
<p>dir &#x2F;var&#x2F;lib&#x2F;redis</p>
</blockquote>
</li>
<li><p>⽇志⽂件</p>
<blockquote>
<p>logfile &#x2F;var&#x2F;log&#x2F;redis&#x2F;redis-server.log</p>
</blockquote>
</li>
<li><p>数据库，默认有16个</p>
<blockquote>
<p>database 16</p>
</blockquote>
</li>
<li><p>主从复制，类似于双机备份。</p>
<blockquote>
<p>slaveof</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="测试redis服务"><a href="#测试redis服务" class="headerlink" title="测试redis服务"></a>测试redis服务</h3><ul>
<li><p>服务端测试</p>
<ol>
<li>redis-cli 打开redis客户端</li>
<li>auth 123456–先验证身份</li>
<li>set a “sss”</li>
<li>get a</li>
</ol>
</li>
<li><p>测试远程登录</p>
<p>本地window打开一个客户端 ,cd到redis安装的目录，主要是要有redis-cli.exe的目录</p>
<ol>
<li>redis-cli -h redis服务器IP -p redis服务端口号(默认6379)</li>
<li>auth 123456–先验证身份</li>
<li>set a “sss”</li>
<li>get a</li>
</ol>
</li>
</ul>
<h2 id="服务器端和客户端"><a href="#服务器端和客户端" class="headerlink" title="服务器端和客户端"></a>服务器端和客户端</h2><h4 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h4><p>Redis服务器负责与多个客户端建立网络连接，处理客户端发送的命令 请求，在数据库中保存客户端执行命令所产生的数据，并通过资源管理来维持服务器自身的运转。<strong>服务器可以接受外来客户端的网络连接</strong>。</p>
<ul>
<li><p>服务器端的命令为redis-server</p>
</li>
<li><p>可以使⽤help查看帮助⽂档</p>
<blockquote>
<p>redis-server –help</p>
</blockquote>
</li>
<li><p>推荐使⽤服务的⽅式管理redis服务</p>
<ul>
<li><p>启动</p>
<blockquote>
<p>sudo service redis start</p>
</blockquote>
</li>
<li><p>停⽌</p>
<blockquote>
<p>sudo service redis stop</p>
</blockquote>
</li>
</ul>
</li>
<li><p>重启 sudo service redis restart</p>
</li>
<li><p>推荐</p>
<blockquote>
<p>ps -ef|grep redis 查看redis服务器进程<br>sudo kill -9 pid 杀死redis服务器<br>sudo redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf 指定加载的配置文件</p>
</blockquote>
</li>
</ul>
<h4 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h4><ul>
<li><p>客户端的命令</p>
<blockquote>
<p>redis-cli</p>
</blockquote>
</li>
<li><p>可以使⽤help查看帮助⽂档</p>
<blockquote>
<p>redis-cli –help</p>
</blockquote>
</li>
<li><p>连接redis</p>
<blockquote>
<p>redis-cli</p>
</blockquote>
</li>
<li><p>切换到数据库n</p>
<p>数据库没有名称，默认有16个，通过0-15来标识，连接redis默认选择第一个数据库</p>
<blockquote>
<p>select n</p>
</blockquote>
</li>
</ul>
<h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><ul>
<li>redis是key-value的数据结构，每条数据都是⼀个键值对</li>
<li>键的类型是字符串</li>
<li>注意：键不能重复</li>
</ul>
<p><a href="20220708-1.jpg"><img src="/../../../../images/20220708-1.jpg" alt="img"></a></p>
<ul>
<li><p>值的类型分为五种：</p>
<ul>
<li>字符串string</li>
<li>哈希hash</li>
<li>列表list</li>
<li>集合set</li>
<li>有序集合zset</li>
</ul>
</li>
<li><h1 id="数据操作行为"><a href="#数据操作行为" class="headerlink" title="数据操作行为"></a>数据操作行为</h1><ul>
<li>保存</li>
<li>修改</li>
<li>获取</li>
<li>删除</li>
</ul>
</li>
</ul>
<h4 id="键命令"><a href="#键命令" class="headerlink" title="键命令"></a>键命令</h4><ul>
<li><p>查找键</p>
<blockquote>
<p>keys pattern</p>
<ul>
<li>查看所有键: keys *</li>
<li>查看名称中包含a的键: keys ‘a*’</li>
</ul>
</blockquote>
</li>
<li><p>判断键是否存在</p>
<blockquote>
<p>exists key</p>
</blockquote>
</li>
<li><p>查看键对应的value的类型</p>
<blockquote>
<p>type key</p>
</blockquote>
</li>
<li><p>删除键及对应的值</p>
<blockquote>
<p>del key1 key2 …</p>
</blockquote>
</li>
<li><p>设置过期时间，以秒为单位</p>
<blockquote>
<p>expire key seconds</p>
</blockquote>
</li>
<li><p>查看有效时间，以秒为单位</p>
<blockquote>
<p>ttl key</p>
</blockquote>
</li>
</ul>
<h4 id="string类型"><a href="#string类型" class="headerlink" title="string类型"></a>string类型</h4><p> 字符串类型是Redis中最为基础的数据存储类型，在Redis中是二进制安全的。该类型可以接受任何格式的数据，如 JPEG图像数据或Json对象描述信息等。<strong>最多可以容纳的数据长度是512M</strong>。</p>
<h5 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h5><ul>
<li><p>设置键值</p>
<blockquote>
<p>set key value</p>
</blockquote>
</li>
<li><p>设置键值及过期时间，以秒为单位</p>
<blockquote>
<p>setex key seconds value</p>
</blockquote>
<p>ex. set name 3 zhangsan</p>
</li>
<li><p>设置多个键值</p>
<blockquote>
<p>mset key1 value1 key2 value2 …</p>
</blockquote>
</li>
<li><p>追加值—-向键中追加值</p>
<blockquote>
<p>append key value</p>
</blockquote>
</li>
</ul>
<h5 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h5><ul>
<li><p>获取：根据键获取值，如果不存在此键则返回nil</p>
<blockquote>
<p>get key</p>
</blockquote>
</li>
<li><p>根据多个键获取多个值</p>
<blockquote>
<p>mget key1 key2 …</p>
</blockquote>
</li>
</ul>
<h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><ul>
<li>删除键时会将值删除</li>
</ul>
<h4 id="hash类型"><a href="#hash类型" class="headerlink" title="hash类型"></a>hash类型</h4><ul>
<li>hash⽤于存储对象，对象的结构为<strong>属性、值</strong></li>
<li>值的类型为string</li>
</ul>
<h5 id="增加、修改"><a href="#增加、修改" class="headerlink" title="增加、修改"></a>增加、修改</h5><ul>
<li><p>设置单个属性</p>
<blockquote>
<p>hset key field value</p>
</blockquote>
<ul>
<li><p>例1：设置键 user的属性name为itheima</p>
</li>
<li><p>hset user name itheima</p>
</li>
<li><p>报exxro:MISCONF Redis is configured to save RDB snapshots..</p>
<p>Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用。</p>
<p>原因：强制关闭Redis快照导致不能持久化。 解决方案：</p>
<ul>
<li>redis中运行：config set stop-writes-on-bgsave-error no</li>
</ul>
</li>
</ul>
</li>
<li><p>设置多个属性</p>
<blockquote>
<p>hmset key field1 value1 field2 value2 …</p>
</blockquote>
</li>
</ul>
<h5 id="获取-1"><a href="#获取-1" class="headerlink" title="获取"></a>获取</h5><ul>
<li><p>获取指定键所有的属性</p>
<blockquote>
<p>hkeys key</p>
</blockquote>
</li>
<li><p>获取⼀个属性的值</p>
<blockquote>
<p>hget key field</p>
</blockquote>
</li>
<li><p>获取多个属性的值</p>
<blockquote>
<p>hmget key field1 field2 …</p>
</blockquote>
</li>
<li><p>获取所有属性的值</p>
<blockquote>
<p>hvals key</p>
</blockquote>
</li>
</ul>
<h5 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h5><ul>
<li><p>删除整个hash键及值，使⽤del命令</p>
<blockquote>
<p>del key</p>
</blockquote>
</li>
<li><p>删除属性，属性对应的值会被⼀起删除</p>
<blockquote>
<p>hdel key field1 field2 …</p>
</blockquote>
</li>
</ul>
<h4 id="list类型"><a href="#list类型" class="headerlink" title="list类型"></a>list类型</h4><ul>
<li>列表的元素类型为string</li>
<li>按照插⼊顺序排序</li>
</ul>
<h5 id="获取-2"><a href="#获取-2" class="headerlink" title="获取"></a>获取</h5><ul>
<li><p>返回列表⾥指定范围内的元素</p>
<ul>
<li>start、stop为元素的下标索引</li>
<li>索引从左侧开始，第⼀个元素为0</li>
<li>索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素</li>
</ul>
<blockquote>
<p>lrange key start stop</p>
</blockquote>
</li>
<li><p>例4：获取键为’a1’的列表所有元素</p>
<blockquote>
<p>lrange a1 0 -1</p>
</blockquote>
</li>
</ul>
<h5 id="增加"><a href="#增加" class="headerlink" title="增加"></a>增加</h5><ul>
<li><p>在左侧插⼊数据</p>
<blockquote>
<p>lpush key value1 value2 …</p>
</blockquote>
<ul>
<li><p>例1：从键为’a1’的列表左侧加⼊数据a 、 b 、c</p>
<blockquote>
<p>lpush a1 a b c</p>
<p>lrange a1 0 3</p>
</blockquote>
</li>
</ul>
</li>
<li><p>在右侧插⼊数据</p>
<blockquote>
<p>rpush key value1 value2 …</p>
</blockquote>
<ul>
<li><p>例2：从键为’a1’的列表右侧加⼊数据0 1</p>
<blockquote>
<p>rpush a1 0 1</p>
<p>lrange a1 0 5</p>
</blockquote>
</li>
</ul>
</li>
<li><p>在指定元素的前或后插⼊新元素</p>
<blockquote>
<p>linsert key before或after 现有元素 新元素</p>
</blockquote>
<ul>
<li><p>例3：在键为’a1’的列表中元素’b’前加⼊’3’</p>
<blockquote>
<p>linsert a1 before b 3</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h5 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h5><ul>
<li><p>设置指定索引位置的值</p>
<ul>
<li>索引从左侧开始，第⼀个元素为0</li>
<li>索引可以是负数，表示尾部开始计数，如-1表示最后⼀个元素</li>
</ul>
<blockquote>
<p>lset key index value</p>
</blockquote>
<ul>
<li><p>例5：修改键为’a1’的列表中下标为1的元素值为’z’</p>
<blockquote>
<p>lset a 1 z</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h5 id="删除-2"><a href="#删除-2" class="headerlink" title="删除"></a>删除</h5><ul>
<li><p>删除指定元素</p>
<ul>
<li>将列表中<strong>前count次出现的值为value的元素移除</strong></li>
<li>count &gt; 0: 从头往尾移除</li>
<li>count &lt; 0: 从尾往头移除</li>
<li>count &#x3D; 0: 移除所有</li>
</ul>
<blockquote>
<p>lrem key count value</p>
</blockquote>
<ul>
<li><p>例6.1：向列表’a2’中加⼊元素’a’、’b’、’a’、’b’、’a’、’b’</p>
<blockquote>
<p>lpush a2 a b a b a b</p>
</blockquote>
</li>
<li><p>例6.2：从’a2’列表右侧开始删除2个’b’</p>
<blockquote>
<p>lrem a2 -2 b</p>
</blockquote>
</li>
<li><p>例6.3：查看列表’py12’的所有元素</p>
<blockquote>
<p>lrange a2 0 -1</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h4 id="set类型"><a href="#set类型" class="headerlink" title="set类型"></a>set类型</h4><ul>
<li>⽆序集合</li>
<li>元素为string类型</li>
<li>元素具有唯⼀性，不重复</li>
<li><strong>说明：对于集合没有修改操作</strong></li>
</ul>
<p>#####　增加</p>
<ul>
<li><p>添加元素</p>
<blockquote>
<p>sadd key member1 member2 …</p>
</blockquote>
<ul>
<li><p>例1：向键’a3’的集合中添加元素’zhangsan’、’lisi’、’wangwu’</p>
<blockquote>
<p>sadd a3 zhangsan sili wangwu</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h5 id="获取-3"><a href="#获取-3" class="headerlink" title="获取"></a>获取</h5><ul>
<li><p>删除指定元素</p>
<blockquote>
<p>srem key</p>
</blockquote>
<ul>
<li><p>例3：删除键’a3’的集合中元素’wangwu’</p>
<blockquote>
<p>srem a3 wangwu</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h4 id="zet类型"><a href="#zet类型" class="headerlink" title="zet类型"></a>zet类型</h4><ul>
<li>sorted set，有序集合</li>
<li>元素为string类型</li>
<li>元素具有唯⼀性，不重复</li>
<li><strong>每个元素都会关联⼀个double类型的score，表示权重，通过权重将元素从⼩到⼤排序</strong></li>
<li><strong>说明：没有修改操作</strong></li>
</ul>
<h5 id="增加-1"><a href="#增加-1" class="headerlink" title="增加"></a>增加</h5><ul>
<li><p>添加</p>
<blockquote>
<p>zadd key score1 member1 score2 member2 …</p>
</blockquote>
</li>
<li><p>例1：向键’a4’的集合中添加元素’lisi’、’wangwu’、’zhaoliu’、’zhangsan’，权重分别为4、5、6、3</p>
<blockquote>
<p>zadd a4 4 lisi 5 wangwu 6 zhaoliu 3 zhangsan</p>
</blockquote>
</li>
</ul>
<h5 id="获取-4"><a href="#获取-4" class="headerlink" title="获取"></a>获取</h5><ul>
<li><p>返回指定范围内的元素</p>
</li>
<li><p>start、stop为元素的下标索引</p>
</li>
<li><p>索引从左侧开始，第⼀个元素为0</p>
</li>
<li><p>索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素</p>
<blockquote>
<p>zrange key start stop</p>
</blockquote>
<ul>
<li><p>例2：获取键’a4’的集合中所有元素</p>
<blockquote>
<p>zrange a4 0 -1</p>
</blockquote>
</li>
</ul>
</li>
<li><p>返回score值在min和max之间的成员</p>
<blockquote>
<p>zrangebyscore key min max</p>
</blockquote>
</li>
<li><p>返回成员member的score值</p>
<blockquote>
<p>zscore key member</p>
</blockquote>
<ul>
<li><p>例4：获取键’a4’的集合中元素’zhangsan’的权重</p>
<blockquote>
<p>zscore a4 zhangsan</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h5 id="删除-3"><a href="#删除-3" class="headerlink" title="删除"></a>删除</h5><ul>
<li><p>删除指定元素</p>
<blockquote>
<p>zrem key member1 member2 …</p>
</blockquote>
</li>
<li><p>删除权重在指定范围的元素</p>
<blockquote>
<p>zremrangebyscore key min max</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>布隆过滤器</title>
    <url>/2019/12/15/%E7%AE%97%E6%B3%95/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
    <content><![CDATA[<h1 id="详解布隆过滤器的原理，使用场景"><a href="#详解布隆过滤器的原理，使用场景" class="headerlink" title="详解布隆过滤器的原理，使用场景"></a>详解布隆过滤器的原理，使用场景</h1><h2 id="1-布隆过滤器简介"><a href="#1-布隆过滤器简介" class="headerlink" title="1. 布隆过滤器简介"></a>1. <strong>布隆过滤器简介</strong></h2><p>布隆过滤器的本质是一种数据结构。</p>
<p>特点：高效插入、查询；</p>
<p>场景：想知道某些值是否一定不存在或者可能存在。即布隆过滤器来加速查找和判断是否存在</p>
<p>优点：高效、占用空间更少</p>
<p>缺点：返回的结果是概率性的，而不是确切的。</p>
<h2 id="2-布隆过滤器数据结构"><a href="#2-布隆过滤器数据结构" class="headerlink" title="2. 布隆过滤器数据结构"></a>2. <strong>布隆过滤器数据结构</strong></h2><p>布隆过滤器是一个 bit 向量或者说 bit 数组。</p>
<p>映射一个值到布隆过滤器，需要使用<strong>多个不同的哈希函数</strong>生成<strong>多个哈希值，</strong>并对每个生成的哈希值指向的 bit 位置 1。</p>
<p>查询：目标值对应多个hash值，判断布隆过滤器对应位置是否都为1，全为1则可能存在，否则一定不存在。</p>
<h2 id="3-难点"><a href="#3-难点" class="headerlink" title="3. 难点"></a>3. 难点</h2><p>如何设置 <strong>hash函数的个数</strong> k, 以及**布隆过滤器长度 **m</p>
<h2 id="4-应用"><a href="#4-应用" class="headerlink" title="4. 应用"></a>4. 应用</h2><p>利用布隆过滤器减少磁盘 IO，或者网络请求（因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。）</p>
<p>布隆过滤器来加速查找和判断是否存在。</p>
<h2 id="5-Spark-BloomFilter"><a href="#5-Spark-BloomFilter" class="headerlink" title="5. Spark BloomFilter"></a>5. Spark BloomFilter</h2><p>spark官方封装了基于DataFrame的布隆过滤器，使用起来相当方便。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .appName(<span class="string">&quot;BloomFilterDemo&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"><span class="keyword">val</span> output = <span class="string">&quot;D:\\testData\\spark\\bloomfilter.txt&quot;</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">val</span> df = spark.sparkContext.parallelize(<span class="type">Seq</span>(</span><br><span class="line">    <span class="type">General</span>(<span class="string">&quot;Person A&quot;</span>,<span class="number">227</span>), <span class="type">General</span>(<span class="string">&quot;Person B&quot;</span>,<span class="number">188</span>), <span class="type">General</span>(<span class="string">&quot;Person C&quot;</span>,<span class="number">100</span>)</span><br><span class="line">)).toDF</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd = spark.sparkContext.parallelize(<span class="type">Seq</span>(<span class="string">&quot;Person A&quot;</span>,<span class="string">&quot;Person B&quot;</span>,<span class="string">&quot;Person C&quot;</span>,<span class="string">&quot;Person D&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成bloomFilter</span></span><br><span class="line"><span class="keyword">val</span> bf = df.stat.bloomFilter(<span class="string">&quot;name&quot;</span>,<span class="number">20</span>L,<span class="number">0.01</span>)</span><br><span class="line"><span class="comment">// 将bloomFilter写出</span></span><br><span class="line"><span class="keyword">val</span> bos = <span class="keyword">new</span> <span class="type">BufferedOutputStream</span>(<span class="keyword">new</span> <span class="type">FileOutputStream</span>(output))</span><br><span class="line">bf.writeTo(bos)</span><br><span class="line">bos.close()</span><br><span class="line"><span class="comment">// 将bloomFilter读入</span></span><br><span class="line"><span class="keyword">val</span> bis = <span class="keyword">new</span> <span class="type">BufferedInputStream</span>(<span class="keyword">new</span> <span class="type">FileInputStream</span>(output))</span><br><span class="line"><span class="keyword">val</span> filter = <span class="type">BloomFilter</span>.readFrom(bis)</span><br><span class="line">bis.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判定数据是否存在</span></span><br><span class="line"><span class="keyword">val</span> resultRdd = rdd.map(x=&gt;(x,filter.mightContainString(x)))</span><br><span class="line">resRdd.foreach(println)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式之美</title>
    <url>/2018/01/21/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BE%8E/</url>
    <content><![CDATA[<h1 id="设计模式之美"><a href="#设计模式之美" class="headerlink" title="设计模式之美"></a>设计模式之美</h1><p>设计模式 设计原则 设计思想</p>
<ul>
<li>如何分层、分模块？</li>
<li>应该怎么划分类？</li>
<li>每个类应该具有哪些属性、方法？</li>
<li>怎么设计类之间的交互？</li>
<li>该用继承还是组合？</li>
<li>该使用接口还是抽象类？</li>
<li>怎样做到解耦、高内聚低耦合？</li>
<li>该用单例模式还是静态方法？</li>
<li>用工厂模式创建对象还是直接 new 出来？</li>
<li>如何避免引入设计模式提高扩展性的同时带来的降低可读性问题？</li>
</ul>
<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ul>
<li>应对面试中的设计模式相关的问题</li>
<li>告别被人吐槽的烂代码</li>
<li>提高复杂代码的设计能力</li>
<li>为了 读源码，框架学习事半功倍</li>
<li>为职业发展铺垫</li>
</ul>
<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><ul>
<li>Talk is cheap, show me the code.</li>
</ul>
<h4 id="代码评价标准（常用）"><a href="#代码评价标准（常用）" class="headerlink" title="代码评价标准（常用）"></a>代码评价标准（常用）</h4><ul>
<li><p>可维护性</p>
</li>
<li><p>可读性</p>
</li>
<li><p>可扩展性</p>
</li>
<li><p>灵活性</p>
</li>
<li><p>简洁性（简单、复杂）</p>
</li>
<li><p>可复用性</p>
</li>
<li><p>可测试性</p>
</li>
</ul>
<h4 id="KISS原则"><a href="#KISS原则" class="headerlink" title="KISS原则"></a>KISS原则</h4><p><em>在设计当中应当注重简约的原则。</em>Keep it Simple and Stupid</p>
<h4 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h4><ul>
<li>面向对象的四大特性：封装、抽象、继承、多态</li>
<li>面向对象编程与面向过程编程的区别和联系</li>
<li>面向对象分析、面向对象设计、面向对象编程</li>
<li>接口和抽象类的区别以及各自的应用场景</li>
<li>基于接口而非实现编程的设计思想</li>
<li>多用组合少用继承的设计思想</li>
<li>面向过程的贫血模型和面向对象的充血模型</li>
</ul>
<h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul>
<li>SOLID 原则 -SRP 单一职责原则</li>
<li>SOLID 原则 -OCP 开闭原则</li>
<li>SOLID 原则 -LSP 里式替换原则</li>
<li>SOLID 原则 -ISP 接口隔离原则</li>
<li>SOLID 原则 -DIP 依赖倒置原则</li>
<li>DRY 原则、KISS 原则、YAGNI 原则、LOD 法则</li>
</ul>
<h4 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h4><h5 id="1-创建型"><a href="#1-创建型" class="headerlink" title="1. 创建型"></a>1. 创建型</h5><p>常用的有：<strong>单例模式</strong>、<strong>工厂模式</strong>（工厂方法和抽象工厂）、<strong>建造者模式</strong>。不常用的有：原型模式。</p>
<h5 id="2-结构型"><a href="#2-结构型" class="headerlink" title="2. 结构型"></a>2. 结构型</h5><p>常用的有：<strong>代理模式</strong>、桥接模式、<strong>装饰者模式</strong>、<strong>适配器模式</strong>。</p>
<p>不常用的有：门面模式、组合模式、享元模式。</p>
<h5 id="3-结构型"><a href="#3-结构型" class="headerlink" title="3. 结构型"></a>3. 结构型</h5><p>常用的有：<strong>观察者模式</strong>、模板模式、<strong>策略模式</strong>、职责链模式、迭代器模式、状态模式。</p>
<p>不常用的有：访问者模式、备忘录模式、命令模式、解释器模式、中介模式。</p>
<p>总结： </p>
<p>面向对象是编程基础，</p>
<p>设计原则是指导原则，</p>
<p>设计模式是针对软件开发中经常遇到的一些设计问题，总结出来的一套解决方案或者设计思路。</p>
<p><img src="/../../../../images/1652696269355.png" alt="1652696269355"></p>
<h2 id="面向对象-1"><a href="#面向对象-1" class="headerlink" title="面向对象"></a>面向对象</h2><p>接口和抽象类如何选择</p>
<p>1.优先使用接口。<br>2.使用抽象类：既要约束子类的行为又要为子类提供公共的功能。</p>
<h2 id="设计原则-1"><a href="#设计原则-1" class="headerlink" title="设计原则"></a>设计原则</h2><h2 id="规范与重构"><a href="#规范与重构" class="headerlink" title="规范与重构"></a>规范与重构</h2><h2 id="设计模式-1"><a href="#设计模式-1" class="headerlink" title="设计模式"></a>设计模式</h2><h3 id="1-创建型-1"><a href="#1-创建型-1" class="headerlink" title="1. 创建型"></a>1. 创建型</h3><h3 id="2-结构性"><a href="#2-结构性" class="headerlink" title="2. 结构性"></a>2. 结构性</h3><h3 id="3-行为型"><a href="#3-行为型" class="headerlink" title="3. 行为型"></a>3. 行为型</h3>]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式理解</title>
    <url>/2018/01/25/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h3 id="策略模式-【Strategy-Pattern-】"><a href="#策略模式-【Strategy-Pattern-】" class="headerlink" title="策略模式 【Strategy Pattern 】"></a>策略模式 【Strategy Pattern 】</h3><p><strong>背景</strong>：刘备要到江东娶老婆了，走之前诸葛亮给赵云（伴郎）三个锦囊妙计，说是按天机拆开解决棘手问题。<br>分析：赵云就是一个干活的人，从根据时机取出锦囊中取出妙计，执行，然后解决问题。<br>总结：策略抽象成接口，不同策略是不同实现类。不同策列场景，传入不同的策列实现类，实现不同场景执行具体的策略行为。</p>
<h4 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805.png"></p>
<h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><p>什么是代理：我很忙，忙的没空理你，那你要找我呢就先找我的代理人，代理人知道被代理人能做哪些事情不能做哪些事情(两个人具备同一个接口)。简言之，就是给某一个对象提供一个代理，并由代理对象控制对原对象的引用。代理对象可以在客户端和目标对象之间起到中介的作用。<br><strong>背景</strong>：有同事出国或者朋友出国的情况下，我们经常会拖这位朋友帮忙带一些电子产品或化妆品等东西，这个场景中，出国的朋友就是一个代理，他是他朋友的一个代理。</p>
<h4 id="类图-1"><a href="#类图-1" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-2.png"></p>
<h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><h4 id="类图-2"><a href="#类图-2" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-3.png"></p>
<h3 id="多例模式"><a href="#多例模式" class="headerlink" title="多例模式"></a>多例模式</h3><p>多例模式也叫有上限的多例模式</p>
<h4 id="类图-3"><a href="#类图-3" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-4.png"></p>
<h3 id="工厂方法模式（简单工厂）"><a href="#工厂方法模式（简单工厂）" class="headerlink" title="工厂方法模式（简单工厂）"></a>工厂方法模式（简单工厂）</h3><p><strong>背景</strong>：女娲造人（黄，黑，白）</p>
<h4 id="类图-4"><a href="#类图-4" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-5.png"></p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h3><p>基于简单工厂的结果，突然发现人类忘记定义性别了（即更细致的产品类别划分）。基于之前的工作，如果改呢？</p>
<h4 id="类图-5"><a href="#类图-5" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-6.png"></p>
<h3 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h3><p>适配器模式把一个类的接口变换成客户端所期待的另一种接口。<br><strong>背景：</strong>在生活中，我们买的电器插头是2个孔的，但是我们买的插座只有三个孔的，此时我们就希望电器的插头可以转换为三个孔的就好，这样我们就可以直接把它插在插座上，此时三个孔插头就是客户端期待的另一种接口，自然两个孔的插头就是现有的接口，适配器模式就是用来完成这种转换的。</p>
<h4 id="类图-6"><a href="#类图-6" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-7.png"></p>
<h3 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h3><p>装饰者模式以对客户透明的方式动态地给一个对象附加上更多的责任，装饰者模式相比生成子类可以更灵活地增加功能。<br><strong>背景</strong>：以手机和手机配件的例子来演示装饰者模式的实现。</p>
<h4 id="类图-7"><a href="#类图-7" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-8.png"></p>
<h3 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h3><p>有时需要创建一个复杂对象，并且这个复杂对象由其各部分子对象通过一定的步骤组合而成。例如一个采购系统中，如果需要采购员去采购一批电脑。我们可以把电脑的各个组件的组装过程封装到一个建造者类对象里，建造者只要负责返还给客户端全部组件都建造完毕的产品对象就可以了。<br><strong>背景</strong>：电脑城的老板是直接与客户（也就是指采购员）联系的，然而电脑的组装是由老板指挥装机人员去把电脑的各个部件组装起来。这里的电脑就是产品。装机人员就是建造者。</p>
<h4 id="类图-8"><a href="#类图-8" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-9.png"></p>
<h3 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h3><p>我们经常会遇到处理简单对象和复合对象的情况，例如对操作系统中目录的处理就是这样的一个例子，因为目录可以包括单独的文件，也可以包括文件夹，文件夹又是由文件组成的，由于简单对象和复合对象在功能上区别，导致在操作过程中必须区分简单对象和复合对象，这样就会导致客户调用带来不必要的麻烦，然而作为客户，它们希望能够始终一致地对待简单对象和复合对象。然而组合模式就是解决这样的问题。<br><strong>组合模式允许你将对象组合成树形结构来表现”部分-整体“的层次结构，使得客户以一致的方式处理单个对象以及对象的组合。</strong><br><strong>背景</strong>：图形可以由一些基本图形元素组成（如直线，圆等），也可以由一些复杂图形组成（由基本图形元素组合而成），为了使客户对基本图形和复杂图形的调用保持一致，我们使用组合模式来达到整个目的。</p>
<h4 id="类图-9"><a href="#类图-9" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-10.png"></p>
<h4 id="组合模式的优缺点："><a href="#组合模式的优缺点：" class="headerlink" title="组合模式的优缺点："></a>组合模式的优缺点：</h4><p>优点：<br>1、组合模式使得客户端代码可以一致地处理对象和对象容器，无需关系处理的单个对象，还是组合的对象容器。<br>2、将”客户代码与复杂的对象容器结构“解耦。<br>3、可以更容易地往组合对象中加入新的构件。<br>缺点：<br>使得设计更加复杂。客户端需要花更多时间理清类之间的层次关系。（这个是几乎所有设计模式所面临的问题）。</p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象，这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己的行为。<br><strong>背景</strong>：只要对订阅号进行关注的客户端，如果订阅号有什么更新，就会直接推送给订阅了的用户。</p>
<h4 id="类图-10"><a href="#类图-10" class="headerlink" title="类图"></a>类图</h4><p><img src="/../../../../images/20220805-11.png"></p>
<hr>
<p>迭代器模式 137</p>
<p>访问者模式 210</p>
<p>状态模式 236</p>
<p>原型模式 255</p>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构基础</title>
    <url>/2019/01/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="1-栈"><a href="#1-栈" class="headerlink" title="1. 栈"></a>1. 栈</h3><ul>
<li>栈是元素的集合，其包含了两个基本操作：push 操作可以用于将元素压入栈，pop 操作可以将栈顶元素移除。</li>
<li>遵循后入先出原则 (LIFO)。</li>
<li>时间复杂度:<ul>
<li>搜索: <code>O(n)</code></li>
<li>插入: <code>O(1)</code></li>
<li>移除: <code>O(1)</code></li>
</ul>
</li>
</ul>
<h4 id="栈的实现"><a href="#栈的实现" class="headerlink" title="栈的实现"></a>栈的实现</h4><table>
<thead>
<tr>
<th align="center">接口</th>
<th align="center">说明</th>
<th align="center">复杂度</th>
</tr>
</thead>
<tbody><tr>
<td align="center">void push(E e)</td>
<td align="center">向栈中加入元素</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">E pop()</td>
<td align="center">弹出栈顶元素</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">E peek()</td>
<td align="center">查看栈顶元素</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">int getSize()</td>
<td align="center">获取栈中元素个数</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">boolean isEmpty()</td>
<td align="center">判断栈是否为空</td>
<td align="center">o(1)</td>
</tr>
</tbody></table>
<p>栈的实现可以通过 <strong>数组</strong> 或者 <strong>链表</strong> 实现，在这里我们使用 数组来实现上述接口。</p>
<p>在栈的设计中，用户只关注栈顶元素存取和栈长度。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//栈的实现</span><br><span class="line">public class ArrayStack&lt;E&gt; implements Stack&lt;E&gt;&#123;</span><br><span class="line">	Array&lt;E&gt; array;    </span><br><span class="line">	public ArrayStack(int capacity)&#123;        </span><br><span class="line">		array = new Array&lt;&gt;(capacity);    </span><br><span class="line">	&#125; </span><br><span class="line">    </span><br><span class="line">	public ArrayStack()&#123;        </span><br><span class="line">		array = new Array&lt;&gt;();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public int getSize()&#123;        </span><br><span class="line">		return array.getSize();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public int isEmpty()&#123;        </span><br><span class="line">		return array.isEmpty();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public void push(E e)&#123;        </span><br><span class="line">		array.addLast(e);    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public E pop()&#123;        </span><br><span class="line">		return array.removeLast();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public E peek()&#123;        </span><br><span class="line">		return array.getLast();    </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>\</p>
<h3 id="2-链表"><a href="#2-链表" class="headerlink" title="2. 链表"></a>2. 链表</h3><ul>
<li><p>链表即是由节点组成的线性集合，每个节点可以利用指针指向其他节点。它是一种包含了多个节点的、能够用于表示序列的数据结构。</p>
</li>
<li><p><strong>单向链表</strong>: 链表中的节点仅指向下一个节点，并且最后一个节点指向空。</p>
</li>
<li><p><strong>双向链表</strong>: 其中每个节点具有两个指针 p、n，使得 p 指向先前节点并且 n 指向下一个节点，最后一个节点的 n 指针指向 null。</p>
</li>
<li><p><strong>循环链表</strong>：每个节点指向下一个节点并且最后一个节点指向第一个节点的链表。</p>
</li>
<li><p>时间复杂度:</p>
<ul>
<li>搜索: <code>O(n)</code></li>
<li>插入: <code>O(1)</code></li>
<li>移除: <code>O(1)</code></li>
</ul>
</li>
<li><p>定义数据结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class Node&#123;     </span><br><span class="line">	int value;//数据域，以int为例     </span><br><span class="line">	Node next;//指针域，指向下一个节点 </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>链表插入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//p节点后插入值为i的节点</span><br><span class="line">void insert_Node(Node p, int i)&#123;    </span><br><span class="line">	Node node = new Node();    </span><br><span class="line">	node.value = i;    </span><br><span class="line">	node.next = p.next;    </span><br><span class="line">	p.next = node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>链表删除</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void delete_Node(Node pHead, int data)&#123;    </span><br><span class="line">	...            </span><br><span class="line">	</span><br><span class="line">	Node pCur;//指向当前节点    </span><br><span class="line">	Node pPre;//指向当前节点的上一个节点    </span><br><span class="line">	if(pCur-&gt;data==data)&#123;//元素比较        </span><br><span class="line">		//将当前节点的前驱节点的next指向当前节点的后继节点        </span><br><span class="line">		...        </span><br><span class="line">		pPre-&gt;next = pCur-&gt;next;        </span><br><span class="line">		...    </span><br><span class="line">	&#125;    </span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>### 3. 队列</p>
<ul>
<li>队列是元素的集合，其包含了两个基本操作：enqueue 操作可以用于将元素插入到队列中，而 dequeue 操作则是将元素从队列中移除。</li>
<li>遵循先入先出原则 (FIFO)。</li>
<li>时间复杂度:<ul>
<li>搜索: <code>O(n)</code></li>
<li>插入: <code>O(1)</code></li>
<li>移除: <code>O(1)</code></li>
</ul>
</li>
<li>队列的应用可以在播放器上的播放列表，数据流对象，异步的数据传输结构(文件IO，管道通讯，套接字等)上体现，当然最直观的的就是排队了。</li>
</ul>
<h3 id="3-队列的实现"><a href="#3-队列的实现" class="headerlink" title="3. 队列的实现"></a>3. 队列的实现</h3><table>
<thead>
<tr>
<th align="center">接口</th>
<th align="center">说明</th>
<th align="center">复杂度</th>
</tr>
</thead>
<tbody><tr>
<td align="center">void enqueue(E e)</td>
<td align="center">入队</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">E dequeue()</td>
<td align="center">出队</td>
<td align="center">o(n)</td>
</tr>
<tr>
<td align="center">E getFront()</td>
<td align="center">获取队首元素</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">int getSize()</td>
<td align="center">获取队列元素个数</td>
<td align="center">o(1)</td>
</tr>
<tr>
<td align="center">boolean isEmpty()</td>
<td align="center">判断队列是否为空</td>
<td align="center">o(1)</td>
</tr>
</tbody></table>
<ul>
<li>入队是从队尾开始，有可能触发resize，因此均摊下来是O(1)。出队是在队首，数组实现每次都要挪动所有元素,O(n)。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//队列的实现</span><br><span class="line">public class ArrayQueue&lt;E&gt; implements Queue&lt;E&gt;&#123;    </span><br><span class="line">	Array&lt;E&gt; array;    </span><br><span class="line">	</span><br><span class="line">	public ArrayQueue(int capacity)&#123;        </span><br><span class="line">		array = new Array&lt;&gt;(capacity);    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	public ArrayQueue()&#123;        </span><br><span class="line">		array = new Array&lt;&gt;();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public int getSize()&#123;        </span><br><span class="line">		return array.getSize();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public int isEmpty()&#123;        </span><br><span class="line">		return array.isEmpty();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public void enqueue(E e)&#123;        </span><br><span class="line">		array.addLast(e);    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public E dequeue()&#123;        </span><br><span class="line">		return array.removeLast();    </span><br><span class="line">	&#125;    </span><br><span class="line">	</span><br><span class="line">	@override    </span><br><span class="line">	public E getFront()&#123;        </span><br><span class="line">		return array.getFirst();    </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-二叉查找树"><a href="#4-二叉查找树" class="headerlink" title="4. 二叉查找树"></a>4. 二叉查找树</h3><ul>
<li>二叉搜索树（BST）是一种特殊的二叉树，其任何节点中的值都会大于或者等于其左子树中存储的值并且小于或者等于其右子树中存储的值。</li>
<li>时间复杂度:<ul>
<li>索引: <code>O(log(n))</code></li>
<li>搜索: <code>O(log(n))</code></li>
<li>插入: <code>O(log(n))</code></li>
<li>删除: <code>O(log(n))</code></li>
</ul>
</li>
</ul>
<p><strong>二分查找法定义</strong>:是一种在有序数组中查找某一特定元素的搜索算法。这种搜索算法每一次比较都使搜索范围缩小一半。</p>
<p>注意：二分查找的前提是数列必须是有序的。</p>
<ul>
<li>二叉查找树也可叫做二分查找树。它不仅可以查找数据，还可以高效地插入、删除数据。</li>
<li>特点：每个节点的key值大于左子节点，小于右子节点。<strong>它不一定是完全的二叉树</strong>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Node &#123;  E e;  Node left;  // 左孩子  Node right; // 右孩子&#125;</span><br></pre></td></tr></table></figure>

<p>二叉查找树有两个属性：</p>
<ul>
<li><strong>所有节点都比左子树中的节点大</strong></li>
<li><strong>所有节点都小于右子树中的节点</strong></li>
</ul>
<p>通过这两个属性，可以推断出以下结论：</p>
<ul>
<li>二叉查找树最小的节点位于最顶端节点的最左边子树行的末尾</li>
<li>二叉查找树的最大节点位于最顶端节点的最右边的子树行的末尾</li>
</ul>
<h4 id="添加元素操作"><a href="#添加元素操作" class="headerlink" title="添加元素操作"></a>添加元素操作</h4><p>核心思想:从根节点开始找插入的位置，满足二叉搜索树的特性，比左子节点大，比右子节点小.</p>
<h4 id="删除元素操作"><a href="#删除元素操作" class="headerlink" title="删除元素操作"></a>删除元素操作</h4><p>步骤：</p>
<ul>
<li>找到左子树中所有节点的最大的节点(左子树的最右节点)</li>
<li>将这个节点赋值到删除节点的位置</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>使用二叉查找树可以实现高效搜索。但是如果树接近形成直线，那么搜索效率将极其差，变成了线性搜索。</li>
<li>因此二叉查找树就需要进行改进为平衡二叉树，比较常见的 Balanced Binary Tree有：<ul>
<li>AVL tree</li>
<li>红黑树</li>
</ul>
</li>
</ul>
<h3 id="7-哈希"><a href="#7-哈希" class="headerlink" title="7. 哈希"></a>7. 哈希</h3><ul>
<li>哈希能够将任意长度的数据映射到固定长度的数据。哈希函数返回的即是哈希值，如果两个不同的键得到相同的哈希值，即将这种现象称为碰撞。</li>
<li><strong>Hash Map</strong>: Hash Map 是一种能够建立起键与值之间关系的数据结构，Hash Map 能够使用哈希函数将键转化为桶或者槽中的下标，从而优化对于目标值的搜索速度。</li>
<li>碰撞解决<ul>
<li><strong>链地址法（Separate Chaining）</strong>: 链地址法中，每个桶是相互独立的，包含了一系列索引的列表。搜索操作的时间复杂度即是搜索桶的时间（固定时间）与遍历列表的时间之和。</li>
<li><strong>开地址法（Open Addressing）</strong>: 在开地址法中，当插入新值时，会判断该值对应的哈希桶是否存在，如果存在则根据某种算法依次选择下一个可能的位置，直到找到一个尚未被占用的地址。所谓开地址法也是指某个元素的位置并不永远由其哈希值决定。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>算法与数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理</title>
    <url>/2018/01/21/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="1-内存地址编码范围？"><a href="#1-内存地址编码范围？" class="headerlink" title="1. 内存地址编码范围？"></a>1. 内存地址编码范围？</h1><p>计算机内存的地址编码是以字节为单位的，即每字节内存都有个编号，8个二进制位为一个字节。</p>
<p>以4G的内存的地址编码范围为例：</p>
<ul>
<li><p>4G &#x3D; 4 <em>1024</em> 1024 <em>1024</em> 8 &#x3D; 2^32</p>
<p>因此编码范围 0 -&gt; 2^32 - 1</p>
<p>16进制表示：0x00000000 -&gt; 0xffffffff</p>
</li>
</ul>
<p>那反过来问：<strong>为什么理论上32位系统最大只支持4G内存呢</strong>？</p>
<p>答:<strong>32位系统的“32”位是指cpu的地址总线是32根</strong>，这样就可以表示0~2^32-1一共2^32个地址，而地址编码是以字节为单位，所以内存最大2^32个字节，即4G</p>
<h1 id="2-8位二进制有符号数表示范围"><a href="#2-8位二进制有符号数表示范围" class="headerlink" title="2. 8位二进制有符号数表示范围"></a>2. 8位二进制有符号数表示范围</h1><p>8位二进制原码的表示范围：-127～+127<br>8位二进制反码的表示范围：-127～+127<br>8位二进制补码的表示范围：-128～+127</p>
<p>这里主要讲补码表示。因为8位数，除去一位符号位，每一位只有0或1，那就有128种情况，每种情况按权值计算，就是0到127，加上正负号，就是256个数，但是存在+0和-0两个0。0是没有正负的，-0（10000000）看作无符号数就是128，而且第一位是1，因此规定-0用来表示-128。</p>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>Git操作手册</title>
    <url>/2019/12/18/Git/</url>
    <content><![CDATA[<h1 id="Git基础"><a href="#Git基础" class="headerlink" title="Git基础"></a>Git基础</h1><h2 id="git一些参数解释"><a href="#git一些参数解释" class="headerlink" title="git一些参数解释"></a>git一些参数解释</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//git中一些选项解释:</span><br><span class="line"></span><br><span class="line">-d</span><br><span class="line">--delete：删除</span><br><span class="line"></span><br><span class="line">-D</span><br><span class="line">--delete --force的快捷键</span><br><span class="line"></span><br><span class="line">-f</span><br><span class="line">--force：强制</span><br><span class="line"></span><br><span class="line">-m</span><br><span class="line">--move：移动或重命名</span><br><span class="line"></span><br><span class="line">-M</span><br><span class="line">--move --force的快捷键</span><br><span class="line"></span><br><span class="line">-r</span><br><span class="line">--remote：远程</span><br><span class="line"></span><br><span class="line">-a</span><br><span class="line">--all：所有</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>附：官方中文文档<br><a href="https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%85%B3%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6">https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%85%B3%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6</a></p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git init</span><br><span class="line">git remote add origin git@git.hypers.com:hadoop/insight.git   //添加远程库</span><br><span class="line"></span><br><span class="line">Unknown SSL protocol error in connection to xxx:443</span><br><span class="line">git config --global http.proxy 127.0.0.1:7890</span><br><span class="line">git config --global http.sslVerify false</span><br><span class="line"></span><br><span class="line">拉取分支到本地</span><br><span class="line">git pull origin dev-1.2.0</span><br><span class="line">git pull origin release-1.2.1</span><br><span class="line"></span><br><span class="line">切换分支操作：</span><br><span class="line">查看所有</span><br><span class="line">git branch -a</span><br><span class="line">查看当前</span><br><span class="line">git branch</span><br><span class="line">切换分支</span><br><span class="line">git checkout dev-1.2.0</span><br><span class="line">拉远程仓库所有分支、指定分支</span><br><span class="line">git fetch origin [branch]</span><br><span class="line"></span><br><span class="line">拉远程仓库指定分支，并合并</span><br><span class="line">git pull origin &lt;branch&gt;</span><br></pre></td></tr></table></figure>



<h2 id="git-fetch-amp-git-pull"><a href="#git-fetch-amp-git-pull" class="headerlink" title="git fetch &amp; git pull"></a>git fetch &amp; git pull</h2><p>git fetch 是将远程主机的最新内容拉到本地，并未合并。</p>
<p>git pull 是 将远程主机的最新内容拉下来后直接合并。即：<code>git pull = git fetch + git merge</code> 但是这样可能会冲突。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git fetch:</span><br><span class="line">git fetch origin(远程主机名)	   全部更新取回本地,</span><br><span class="line">git fetch origin dev(分支名)	取回特定分支</span><br><span class="line">git log -p FETCH_HEAD   	  取回更新后，会返回一个FETCH_HEAD，可以查看取回的更新信息</span><br><span class="line">git merge FETCH_HEAD    	  将拉取下来的最新内容合并到当前所在的分支中</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git pull:</span><br><span class="line">git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;</span><br><span class="line">git pull origin dev  如果拉取某个分支并且与当前分支合并，可以：以及后面的</span><br></pre></td></tr></table></figure>



<h2 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">如果当前分支只有一个远程分支，那么主机名都可以省略，形如 git push.</span><br><span class="line"></span><br><span class="line">常用命令：</span><br><span class="line">git push -u origin dev  如果当前分支与多个主机存在追踪关系，则可以使用 -u 参数指定一个默认主机，这样后面就可以不加任何参数使用git push</span><br><span class="line"></span><br><span class="line">git push --all origin   不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机.</span><br><span class="line">git push --force origin git push  如果本地版本库比远程服务器上的低，强制push。不建议使用</span><br><span class="line">git push origin --tags   git push 的时候不会推送标签，如果一定要推送标签的话那么可以使用这个命令</span><br><span class="line"></span><br><span class="line">一般使用</span><br><span class="line">git push origin dev(分支名)</span><br></pre></td></tr></table></figure>



<h2 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用命令</span><br><span class="line">git remote update origin --prune  //更新远程分支列表</span><br><span class="line"></span><br><span class="line">git branch //查看本地所有分支 </span><br><span class="line"></span><br><span class="line">git branch -r //查看远程所有分支</span><br><span class="line"></span><br><span class="line">git branch -a //查看本地和远程的所有分支</span><br><span class="line"></span><br><span class="line">git branch &lt;branchname&gt; //新建分支</span><br><span class="line"></span><br><span class="line">git branch -d &lt;branchname&gt; //删除本地分支</span><br><span class="line"></span><br><span class="line">git branch -d -r &lt;branchname&gt; //删除远程分支，删除后还需推送到服务器</span><br><span class="line">git push origin:&lt;branchname&gt;  //删除后推送至服务器</span><br><span class="line">git push origin --delete &lt;branchname&gt;  //直接删除远程分支  一步到位</span><br><span class="line"></span><br><span class="line">git branch -m &lt;oldbranch&gt; &lt;newbranch&gt; //重命名本地分支</span><br></pre></td></tr></table></figure>



<h2 id="git-tag"><a href="#git-tag" class="headerlink" title="git tag"></a>git tag</h2><p>tag 和 branch的区别：</p>
<p>tag就像是一个里程碑，branch是新的一条线。稳定版本备份用tag，新功能多人开发用branch（开发完成后merge到master）。tag的本质就是给commit的 hash校验和 取的一个名字，比较直观，方便记忆和使用。</p>
<p>tag分两类：轻量标签，附注标签</p>
<ul>
<li><p>轻量标签很像一个不会改变的分支——它只是某个特定提交的引用。</p>
</li>
<li><p>附注标签是存储在 Git 数据库中的一个完整对象。包括打标签者的名字、电子邮件地址、日期时间， 此外还有一个标签信息等。</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git tag [-l]   列出已有的标签</span><br><span class="line">git tag -l &quot;v1.8.5*&quot;    模糊查询</span><br><span class="line">git checkout v2.0   切换到该标签，查看文件。注：这会使你的仓库处于“分离头指针（detached HEAD）”的状态</span><br><span class="line">	在“分离头指针”状态下，你的新提交将不属于任何分支，并且将无法访问（除非给定hash）</span><br><span class="line">	在该标签下，如果要修复bug，通常基于标签新建一个分支：git checkout -b dev1.3 v2.0</span><br><span class="line">	这之后的提交就会在新分支。</span><br><span class="line">	总之：基于标签的check out 不要做任何修改。</span><br><span class="line"></span><br><span class="line">附注标签：</span><br><span class="line">git tag -a v1.4 -m &quot;my version 1.4&quot;   标签版本v1.4</span><br><span class="line">git show v1.4   可以看到标签信息和与之对应的提交信息。</span><br><span class="line"></span><br><span class="line">轻量标签：</span><br><span class="line">git tag v1.4.1   轻量标签v1.4.1</span><br><span class="line">git show v1.4.1  只会显示提交信息</span><br><span class="line"></span><br><span class="line">删除标签：</span><br><span class="line">git tag -d tagname  这个只会删除本地标签</span><br><span class="line">	git push &lt;remote&gt; :refs/tags/&lt;tagname&gt;  使用该命令更新变成仓库</span><br><span class="line">	如git push origin :refs/tags/v1.4.1</span><br><span class="line">git push origin --delete &lt;tagname&gt;   本地和远程都删除。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">后期打标签：对过去的提交打标签</span><br><span class="line">git log --pretty=oneline</span><br><span class="line">git tag -a v1.2 9fceb02（提交的校验和）</span><br><span class="line"></span><br><span class="line">共享标签：</span><br><span class="line">git push并不会推送 tag, 如果想共享标签可以使用： git push origin &lt;tagname&gt;</span><br><span class="line">共享全部标签：git push origin --tags</span><br></pre></td></tr></table></figure>



<h2 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dev分支 merge到 master：</span><br><span class="line">git checkout master</span><br><span class="line">git pull origin master</span><br><span class="line">#--no-ff：不使用fast-forward方式合并，保留分支的commit历史</span><br><span class="line">git merge --no-ff dev</span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果合并失败，想要一键回滚到合并前：</span><br><span class="line">git reset --merge</span><br></pre></td></tr></table></figure>



<h2 id="git-remote"><a href="#git-remote" class="headerlink" title="git remote"></a>git remote</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote -v	//显示所有远程仓库信息： 远程主机名(如origin) 地址</span><br><span class="line">git remote add [shortname] [url]	//添加远程版本库,shortname即远程主机名（如origin）</span><br><span class="line">git remote prune origin  //刷新本地仓库, 与远程仓库的保持同步. 即删除本地有但在远程库已经不存在的分支</span><br><span class="line">git remote update origin --prune   //更新远程分支列表</span><br><span class="line"></span><br><span class="line">git remote rm name  # 删除远程仓库</span><br><span class="line">git remote rename old_name new_name  # 修改仓库名</span><br></pre></td></tr></table></figure>



<h2 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h2><p>使用场景：有时候，进行了错误的提交，但是还没有push到远程分支，想要撤销本次提交，可以使用git reset –-soft&#x2F;hard命令。</p>
<p>二者区别：</p>
<ul>
<li>git reset –-soft：回退到某个版本，只回退了commit的信息，不会恢复到index file一级。如果还要提交，直接commit即可；</li>
<li>git reset -–hard：彻底回退到某个版本，本地的源码也会变为上一个版本的内容，撤销的commit中所包含的更改被冲掉；</li>
</ul>
<p>使用过程：</p>
<ul>
<li>git status</li>
<li>git log  &#x2F;    git log –oneline</li>
<li>git reset –-soft 回退版本号（注意别少回退了，上次版本之前的版本）</li>
<li>git reset –hard origin&#x2F;dev-1.3.0 放弃本地修改，与远程仓库保持一致</li>
</ul>
<h2 id="git-stash"><a href="#git-stash" class="headerlink" title="git stash"></a>git stash</h2><p>使用场景：当切换分支的时候，如果有未提交的变更记录，此时系统会阻止你切换分支，解决方法有两种。</p>
<ol>
<li>commit后，git checkout 分支名</li>
<li>git stash 将数据存到缓存，再切换分支。等修改完毕后，git stash apply切换回来</li>
</ol>
<p>git stash 适用场景：</p>
<ol>
<li>有一个类，想删掉他，但又怕以后会用到。考虑使用git stash</li>
<li>在分支1改了代码，但这时分支2有需要修改的地方。常规操作：提交分支1的变更到本地仓库，切换到分支2然后修改，完成后再切回分支1. 这样会留下不必要的提交记录<br>如果不想提交完成一半的代码，却不得不切换分支。使用git stash</li>
</ol>
<p>命令集：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git stash list 查看stash缓存;</span><br><span class="line"></span><br><span class="line">git stash save ‘msg’  缓存当前分支;</span><br><span class="line"></span><br><span class="line">git stash pop stash@&#123;id&#125;    将缓存堆栈中的第一个stash删除，并将对应修改应用到当前的工作目录下;</span><br><span class="line"></span><br><span class="line">git stash apply stash@&#123;id&#125;  将缓存堆栈中的stash 应用到工作目录中，但并不删除stash;</span><br><span class="line"></span><br><span class="line">git stash drop [stash@&#123;id&#125;]  删除指定缓存, 如果不加stash编号，默认的就是删除最新的，也就是编号为0的那个;</span><br><span class="line"></span><br><span class="line">git stash clear  清空缓存;</span><br><span class="line"></span><br><span class="line">--查看指定stash的diff</span><br><span class="line"></span><br><span class="line">git stash show 查看第一个;</span><br><span class="line"></span><br><span class="line">git stash show stash@&#123;id&#125; 查看指点stash;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">特别的：</span><br><span class="line">默认情况下，git stash会缓存下列文件：  添加到暂存区的修改（staged changes）即已经add的文件，   Git跟踪的但并未添加到暂存区的修改（unstaged changes）</span><br><span class="line">			不会缓存一下文件：在工作目录中新的文件（untracked files），  被忽略的文件（ignored files）即.gitignore忽略的文件</span><br><span class="line"></span><br><span class="line">git stash save -u name  可以stash untracked文件</span><br><span class="line">git stash save -a name  可以stash当前目录下的所有修改。</span><br></pre></td></tr></table></figure>

<h2 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h2><p>git commit -m ‘desc’<br>使用场景：提交变更</p>
<p>git commit –amend –no-edit<br>使用场景：上次提交之后，发现漏了点东西。但是你又不想有提交两次记录。即本次修改追加到上次修改，但是不变动commit message<br>git commit –amend -m ‘new desc’<br>本次修改追加到上次修改，并修改commit message</p>
<h2 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h2><p>git add [file1] [file2] …<br>git add [dir]<br>git add .<br>分别将单文件，目录以及当前目录下所有文件 添加到 暂存区</p>
<p>git commit -m [message]<br>将暂存区所有信息提交到本地仓库</p>
<p>git commit [file1] [file2] … -m [message]</p>
<h2 id="关于-refs-x2F-for"><a href="#关于-refs-x2F-for" class="headerlink" title="关于 refs&#x2F;for"></a>关于 refs&#x2F;for</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">refs/for 的意义在于我们提交代码到服务器之后是需要经过code review 之后才能进行merge的，而refs/heads 不需要</span><br></pre></td></tr></table></figure>



<h2 id="关于git提交格式"><a href="#关于git提交格式" class="headerlink" title="关于git提交格式"></a>关于git提交格式</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Git-Flow"><a href="#Git-Flow" class="headerlink" title="Git Flow"></a>Git Flow</h1><h2 id="1-Git-Flow常用分支"><a href="#1-Git-Flow常用分支" class="headerlink" title="1. Git Flow常用分支"></a>1. Git Flow常用分支</h2><h3 id="1-Master-分支"><a href="#1-Master-分支" class="headerlink" title="1. Master 分支"></a>1. Master 分支</h3><p>这个分支是最近发布到生产环境的代码，即最近发布的Release， 这个分支只能从其他分支合并，不能在这个分支直接修改。</p>
<h3 id="2-Dev-分支"><a href="#2-Dev-分支" class="headerlink" title="2. Dev 分支"></a>2. Dev 分支</h3><p>这个分支是我们是我们的主开发分支，包含所有要发布到下一个Release的代码，以及合并其他分支，比如Feature分支。</p>
<h3 id="3-Feature-分支"><a href="#3-Feature-分支" class="headerlink" title="3. Feature 分支"></a>3. Feature 分支</h3><p> 这个分支主要是用来开发一个新的功能，一旦开发完成，我们会 合并回 Develop分支，并进入下一个Release。</p>
<h3 id="4-Release-分支"><a href="#4-Release-分支" class="headerlink" title="4. Release 分支"></a>4. Release 分支</h3><p>发布一个新Release的时候，我们基于Develop分支创建一个Release分支，完成Release后，我们合并到Master和Develop分支</p>
<h3 id="5-Hotfix-分支"><a href="#5-Hotfix-分支" class="headerlink" title="5. Hotfix 分支"></a>5. Hotfix 分支</h3><p>已发布的版本发现新的bug的时候，我们需要创建一个Hotfix, 完成Hotfix后，我们合并回Master和Develop分支，所以Hotfix的改动会进入下一个Release</p>
<p>– 以上是对于 Gitflow 的简单总结，但是如果对于 hac 这种 toB的 产品， 各个客户有不同版本，多个版本需要同时维护的时候，需要考虑下这种场景是否适用。</p>
<h2 id="2-Git-Flow-如何使用"><a href="#2-Git-Flow-如何使用" class="headerlink" title="2. Git Flow 如何使用"></a>2. Git Flow 如何使用</h2><h3 id="1-Master-和-Dev-分支"><a href="#1-Master-和-Dev-分支" class="headerlink" title="1. Master 和 Dev 分支"></a>1. Master 和 Dev 分支</h3><p>所有在Master分支上的Commit应该打上Tag，一般情况下Master不存在Commit，Devlop分支基于Master分支创建</p>
<p> <img src="/../../../../images/20220805-12.png" alt="img"></p>
<h3 id="2-Feature-分支"><a href="#2-Feature-分支" class="headerlink" title="2. Feature 分支"></a>2. Feature 分支</h3><p>Feature分支做完后，必须合并回Develop分支, 合并完分支后一般会删点这个Feature分支。</p>
<p><img src="/../../../../images/20220805-13.png" alt="img"></p>
<h3 id="3-Release-分支"><a href="#3-Release-分支" class="headerlink" title="3. Release 分支"></a>3. Release 分支</h3><p>Release分支 基于 Develop分支 创建，打完Release分支之后，我们可以在这个Release分支上测试，修改Bug等。同时，其它开发人员可以基于Develop分支新建Feature  (记住：一旦打了Release分支之后不要从Develop分支上合并新的改动到Release分支) 发布Release分支时，合并Release到Master和Develop， 同时在Master分支上打个Tag记住Release版本号，然后删除Release分支。</p>
<p><img src="/../../../../images/20220805-14.png" alt="img"></p>
<h3 id="4-Hotfix分支"><a href="#4-Hotfix分支" class="headerlink" title="4. Hotfix分支"></a>4. Hotfix分支</h3><p>hotfix分支 基于 Master分支 创建，开发完后需要合并回Master和Develop分支，同时在Master上打一个tag。</p>
<p><img src="/../../../../images/20220805-15.png" alt="img"></p>
<h2 id="3-Git-Flow-命令示例"><a href="#3-Git-Flow-命令示例" class="headerlink" title="3. Git Flow 命令示例"></a>3. Git Flow 命令示例</h2><h3 id="1-创建-Dev"><a href="#1-创建-Dev" class="headerlink" title="1. 创建 Dev"></a>1. 创建 Dev</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git branch dev </span><br><span class="line">git push -u origin dev</span><br></pre></td></tr></table></figure>

<h3 id="2-开始-Feature"><a href="#2-开始-Feature" class="headerlink" title="2. 开始 Feature"></a>2. 开始 Feature</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 通过dev新建feaeure分支</span><br><span class="line">git checkout -b feature dev</span><br><span class="line"># 或者, 推送至远程服务器:</span><br><span class="line">git push -u origin feature    </span><br><span class="line"></span><br><span class="line"># 修改md文件   </span><br><span class="line">git status</span><br><span class="line">git add .</span><br><span class="line">git commit    </span><br></pre></td></tr></table></figure>

<h3 id="3-完成-Feature-合并其代码到dev"><a href="#3-完成-Feature-合并其代码到dev" class="headerlink" title="3. 完成 Feature, 合并其代码到dev"></a>3. 完成 Feature, 合并其代码到dev</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git pull origin dev</span><br><span class="line">git checkout dev</span><br><span class="line"></span><br><span class="line">#--no-ff：不使用fast-forward方式合并，保留分支的commit历史</span><br><span class="line">#--squash：使用squash方式合并，把多次分支commit历史压缩为一次</span><br><span class="line"></span><br><span class="line">git merge --no-ff feature</span><br><span class="line">git push origin develop</span><br><span class="line"></span><br><span class="line">git branch -d feature</span><br><span class="line"></span><br><span class="line"># 如果需要删除远程feature分支:</span><br><span class="line">git push origin --delete feature   </span><br></pre></td></tr></table></figure>

<h3 id="4-开始-Release"><a href="#4-开始-Release" class="headerlink" title="4. 开始 Release"></a>4. 开始 Release</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---基于dev分支，新建release分支 </span><br><span class="line">git checkout -b release-0.1.0 dev</span><br></pre></td></tr></table></figure>

<h3 id="5-完成-Release"><a href="#5-完成-Release" class="headerlink" title="5. 完成 Release"></a>5. 完成 Release</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--合并release 到 master</span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff release-0.1.0</span><br><span class="line">git push</span><br><span class="line"></span><br><span class="line">--合并release 到 dev</span><br><span class="line">git checkout dev</span><br><span class="line">git merge --no-ff release-0.1.0</span><br><span class="line">git push</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">git branch -d release-0.1.0</span><br><span class="line">git push origin --delete release-0.1.0   </span><br><span class="line"></span><br><span class="line"># 合并master/dev分支之后，打上tag </span><br><span class="line">git tag -a v0.1.0 master</span><br><span class="line">git push --tags</span><br></pre></td></tr></table></figure>

<h3 id="6-开始-Hotfix"><a href="#6-开始-Hotfix" class="headerlink" title="6. 开始 Hotfix"></a>6. 开始 Hotfix</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git checkout -b hotfix-0.1.1 master  </span><br></pre></td></tr></table></figure>

<h3 id="7-完成-Hotfix"><a href="#7-完成-Hotfix" class="headerlink" title="7. 完成 Hotfix"></a>7. 完成 Hotfix</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git checkout master</span><br><span class="line">git merge --no-ff hotfix-0.1.1</span><br><span class="line">git push</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff hotfix-0.1.1</span><br><span class="line">git push</span><br><span class="line"></span><br><span class="line">git branch -d hotfix-0.1.1</span><br><span class="line">git push origin --delete  hotfix-0.1.1 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">git tag -a v0.1.1 master</span><br><span class="line">git push --tags</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
